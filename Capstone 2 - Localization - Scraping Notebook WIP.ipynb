{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Video game localizion prioritization tool proposal\n",
    "---\n",
    "\n",
    "My goal is to scrape and analyze data from the video game platform\n",
    "Steam in order to help studios or localization service providers\n",
    "choose which languages they should localize into in order to\n",
    "maximize their localization ROI.\n",
    "\n",
    "The dataset would consist of a database of games with columns including\n",
    "genre, sales, price, number of reviews, percent of positive reviews,\n",
    "available languages, and the language that positive or negative reviews\n",
    "are written in. Any relationships between these variables (especially\n",
    "between language, genre, sales, price, and positive reviews, if such a\n",
    "relationship is found) could be instrumental in driving business\n",
    "decisions on the studio or language service provider level.\n",
    "\n",
    "The code below is the beginning of my scraper. It scrapes a search result\n",
    "page to gather the name, price, number of reviews, percent of positive\n",
    "reviews, and individual game page url for all listed games. In order to\n",
    "suit the needs of my project, it must be expanded to also perform the\n",
    "following:\n",
    "\n",
    "1. Scroll through a results list in order to cause the page to load more\n",
    "results (current max is 50). Tools exist for this, but I haven't had the\n",
    "time to study them yet.\n",
    "\n",
    "2. Perform a secondary scraping of the individual games' pages to collect\n",
    "the remainder of the column info that I haven't scraped yet. This is\n",
    "theoretically possible with my current limited skillset, though I worry\n",
    "that so many rapid calls will cause Steam to ban my ISP, so I should also\n",
    "study tools that slow down and/or randomize the request timing.\n",
    "\n",
    "3. Be able to ascertain the language in which a review is written. I think\n",
    "there are tools available for this - worst case scenario, I just ask\n",
    "ChatGPT 3.5 which language it is, using a rotating cast of ISPs to bypass\n",
    "the daily message limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic DS stuff\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Web scraping\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# I needed some extra help locating specific parts within a\n",
    "# bs4 tag object, so I got this.\n",
    "import re\n",
    "\n",
    "# I didn't end up using this one, but that might be because\n",
    "# I still have no idea what the eff I'm doing. Leaving it for\n",
    "# now in case I need it later.\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm using the search results for the word \"Hello\" as a test case.\n",
    "# The search URL can be directly appended to include specific search\n",
    "# conditions, including avialable languages, price, genre, etc.\n",
    "\n",
    "url = \"https://store.steampowered.com/search/?term=hello\"\n",
    "html = urlopen(url)\n",
    "my_soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"search_result_row ds_collapse_flag\" data-ds-appid=\"521890\" data-ds-crtrids=\"[6858705,35483784]\" data-ds-itemkey=\"App_521890\" data-ds-steam-deck-compat-handled=\"true\" data-ds-tagids=\"[1667,3810,1687,3839,4106,1742,3978]\" data-gpnav=\"item\" data-search-page=\"1\" href=\"https://store.steampowered.com/app/521890/Hello_Neighbor/?snr=1_7_7_151_150_1\" onmouseout=\"HideGameHover( this, event, 'global_hover' )\" onmouseover=\"GameHover( this, event, 'global_hover', {&quot;type&quot;:&quot;app&quot;,&quot;id&quot;:521890,&quot;public&quot;:1,&quot;v6&quot;:1} );\">\n",
      " <div class=\"col search_capsule\">\n",
      "  <img src=\"https://cdn.cloudflare.steamstatic.com/steam/apps/521890/capsule_sm_120.jpg?t=1670593236\" srcset=\"https://cdn.cloudflare.steamstatic.com/steam/apps/521890/capsule_sm_120.jpg?t=1670593236 1x, https://cdn.cloudflare.steamstatic.com/steam/apps/521890/capsule_231x87.jpg?t=1670593236 2x\"/>\n",
      " </div>\n",
      " <div class=\"responsive_search_name_combined\">\n",
      "  <div class=\"col search_name ellipsis\">\n",
      "   <span class=\"title\">\n",
      "    Hello Neighbor\n",
      "   </span>\n",
      "   <div>\n",
      "    <span class=\"platform_img win\">\n",
      "    </span>\n",
      "   </div>\n",
      "  </div>\n",
      "  <div class=\"col search_released responsive_secondrow\">\n",
      "   Dec 8, 2017\n",
      "  </div>\n",
      "  <div class=\"col search_reviewscore responsive_secondrow\">\n",
      "   <span class=\"search_review_summary positive\" data-tooltip-html=\"Very Positive&lt;br&gt;84% of the 9,599 user reviews for this game are positive.\">\n",
      "   </span>\n",
      "  </div>\n",
      "  <div class=\"col search_price_discount_combined responsive_secondrow\" data-price-final=\"2999\">\n",
      "   <div class=\"col search_discount_and_price responsive_secondrow\">\n",
      "    <div class=\"discount_block search_discount_block no_discount\" data-bundlediscount=\"0\" data-discount=\"0\" data-price-final=\"2999\">\n",
      "     <div class=\"discount_prices\">\n",
      "      <div class=\"discount_final_price\">\n",
      "       $29.99\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "   </div>\n",
      "  </div>\n",
      " </div>\n",
      " <div style=\"clear: left;\">\n",
      " </div>\n",
      "</a>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# From looking at the whole page's HTML, I can tell which tag to call in order\n",
    "# to get the information relevant to only a single game.\n",
    "\n",
    "single_game_example = my_soup.find('a', class_='search_result_row ds_collapse_flag')\n",
    "\n",
    "print(single_game_example.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "{'title': 'Hello Neighbor', 'release_date': 'Dec 8, 2017', 'positive_review_percent': '84%', 'number_of_reviews': '9,599', 'price': '$29.99', 'game_page_link': 'https://store.steampowered.com/app/521890/Hello_Neighbor/?snr=1_7_7_151_150_1'}\n"
     ]
    }
   ],
   "source": [
    "# Now I can begin scraping this info. In this step I'll also scrape the URL of\n",
    "# the game's inividual page for future scraping.\n",
    "\n",
    "# Create an empty list for the game info dictionaries to go into later.\n",
    "\n",
    "games = []\n",
    "\n",
    "# Loop through the HTML blocks for each game and scrape the key info into a dictionary,\n",
    "# then add the dictionaries to the list.\n",
    "# I'm not cleaning up the data types at this point - I'm learning as I'm going, so I'm\n",
    "# prioritizing getting all the info I need into the df, and then working with data\n",
    "# types later either by doing operations on the df or re-writing some of this code.\n",
    "\n",
    "for listing in my_soup.find_all('a', class_='search_result_row ds_collapse_flag') :\n",
    "\n",
    "    # Create (or clean out) an empty dictionary to hold the new info.\n",
    "\n",
    "    game = {}\n",
    "\n",
    "    # The title and release date seem to be at uniform locations in all listings.\n",
    "\n",
    "    game['title'] = listing.find('span', class_='title').get_text()\n",
    "    game['release_date'] = listing.find('div', class_='col search_released responsive_secondrow').get_text()\n",
    "\n",
    "    # Not all games have reviws listed, so we have to account for code blocks that omit this part.\n",
    "    # I might eventually remove this part and scrape the review data from the individual game pages\n",
    "    # instead, since it seems to be more complete there. This is just proof of concept for now.\n",
    "\n",
    "    try:\n",
    "        review_string = re.split('>| of|the | user', listing.find('div', class_='col search_reviewscore responsive_secondrow') \\\n",
    "                                                    .find('span').get('data-tooltip-html'))\n",
    "        game['positive_review_percent'] = review_string[1]\n",
    "        game['number_of_reviews'] = review_string[3]\n",
    "    except: \n",
    "        game['positive_review_percent'] = np.nan\n",
    "        game['number_of_reviews'] = np.nan\n",
    "    \n",
    "    # Same for price - many unreleased games do not have price info, so we have to skip them.\n",
    "    # Some games have an original price and a discounted price listed, but for the time being\n",
    "    # I've decided to only go by original prices, so I'll default to that and only return\n",
    "    # a null value if no kind of price whatsoever is listed.\n",
    "\n",
    "    try: \n",
    "        game['price'] = listing.find('div', class_=\"discount_original_price\").get_text()\n",
    "    except:\n",
    "        try:\n",
    "            game['price'] = listing.find('div', class_=\"discount_final_price\").get_text()\n",
    "        except:\n",
    "            game['price'] = np.nan\n",
    "\n",
    "    # Weirdly enough, not every game seems to have its own page.\n",
    "\n",
    "    try:\n",
    "        game['game_page_link'] = listing.get('href')\n",
    "    except:\n",
    "        game['game_page_link'] = False\n",
    "\n",
    "    # Now we add this dict to the list, rinse and repeat.\n",
    "\n",
    "    games.append(game)\n",
    "\n",
    "# After the loop, we check...\n",
    "print(len(games))\n",
    "print(games[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 6 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   title                    50 non-null     object\n",
      " 1   release_date             50 non-null     object\n",
      " 2   positive_review_percent  35 non-null     object\n",
      " 3   number_of_reviews        35 non-null     object\n",
      " 4   price                    32 non-null     object\n",
      " 5   game_page_link           50 non-null     object\n",
      "dtypes: object(6)\n",
      "memory usage: 2.5+ KB\n",
      "None\n",
      "              title  release_date positive_review_percent number_of_reviews  \\\n",
      "0    Hello Neighbor   Dec 8, 2017                     84%             9,599   \n",
      "1     Hello Goodboy  May 25, 2023                    100%                34   \n",
      "2    Hello, Goodbye  Apr 18, 2019                     91%                48   \n",
      "3  Hello Neighbor 2   Dec 6, 2022                     73%             1,444   \n",
      "4     Hello Teacher  Jun 16, 2021                     61%                36   \n",
      "\n",
      "    price                                     game_page_link  \n",
      "0  $29.99  https://store.steampowered.com/app/521890/Hell...  \n",
      "1  $14.99  https://store.steampowered.com/app/1789090/Hel...  \n",
      "2  $29.99  https://store.steampowered.com/app/1009460/Hel...  \n",
      "3  $39.99  https://store.steampowered.com/app/1321680/Hel...  \n",
      "4   $0.99  https://store.steampowered.com/app/1387970/Hel...  \n"
     ]
    }
   ],
   "source": [
    "# Frame it and check.\n",
    "\n",
    "game_info_df = pd.DataFrame(games)\n",
    "print(game_info_df.info())\n",
    "print(game_info_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*That's all for now!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
