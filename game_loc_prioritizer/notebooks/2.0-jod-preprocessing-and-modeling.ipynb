{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Uses the following data:  \n",
    "1. games_df, a table of general information about (almost) all Steam games\n",
    "2. review_table, a table of 6+million reviews scraped from the Steam store, listing the user, game, etc\n",
    "3. recently_played_df, a table of users' recently played games with playtimes\n",
    "\n",
    "Accomplishes the following:\n",
    "1. Generate tables containing vectors for every game and every user. Our inputs will be limited to items in this table.\n",
    "2. Generate reduced tables containing vectors of only the games and users that have rich enough info to be useful for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bidict import bidict\n",
    "\n",
    "import pickle\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import coo_matrix, csr_matrix, lil_matrix, save_npz\n",
    "\n",
    "%store -r tags_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "\n",
    "with open('../data/interim/1 - Games DF - Wrangled.pkl', 'rb') as file :\n",
    "    games_df = pickle.load(file)\n",
    "\n",
    "review_table = pq.read_table('../data/interim/cleaned_reviews.parquet')\n",
    "\n",
    "with open('../data/interim/recently_played_cleaned.pkl', 'rb') as file :\n",
    "    recently_played_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make games vectors/matrices\n",
    "\n",
    "We'll produce one matrix with all known games. This will be used to vectorize input.  \n",
    "  \n",
    "Then we'll produce a matrix that contains only those games with sufficient information to be subjects of recommendation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>tag_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>730</td>\n",
       "      <td>[FPS, Shooter, Multiplayer, Competitive, Actio...</td>\n",
       "      <td>[FPS, Shooter, Multiplayer, Competitive, Actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>553850</td>\n",
       "      <td>[Action, Online Co-Op, Multiplayer, Third-Pers...</td>\n",
       "      <td>[Action, Online Co-Op, Third-Person Shooter, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1086940</td>\n",
       "      <td>[RPG, Choices Matter, Story Rich, Character Cu...</td>\n",
       "      <td>[RPG, Choices Matter, Story Rich, Character Cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1245620</td>\n",
       "      <td>[Souls-like, Dark Fantasy, Open World, RPG, Di...</td>\n",
       "      <td>[Souls-like, Dark Fantasy, Open World, RPG, Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1623730</td>\n",
       "      <td>[Multiplayer, Open World, Survival, Creature C...</td>\n",
       "      <td>[Multiplayer, Open World, Survival, Creature C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    app_id                                               tags  \\\n",
       "0      730  [FPS, Shooter, Multiplayer, Competitive, Actio...   \n",
       "1   553850  [Action, Online Co-Op, Multiplayer, Third-Pers...   \n",
       "2  1086940  [RPG, Choices Matter, Story Rich, Character Cu...   \n",
       "3  1245620  [Souls-like, Dark Fantasy, Open World, RPG, Di...   \n",
       "4  1623730  [Multiplayer, Open World, Survival, Creature C...   \n",
       "\n",
       "                                            tag_list  \n",
       "0  [FPS, Shooter, Multiplayer, Competitive, Actio...  \n",
       "1  [Action, Online Co-Op, Third-Person Shooter, M...  \n",
       "2  [RPG, Choices Matter, Story Rich, Character Cu...  \n",
       "3  [Souls-like, Dark Fantasy, Open World, RPG, Di...  \n",
       "4  [Multiplayer, Open World, Survival, Creature C...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isolate the info we'll use for the vectors\n",
    "games_df_tags_only = games_df[['app_id', 'tags', 'tag_list']]\n",
    "games_df_tags_only.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a handy dict for the app_ids and their new indexes\n",
    "game_to_full_index = bidict()\n",
    "for index, row in games_df_tags_only.iterrows() :\n",
    "    game_to_full_index[index] = row['app_id']\n",
    "game_to_full_index = game_to_full_index.inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our list of columns\n",
    "used_tags = set(tags_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 'FPS', 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare our sparse matrix\n",
    "# NOTE: We will weight PRIMARY tags more strongly than non-primary tags.\n",
    "# A lower weight_ratio favors primary tags more.\n",
    "\n",
    "weight_ratio = 0.8\n",
    "\n",
    "matrix_values = []\n",
    "\n",
    "for index, row in games_df_tags_only.iterrows() :\n",
    "    skips = set()\n",
    "    for tag in row['tags'] :\n",
    "        skips.add(tag)\n",
    "        tup = (index, tag, 1)\n",
    "        matrix_values.append(tup)\n",
    "    for tag in row['tag_list'] :\n",
    "        if tag not in skips :\n",
    "                    tup = (index, tag, weight_ratio)\n",
    "                    matrix_values.append(tup)\n",
    "\n",
    "matrix_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make the matrix, we must index our tags.\n",
    "tag_to_col_index = bidict()\n",
    "i = 0\n",
    "for value in tags_dict.values() :\n",
    "    tag_to_col_index[value] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the matrix\n",
    "\n",
    "rows = [row[0] for row in matrix_values]\n",
    "columns = [tag_to_col_index[row[1]] for row in matrix_values]\n",
    "values = [row[2] for row in matrix_values]\n",
    "\n",
    "matrix_row_count = max(rows)+1\n",
    "matrix_col_count = max(columns)+1\n",
    "\n",
    "game_tags_matrix = coo_matrix((values, (rows, columns)), shape=(matrix_row_count, matrix_col_count))\n",
    "game_tags_matrix = csr_matrix(game_tags_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good job, everybody! Let's save it and move on.\n",
    "save_npz('../data/processed/full_game_tag_matrix.npz', game_tags_matrix)\n",
    "\n",
    "# And also the index dicts.\n",
    "with open('../data/processed/tag_to_col_index.pkl', \"wb\") as file :\n",
    "    pickle.dump(tag_to_col_index, file)\n",
    "\n",
    "with open('../data/processed/game_to_full_index.pkl', \"wb\") as file :\n",
    "    pickle.dump(game_to_full_index, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we subset this matrix to include only games with 10+ tags.\n",
    "\n",
    "This index will be smaller, but we must be careful to note the original index values. That's the only way we can relate the rows in this matrix to any other matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_counts = pd.Series(game_tags_matrix.getnnz(axis=1))\n",
    "can_keep = nonzero_counts >= 10\n",
    "game_tags_matrix_reduced = game_tags_matrix[can_keep]\n",
    "\n",
    "## This creates a dict with:\n",
    "##  KEYS == reduced matrix index\n",
    "##  VALUES == corresponding full matrix index\n",
    "game_reduced_index_to_full_index = bidict()\n",
    "i=0\n",
    "for index, value in can_keep.items() :\n",
    "    if value==True :\n",
    "        game_reduced_index_to_full_index[i]=index\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save! That! Matrix!\n",
    "save_npz('../data/processed/reduced_game_tag_matrix.npz', game_tags_matrix_reduced)\n",
    "\n",
    "# And the dict, of course.\n",
    "with open('../data/processed/game_reduced_index_to_full_index.pkl', 'wb') as file :\n",
    "    pickle.dump(game_reduced_index_to_full_index, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we make the users matrices..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4181501 entries, 0 to 4181500\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Dtype \n",
      "---  ------       ----- \n",
      " 0   user         object\n",
      " 1   app_id       int64 \n",
      " 2   playtime_2w  int64 \n",
      " 3   playtime_f   int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 127.6+ MB\n"
     ]
    }
   ],
   "source": [
    "recently_played_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6747619, 11)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100894"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because our games_df does not contain every single game on Steam, it's possible\n",
    "# that a game will be touched in a review or recently_played about which we cannot\n",
    "# make inference.\n",
    "# Let's make a set of all usable games to help limit our tables to legal values.\n",
    "usable_app_ids = set(games_df['app_id'].values)\n",
    "len(usable_app_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3593525 entries, 0 to 3593524\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Dtype \n",
      "---  ------       ----- \n",
      " 0   user         object\n",
      " 1   app_id       int64 \n",
      " 2   playtime_2w  int64 \n",
      " 3   playtime_f   int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 109.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Now let's reduce the above datasets to only those which touch usable games.\n",
    "recently_played_df = recently_played_df[recently_played_df['app_id'].isin(usable_app_ids)].reset_index(drop=True)\n",
    "recently_played_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5726093 entries, 0 to 5726092\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   user             object \n",
      " 1   app_id           int64  \n",
      " 2   positive         int64  \n",
      " 3   total_playtime   float64\n",
      " 4   review_playtime  float64\n",
      " 5   text             object \n",
      " 6   helpful_count    int64  \n",
      " 7   review_date      object \n",
      " 8   edit_date        object \n",
      " 9   date_scraped     object \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 436.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# To subset the review_talbe, we'll have to pandacize it first.\n",
    "\n",
    "review_df = review_table.to_pandas()\n",
    "review_df = review_df[review_df['app_id'].isin(usable_app_ids)].reset_index(drop=True)\n",
    "review_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should save processed versions of these for use in the modeling notebook.\n",
    "usable_review_table = pa.Table.from_pandas(review_df)\n",
    "pq.write_table(usable_review_table, '../data/processed/usable_review_table.parquet')\n",
    "\n",
    "with open('../data/processed/usable_recently_played.pkl', 'wb') as file :\n",
    "    pickle.dump(recently_played_df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The two tables above contain different but overlapping sets of users.\n",
    "# In order to combine them into a single users matrix, we must first create\n",
    "# a unified index for all touched users.\n",
    "\n",
    "recently_users = set(recently_played_df['user'].values)\n",
    "review_users = set(review_table['user'].to_pylist())\n",
    "touched_users = recently_users | review_users\n",
    "\n",
    "user_to_full_index = bidict()\n",
    "i=0\n",
    "for user in touched_users :\n",
    "    user_to_full_index[user] = i\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need a unified index for games.\n",
    "\n",
    "recently_games =set(recently_played_df['app_id'].values)\n",
    "review_games = set(review_table['app_id'].to_pylist())\n",
    "touched_games = recently_games | review_games\n",
    "\n",
    "game_to_col_index = bidict()\n",
    "i=0\n",
    "for game in touched_games :\n",
    "    game_to_col_index[game] = i\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's prepare our points.\n",
    "\n",
    "recently_played_points = recently_played_df.apply( \\\n",
    "                                lambda row: (user_to_full_index[row['user']], game_to_col_index[row['app_id']], 0.2), axis=1) \\\n",
    "                                .tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we'll have to update this matrix in a sec, let's make it a lil_matrix first.\n",
    "\n",
    "user_info_matrix = lil_matrix((len(touched_users), len(touched_games)), dtype=float)\n",
    "\n",
    "for point in recently_played_points :\n",
    "    user_info_matrix[point[0], point[1]] = point[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's prepare the review data to update that matrix.\n",
    "\n",
    "positive_reviews = review_df[review_df['positive']==1][['user', 'app_id']]\n",
    "negative_reviews = review_df[review_df['positive']==0][['user', 'app_id']]\n",
    "\n",
    "positive_points = positive_reviews.apply( \\\n",
    "                lambda row: (user_to_full_index[row['user']], game_to_col_index[row['app_id']], 1), axis=1) \\\n",
    "                .tolist()\n",
    "                                \n",
    "negative_points = negative_reviews.apply( \\\n",
    "                lambda row: (user_to_full_index[row['user']], game_to_col_index[row['app_id']], -1), axis=1) \\\n",
    "                .tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now, we update the matrix.\n",
    "\n",
    "for point in positive_points :\n",
    "    user_info_matrix[point[0], point[1]] = point[2]\n",
    "\n",
    "for point in negative_points :\n",
    "    user_info_matrix[point[0], point[1]] = point[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just for funsies, make it the same format as our games matrix.\n",
    "user_info_matrix = user_info_matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save! That! Matrix!\n",
    "save_npz('../data/processed/user_info_matrix.npz', user_info_matrix)\n",
    "\n",
    "# And the dicts, of course.\n",
    "with open('../data/processed/user_to_full_index.pkl', 'wb') as file :\n",
    "    pickle.dump(user_to_full_index, file)\n",
    "\n",
    "with open('../data/processed/game_to_col_index.pkl', 'wb') as file :\n",
    "    pickle.dump(game_to_col_index, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.887354e+06\n",
       "mean     4.779766e+00\n",
       "std      7.041132e+00\n",
       "min      0.000000e+00\n",
       "25%      1.000000e+00\n",
       "50%      3.000000e+00\n",
       "75%      6.000000e+00\n",
       "max      5.517000e+03\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we create a subset of the matrix that contains only users with enough info for prediction.\n",
    "# Where should we put the threshold?\n",
    "\n",
    "nonzero_counts = pd.Series(user_info_matrix.getnnz(axis=1))\n",
    "nonzero_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll arbitrarily choose 5. Sue me! I dare you.\n",
    "\n",
    "can_keep = nonzero_counts >= 5\n",
    "user_info_matrix_reduced = user_info_matrix[can_keep]\n",
    "\n",
    "## This creates a dict with:\n",
    "##  KEYS == reduced matrix index\n",
    "##  VALUES == corresponding full matrix index\n",
    "\n",
    "user_reduced_index_to_full_index = bidict()\n",
    "i=0\n",
    "for index, value in can_keep.items() :\n",
    "    if value==True :\n",
    "        user_reduced_index_to_full_index[i]=index\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save! That! Matrix!\n",
    "save_npz('../data/processed/user_info_matrix_reduced.npz', user_info_matrix_reduced)\n",
    "\n",
    "# etc etc\n",
    "with open('../data/processed/user_reduced_index_to_full_index.pkl', 'wb') as file :\n",
    "    pickle.dump(user_reduced_index_to_full_index, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At time of inference, the top X consine similarity users' rows will be called up, and the most common games not already played by the user will be recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Describes a system for taking a single user_id as an input and generating game recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dfs to display the rec results in a human-readable way\n",
    "with open('../data/interim/1 - Games DF - Wrangled.pkl', 'rb') as file :\n",
    "    games_df = pickle.load(file)\n",
    "with open('../data/processed/usable_recently_played.pkl', 'rb') as file :\n",
    "    recently_played_df = pickle.load(file)\n",
    "review_table = pq.read_table('../data/processed/usable_review_table.parquet')\n",
    "with open('../data/raw/all_users', 'rb') as file :\n",
    "    all_users = pickle.load(file)\n",
    "\n",
    "# Load the tables used to define input\n",
    "game_tags_matrix = load_npz('../data/processed/full_game_tag_matrix.npz')\n",
    "user_info_matrix = load_npz('../data/processed/user_info_matrix.npz')\n",
    "\n",
    "# Load the tables used for inference\n",
    "game_tags_matrix_reduced = load_npz('../data/processed/reduced_game_tag_matrix.npz')\n",
    "user_info_matrix_reduced = load_npz('../data/processed/user_info_matrix_reduced.npz')\n",
    "\n",
    "# Load the index converters for the games/tags matrix\n",
    "with open('../data/processed/tag_to_col_index.pkl', \"rb\") as file :\n",
    "    tag_to_col_index = pickle.load(file)\n",
    "with open('../data/processed/game_reduced_index_to_full_index.pkl', 'rb') as file :\n",
    "    game_reduced_index_to_full_index = pickle.load(file)\n",
    "with open('../data/processed/game_to_full_index.pkl', 'rb') as file :\n",
    "    game_to_full_index = pickle.load(file)\n",
    "\n",
    "# Load the index converters for the users/games matrix\n",
    "with open('../data/processed/user_to_full_index.pkl', 'rb') as file :\n",
    "    user_to_full_index = pickle.load(file)\n",
    "with open('../data/processed/game_to_col_index.pkl', 'rb') as file :\n",
    "    game_to_col_index = pickle.load(file)\n",
    "with open('../data/processed/user_reduced_index_to_full_index.pkl', 'rb') as file :\n",
    "    user_reduced_index_to_full_index = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative recommendations, step 1: find similar users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an arbitrary number of similar users\n",
    "def get_similar_users(target_user_row, similar_user_limit=50, test_user_indices=[], testing=False, verbose=False) :\n",
    "    \"\"\"\n",
    "    Takes a user id and returns a sorted descending series of the X most similar users:\n",
    "        keys = user index (in the reduced matrix)\n",
    "        values = cosine similarity\n",
    "    Rows that have played no games that the target user hasn't also played are removed,*\n",
    "    as they have no novel info for prediction.\n",
    "    \"\"\"\n",
    "\n",
    "    # Go ahead and run cosine similarity now, so that the scores can be associated with the correct index (the reduced user matrix index).\n",
    "    row_cosine_similarities = pd.Series(cosine_similarity(target_user_row, user_info_matrix_reduced)[0], name=\"similarity_score\")\n",
    "\n",
    "    # If we're testing, remove all test users from this step\n",
    "    if testing==True :\n",
    "        for index in row_cosine_similarities.index :\n",
    "            if index in test_user_indices :\n",
    "                row_cosine_similarities = row_cosine_similarities.drop(index)\n",
    "\n",
    "    # Remove the 1s.\n",
    "    # This eliminates any user whose play profile is identical to that of the target user,\n",
    "    # meaning they would be useless for prediction.\n",
    "    # Also removes the target user.\n",
    "    row_cosine_similarities = row_cosine_similarities[row_cosine_similarities < 1]\n",
    "\n",
    "    row_cosine_similarities.sort_values(ascending=False, inplace=True)\n",
    "    most_similar_users = row_cosine_similarities[:similar_user_limit]\n",
    "\n",
    "    if verbose==True :\n",
    "        print(f\"Top {similar_user_limit} most similar users:\")\n",
    "        for index, value in most_similar_users.items() :\n",
    "            print(f\"{round(value, 9)} -- {index}\")\n",
    "            \n",
    "    return(most_similar_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative recommendations, step 2: generate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate suggestions based on that.\n",
    "# First, find out all the games these \"similar users\" have played.\n",
    "# Then, weight those playes by the similarity score, then sum them across users.\n",
    "\n",
    "# NOTE：I could speed all this up by just using arrays instead of rows/columns\n",
    "\n",
    "\n",
    "def get_collab_scores(similar_users, collab_filter_limit=50, target_user_touched_games=[], verbose=False) :\n",
    "    \n",
    "    # Convert to df for easier row/column-wise computation\n",
    "    similar_users_df = pd.DataFrame(similar_users)\n",
    "\n",
    "    # We need to make a column in the df for each game, so we grab all games\n",
    "    # here (indexed by game col index).\n",
    "    # We remove any games already touched by the target user along the way.\n",
    "    relevant_games = set()\n",
    "    for user in similar_users.keys() :\n",
    "        for game in user_info_matrix[user].indices :\n",
    "            if game not in target_user_touched_games :\n",
    "                relevant_games.add(game)\n",
    "    \n",
    "    # Create a column for each game\n",
    "    for game in relevant_games :\n",
    "        similar_users_df[game] = 0\n",
    "\n",
    "    # Now fill those columns with the scores\n",
    "    for user in similar_users.keys() :\n",
    "        for game in user_info_matrix[user].indices :\n",
    "            similar_users_df.loc[user, game] = user_info_matrix[user, game]\n",
    "\n",
    "    # Now multiply the scores by the normalized similarity score\n",
    "    for user, row in similar_users_df.iterrows() :\n",
    "        for game in relevant_games :\n",
    "            if row[game] != 0 :\n",
    "                similar_users_df.loc[user, game] = row['similarity_score'] * row[game]\n",
    "\n",
    "    # Now collect those scores\n",
    "    # NOTE: CONVERTS GAME COL INDEX BACK TO APP_ID AT THIS STEP\n",
    "    collab_filt_rec_scores = {}\n",
    "    for game in relevant_games:\n",
    "        collab_filt_rec_scores[game_to_col_index.inverse[game]] = similar_users_df[game].sum()\n",
    "\n",
    "    collab_filt_scores = pd.Series(collab_filt_rec_scores, name=\"collab_rec_score\").sort_values(ascending=False)\n",
    "\n",
    "    # Limit the output\n",
    "    collab_filt_scores = collab_filt_scores[:collab_filter_limit]\n",
    "\n",
    "    # To make them interactible with later scores, let's standardize them\n",
    "    # scaler = MinMaxScaler()\n",
    "    # collab_filt_scores = pd.Series(scaler.fit_transform(collab_filt_rec_scores.values.reshape(-1,1)).flatten(), index=collab_filt_rec_scores.index)\n",
    "    # if verbose==True :\n",
    "    #     for app_id, score in collab_filt_scores.items() :\n",
    "    #         print(f\"{round(score, 3)} -- {games_df[games_df['app_id']==app_id]['title'].values[0]}\")\n",
    "    \n",
    "    return collab_filt_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-based recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: STRETCH GOAL: Determine multimodality, generate different lists of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine most similar games for each, multiply by user preference, MinMaxScale.\n",
    "\n",
    "def get_content_scores(target_user_row, content_filter_limit, verbose=False) :\n",
    "\n",
    "    \"\"\"\n",
    "    Takes a row from the users/games table, then does the following:\n",
    "        1. Finds recs for each from the reduced game/tags matrix\n",
    "        2. Creates a descending-sorted 10-row Series:\n",
    "            keys = game's index (relative to main games_df)\n",
    "            values = queried game's cosine similarity score to the queried game\n",
    "        3. Weights all values in the series by the user's preference for the game\n",
    "        4. Combines all resulting series into a single series with sim scores summed\n",
    "        5. Returns the series\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the most recent games.\n",
    "    # I already have the games in terms of col indices in the users matrix.\n",
    "    # I need the indices for the games matrix, to do cos similarity.\n",
    "\n",
    "    # Go from game col index to app_id\n",
    "    # played_game_app_ids = [game_to_col_index.inverse[game] for game in target_user_row.indices]\n",
    "    # # Go from app_id to full game row index\n",
    "    # played_game_full_matrix_row_indices = [game_to_full_index[game] for game in played_game_app_ids]\n",
    "\n",
    "    # Find the sim scores for each game, adding them to the main list\n",
    "    similarity_series_list = []\n",
    "    full_row_indexes = []\n",
    "\n",
    "    for query_index in target_user_row.indices :\n",
    "\n",
    "        # Get the reduced game/tags matrix index\n",
    "        current_app_id = game_to_col_index.inverse[query_index] \n",
    "        current_full_row_index = game_to_full_index[current_app_id]\n",
    "        try :\n",
    "            reduced_row_index = game_reduced_index_to_full_index.inverse[current_full_row_index]\n",
    "        except :\n",
    "            ####\n",
    "            continue \n",
    "\n",
    "        # Let's grab the full row index. We will later use this to remove\n",
    "        # already-touched games from the recommendations.\n",
    "        full_row_indexes.append(current_full_row_index)\n",
    "\n",
    "        # Find the similarity score between games\n",
    "        # The resulting series is indexed by the reduced games matrix\n",
    "        row_cosine_similarities = pd.Series(cosine_similarity(game_tags_matrix[current_full_row_index], game_tags_matrix_reduced)[0])\n",
    "        # Reindex the predictions back to the full game matrix index\n",
    "        row_cosine_similarities.index = [game_reduced_index_to_full_index[index] for index in row_cosine_similarities.index]\n",
    "        row_cosine_similarities.sort_values(ascending=False, inplace=True)\n",
    "        # Since we cannot know ahead of time how many games the user has touched,\n",
    "        # and the user may have only touched one game,\n",
    "        # we can safely limit the results here to the overall content filter limit.\n",
    "        # This will ensure that the full number of scores are returned no matter \n",
    "        # how many games were touched. \n",
    "        # This is still indexed by the full game matrix.\n",
    "        top_similar = row_cosine_similarities[:content_filter_limit]\n",
    "\n",
    "        # Now, get a coefficient to represent the user's preference for the game in question.\n",
    "        # All games similar to this game will be modified by this coefficient.\n",
    "        # First we find the game's column in the full user matrix\n",
    "        preference_coefficient = target_user_row[0, query_index]\n",
    "        # Then we just multiply.\n",
    "        top_similar = top_similar * preference_coefficient\n",
    "\n",
    "        # That's all we need for the score! Let's append.\n",
    "        similarity_series_list.append(top_similar)\n",
    "\n",
    "        # if verbose == True :\n",
    "        #     print(f\"Recs for {games_df.loc[current_full_row_index]['title']}:\")\n",
    "        #     for rec in top_similar.items() :\n",
    "        #         print(f\"{round(rec[1], 3)} -- {games_df.loc[rec[0]]['title']}\")\n",
    "\n",
    "    # Combine the serieses into the main series.\n",
    "    # Here it's still indexed by full game matrix index.\n",
    "    final_scores = pd.Series()\n",
    "    for similarity_series in similarity_series_list :\n",
    "        final_scores = final_scores.add(similarity_series, fill_value=0)\n",
    "    final_scores = final_scores.sort_values(ascending=False)\n",
    "\n",
    "    # Remove already-played games from the main series\n",
    "    for game in full_row_indexes :\n",
    "        try :\n",
    "            final_scores = final_scores.drop(labels=game)\n",
    "        except :\n",
    "            continue\n",
    "\n",
    "    # Normalize the series to make it similar to the collaborative score series\n",
    "    # I suppose the original values were some wonky kind of float that didn't work\n",
    "    # with scipy, so we coerce them here.\n",
    "    content_filt_scores = stats.zscore(final_scores.astype(float))\n",
    "\n",
    "    # Return the desired number of values\n",
    "    if len(content_filt_scores) < content_filter_limit :\n",
    "        content_filter_limit = len(content_filt_scores)\n",
    "    content_filt_scores = content_filt_scores[:content_filter_limit]\n",
    "\n",
    "    # Set index to app_id\n",
    "    content_filt_scores.index = [game_to_full_index.inverse[game] for game in content_filt_scores.index]\n",
    "\n",
    "    # if verbose == True :\n",
    "    #     print('------------------')\n",
    "    #     for game, score in content_filt_scores.items() :\n",
    "    #         print(f\"{round(score, 3)} -- {games_df[games_df['app_id']==game]['title'].values[0]}\")     \n",
    "    \n",
    "    return(content_filt_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the recs for final set of recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Is it worth checking the scale discrepancy between the two and tweaking the ratio\n",
    "# programmatically for each distribution?\n",
    "\n",
    "# It may be that tweaking the relative weights of the collaborative and content-based filter results\n",
    "# can improve accuracy. Let's define this as a function so we can play with that programmatically\n",
    "# later, if need be.\n",
    "\n",
    "def combine_scores(collaborative, content_based, double_bonus=0, popular_bias=0, ratio=0.5, recs=10) :\n",
    "    \"\"\"\n",
    "    Takes a series of collaborative filtering scores (key=app_id, value=score)\n",
    "    And a series of content based filtering scores with the same schema\n",
    "    And a 0-1 ratio of importance between the two (higher ratio favors collaborative scores)\n",
    "    And the \"double_bonus\", which is multiplied/summed to the score of each game that appears in both lists\n",
    "    And a \"popular_bias\" which is multiplied to the pos_review_percent and added to the score\n",
    "    And the number of recommendations to be returned\n",
    "\n",
    "    Returns a series of game app_ids and recommendation scores\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the ratio-modified scores\n",
    "    collaborative = collaborative * ratio\n",
    "    content_based = content_based * (1-ratio)\n",
    "\n",
    "    # Add them into the base final scores series\n",
    "    final_recs = collaborative.add(content_based, fill_value=0)\n",
    "\n",
    "    # Apply doubles bonus, if any\n",
    "    doubles = []\n",
    "    for game in collaborative.index :\n",
    "        if game in content_based.index :\n",
    "            doubles.append(game)\n",
    "    for game in doubles :\n",
    "        final_recs[game] += (final_recs[game] * double_bonus)\n",
    "\n",
    "    # Apply popularity bonus, if any\n",
    "    for index in final_recs.index :\n",
    "        positive_review_percent = games_df[games_df['app_id']==index]['positive_review_percent'].values[0]\n",
    "        final_recs[index] += (positive_review_percent * popular_bias)\n",
    "\n",
    "    # Sort descending\n",
    "    final_recs = final_recs.sort_values(ascending=False)\n",
    "\n",
    "    # Determine length\n",
    "    if len(final_recs) < recs :\n",
    "        recs = len(final_recs)\n",
    "    \n",
    "    # Determine final recs\n",
    "    final_recs = final_recs[:recs]\n",
    "\n",
    "    return final_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create unified function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recs(user, similar_user_limit=50, collab_filter_limit=50, content_filter_limit=50, double_bonus=0, popular_bias=0, ratio=0.5, recs=10, test_user_indices=[], test_user_rows=[], testing=False, verbose=False, show_result=False) :\n",
    "\n",
    "    \"\"\"\n",
    "    Takes a user via full user matrix index\n",
    "    Generates a series of recommendations\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Let's-a-go!\n",
    "    begin = time.time()\n",
    "\n",
    "    # Grab some useful info about the target user\n",
    "    if testing==True :\n",
    "        # target_user_id = user_reduced_index_to_full_index.inverse[game_reduced_index_to_full_index[user]]\n",
    "        target_user_row = test_user_rows[test_user_indices.index(user)]\n",
    "        # print(target_user_row)\n",
    "    else :\n",
    "        # target_user_id = user_to_full_index.inverse[user]\n",
    "        target_user_row = user_info_matrix[user]\n",
    "\n",
    "    target_user_touched_games = set(target_user_row.indices)\n",
    "\n",
    "    # Display some stuff\n",
    "    if show_result==True or verbose==True :\n",
    "        print(\"------ User profile:\")\n",
    "        for game in target_user_touched_games :\n",
    "            app_id = game_to_col_index.inverse[game]\n",
    "            score = target_user_row[0, game]\n",
    "            print(f\"{score} - {games_df[games_df['app_id']==app_id]['title'].values[0]}\")\n",
    "        print(\"--------------------\")\n",
    "\n",
    "    # Get similar users\n",
    "    most_similar_users = get_similar_users(target_user_row, similar_user_limit=similar_user_limit, test_user_indices=test_user_indices, testing=testing, verbose=False)\n",
    "    if verbose==True :\n",
    "        print(\"\\nTop 5 most similar users\\n\")\n",
    "        print(most_similar_users.head())\n",
    "        print(\"--------------------------\")\n",
    "\n",
    "    # Print the params here to make it easier to intuit what's happening in the results\n",
    "    if verbose==True :\n",
    "        print(f\"similar_user_limit: {similar_user_limit}\")\n",
    "        print(f\"collab_filter_limit: {collab_filter_limit}\")\n",
    "        print(f\"content_filter_limit: {content_filter_limit}\")\n",
    "        print(f\"double_bonus: {round(double_bonus, 3)}\")\n",
    "        print(f\"popular_bias: {round(popular_bias, 3)}\")\n",
    "        print(f\"ratio col/con: {round(ratio, 3)}\")\n",
    "        print(f\"num of recs: {recs}\\n\")\n",
    "\n",
    "    # Get scores from them\n",
    "    collab_filt_scores = get_collab_scores(most_similar_users, collab_filter_limit=collab_filter_limit, target_user_touched_games=target_user_touched_games, verbose=False)\n",
    "    if verbose==True :\n",
    "        print(\"Top 8 collab filt scores\")\n",
    "        for index, item in collab_filt_scores.head(8).items() :\n",
    "            print(f\"{round(item, 3)} -- {games_df[games_df['app_id']==index]['title'].values[0]}\")\n",
    "        print(\"--------------------------\")\n",
    "\n",
    "    # Get content filtering scores\n",
    "    content_filt_scores = get_content_scores(target_user_row, content_filter_limit=content_filter_limit,  verbose=False)\n",
    "    if verbose==True :\n",
    "        print(\"Top 8 content filt scores\")\n",
    "        for index, item in content_filt_scores.head(8).items() :\n",
    "            print(f\"{round(item, 3)} -- {games_df[games_df['app_id']==index]['title'].values[0]}\")\n",
    "        print(\"--------------------------\")\n",
    "    \n",
    "    # Calculate final scores\n",
    "    final_recs = combine_scores(collab_filt_scores, content_filt_scores, double_bonus=double_bonus, popular_bias=popular_bias, ratio=ratio, recs=recs)\n",
    "\n",
    "    if show_result==True or verbose==True:\n",
    "        print('')\n",
    "        print('------ Recommendations')\n",
    "        for index, score in final_recs.items() :\n",
    "            print(f\"{round(score, 3)} -- {games_df[games_df['app_id']==index]['title'].values[0]}\")\n",
    "        print(\"--------------------\")\n",
    "        print(f\"\\nRuntime: {round(time.time()-begin, 2)}s\\n\")\n",
    "\n",
    "    return final_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Commented out so that running the notebook skips directly to testing/evaluation\n",
    "\n",
    "# params = {\n",
    "#     \"similar_user_limit\":50,\n",
    "#     \"collab_filter_limit\":50,\n",
    "#     \"content_filter_limit\":50,\n",
    "#     \"double_bonus\":2,\n",
    "#     \"popular_bias\":3,\n",
    "#     \"ratio\":0.2,\n",
    "#     \"recs\":20,\n",
    "#     \"verbose\":False,\n",
    "#     \"show_result\": True\n",
    "# }\n",
    "\n",
    "# recs = get_recs(50, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "The basic idea is to remove a game or games from a user's profile (preferably a user with a significant number of touched games) and see if the engine recommends that game for the modified user profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programmatically assemble a set of usable user profiles (10+ touched games)\n",
    "\n",
    "def get_test_users(user_count=50, minimum_games=10) :\n",
    "    \"\"\"\n",
    "    Returns user_count number of test users (reduced user matrix index) as a list\n",
    "    Each user must have at least minimum_games number of touched games and disliked at least one game\n",
    "    \"\"\"\n",
    "    \n",
    "    # VARS\n",
    "    test_user_indices = []\n",
    "    checked_indices = set()\n",
    "    total_users = user_info_matrix_reduced.shape[0]\n",
    "\n",
    "    while len(test_user_indices) < user_count :\n",
    "        # Find a user at random\n",
    "        index = random.randint(1, total_users)\n",
    "        # Make sure you haven't done this one before\n",
    "        if index not in checked_indices :\n",
    "            # Make sure the user has enough games\n",
    "            if len(user_info_matrix_reduced[index].indices) >= minimum_games :\n",
    "                # Make sure they dislike at least one game\n",
    "                if -1 in user_info_matrix_reduced[index].data :\n",
    "                    # Log 'em!\n",
    "                    test_user_indices.append(index)\n",
    "        # Log 'em!\n",
    "        checked_indices.add(index)\n",
    "    \n",
    "    return test_user_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly remove one or more game(s) from each, and save as a list of rows.\n",
    "\n",
    "def create_test_rows(test_user_indices) :\n",
    "    \"\"\"\n",
    "    Takes a list of reduced user matrix indices (test users)\n",
    "    Returns 3 items:\n",
    "    1. A list of those users' rows with the most- and least- liked games removed\n",
    "    2. A list of those users' most-liked games (in matching index order)\n",
    "    3. A list of those users' least-liked games (in matching index order)\n",
    "    \"\"\"\n",
    "\n",
    "    test_rows = []\n",
    "    liked_games = []\n",
    "    disliked_games = []\n",
    "\n",
    "    for test_user in test_user_indices :\n",
    "        current_row = user_info_matrix_reduced[test_user]\n",
    "\n",
    "        # Pick a game they LIKED VERY MUCH to remove\n",
    "        liked_game = np.argmax(current_row.data)\n",
    "\n",
    "        # Pick a game they HATED to remove.\n",
    "        # It's possible that all values are positive, in which case this variable will\n",
    "        # have no meaning. We will check that at the evaluation phase.\n",
    "        # For now, we'll pull the value no matter what to perserve index relationships.\n",
    "        disliked_game = np.argmin(current_row.data)\n",
    "\n",
    "        # Save the values for evaluation\n",
    "        liked = (test_user, current_row.indices[liked_game], current_row.data[liked_game])\n",
    "        liked_games.append(liked)\n",
    "        disliked = (test_user, current_row.indices[disliked_game], current_row.data[disliked_game])\n",
    "        disliked_games.append(disliked)\n",
    "\n",
    "        # Remove the values\n",
    "\n",
    "        lil_row = current_row.tolil()\n",
    "        lil_row[0, liked[1]] = 0\n",
    "        lil_row[0, disliked[1]] = 0\n",
    "        current_row = lil_row.tocsr()\n",
    "        current_row.eliminate_zeros()\n",
    "\n",
    "        # Add it to the list\n",
    "        test_rows.append(current_row)\n",
    "        \n",
    "    return test_rows, liked_games, disliked_games\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "\n",
    "# Checks to see if POSITIVE game is in top X recs: +\n",
    "# Checks to see if NEGATIVE game is in recs at all: -\n",
    "\n",
    "def binary_evaluator(results, verbose=False) :\n",
    "    \"\"\"\"\n",
    "    Takes a list of tuples with the schema:\n",
    "        1. Series of recommendations (key=app_id, value=utility score)\n",
    "        2. app_id of favorite game\n",
    "        3. app_id of least favorite game\n",
    "\n",
    "    Evaluates the recommendations in each tuple by:\n",
    "        Adding 1 to the overall score if the favorite game is recommended\n",
    "        Subtracting 1 from the overall score if the least favorite game is recommended\n",
    "    \n",
    "    Returns the score as an int\n",
    "    \"\"\"\n",
    "\n",
    "    good = []\n",
    "    bad = []\n",
    "\n",
    "    for result in results :\n",
    "        if result[1] in result[0].index :\n",
    "            good.append(1)\n",
    "        if (result[2] != result[1]) and (result[2] in result[0].index) :\n",
    "            bad.append(1)\n",
    "    \n",
    "    validated = sum(good)\n",
    "    disproved = sum(bad)\n",
    "    score = validated - disproved\n",
    "\n",
    "    print(f\"Validated recommendations: {validated}\")\n",
    "    print(f\"Disproved recommendations: {disproved}\")\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on each modified profile\n",
    "\n",
    "\n",
    "def run_a_test(test_users=50, evaluator=binary_evaluator, similar_user_limit=50, collab_filter_limit=50, \\\n",
    "               content_filter_limit=50, double_bonus=0, popular_bias=0, ratio=0.5, recs=10, \\\n",
    "               testing=True, verbose=False, show_result=False) :\n",
    "    \n",
    "    # Generate X test user indices\n",
    "    test_user_indices = get_test_users(test_users)\n",
    "\n",
    "    test_rows, liked_games, disliked_games = create_test_rows(test_user_indices)\n",
    "\n",
    "    # test_user_full_indices = [user_reduced_index_to_full_index[user] for user in test_user_indices]\n",
    "    results = []\n",
    "\n",
    "    params = {\n",
    "        \"test_user_indices\":test_user_indices,\n",
    "        \"test_user_rows\":test_rows,\n",
    "        \"similar_user_limit\":similar_user_limit,\n",
    "        \"collab_filter_limit\":collab_filter_limit,\n",
    "        \"content_filter_limit\":content_filter_limit,\n",
    "        \"double_bonus\":double_bonus,\n",
    "        \"popular_bias\":popular_bias,\n",
    "        \"ratio\":ratio,\n",
    "        \"recs\":recs,\n",
    "        \"verbose\":verbose,\n",
    "        \"show_result\":show_result,\n",
    "        \"testing\":testing\n",
    "        }\n",
    "\n",
    "    for i in range(len(test_user_indices)) :\n",
    "        result = get_recs(test_user_indices[i], **params)\n",
    "        results.append((result, \\\n",
    "                        game_to_col_index.inverse[liked_games[i][1]], \\\n",
    "                        game_to_col_index.inverse[disliked_games[i][1]]))\n",
    "        \n",
    "    score = evaluator(results)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Commented out so that running the notebook skips directly to testing/evaluation\n",
    "\n",
    "# test_params = {\n",
    "#     \"test_users\":50,\n",
    "#     \"evaluator\":binary_evaluator,\n",
    "#     \"similar_user_limit\":50,\n",
    "#     \"collab_filter_limit\":50,\n",
    "#     \"content_filter_limit\":50,\n",
    "#     \"double_bonus\":2,\n",
    "#     \"popular_bias\":3,\n",
    "#     \"ratio\":0.2,\n",
    "#     \"recs\":20,\n",
    "#     \"testing\":True,\n",
    "#     \"verbose\":False,\n",
    "#     \"show_result\":True\n",
    "# }\n",
    "\n",
    "# run_a_test(**test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O   P   T   I   M   I   Z   E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boptimize(test_users=50, evaluator=binary_evaluator, n_iter=4, init_points=10, verbose=False, show_result=False) :\n",
    "    \n",
    "    # We'll define our test set here, so the Bayesian bit below will\n",
    "    # execute on the same subset each time.\n",
    "\n",
    "    # Generate X test user indices\n",
    "    test_user_indices = get_test_users(test_users)\n",
    "\n",
    "    # Generate test rows\n",
    "    test_rows, liked_games, disliked_games = create_test_rows(test_user_indices)\n",
    "\n",
    "\n",
    "    # Define the scoring function within the main function so that it has native access to variables\n",
    "    def bayes_test(test_user_indices=test_user_indices, liked_games=liked_games, \\\n",
    "               disliked_games=disliked_games, test_rows=test_rows, evaluator=evaluator, \\\n",
    "               similar_user_limit=50, collab_filter_limit=50, \\\n",
    "               content_filter_limit=50, double_bonus=0, popular_bias=0, ratio=0.5, \\\n",
    "               recs=10, testing=True, verbose=verbose, show_result=show_result) :\n",
    "    \n",
    "        params = {\n",
    "        \"test_user_indices\":test_user_indices,\n",
    "        \"test_user_rows\":test_rows,\n",
    "        \"similar_user_limit\":int(similar_user_limit),\n",
    "        \"collab_filter_limit\":int(collab_filter_limit),\n",
    "        \"content_filter_limit\":int(content_filter_limit),\n",
    "        \"double_bonus\":double_bonus,\n",
    "        \"popular_bias\":popular_bias,\n",
    "        \"ratio\":ratio,\n",
    "        \"recs\":int(recs),\n",
    "        \"verbose\":verbose,\n",
    "        \"show_result\":show_result,\n",
    "        \"testing\":testing\n",
    "        }\n",
    "        \n",
    "        results = []\n",
    "\n",
    "        for i in range(len(test_user_indices)) :\n",
    "            result = get_recs(test_user_indices[i], **params)\n",
    "            results.append((result, \\\n",
    "                            game_to_col_index.inverse[liked_games[i][1]], \\\n",
    "                            game_to_col_index.inverse[disliked_games[i][1]]))\n",
    "            \n",
    "        score = evaluator(results)\n",
    "        print(score)\n",
    "\n",
    "        return score\n",
    "\n",
    "\n",
    "    # Prepare params for Bayes\n",
    "    param_bounds = {\n",
    "        \"similar_user_limit\":(250, 250),\n",
    "        \"collab_filter_limit\":(100, 125),\n",
    "        \"content_filter_limit\":(30, 40),\n",
    "        \"double_bonus\":(1.5, 2.3),\n",
    "        \"popular_bias\":(1.3, 2.5),\n",
    "        \"ratio\":(0.4, 0.8),\n",
    "        \"recs\":(20, 20),\n",
    "        }\n",
    "    \n",
    "    # Execute\n",
    "    optimizer = BayesianOptimization(f=bayes_test, pbounds=param_bounds, random_state=42)\n",
    "    optimizer.maximize(init_points=init_points, n_iter=n_iter)\n",
    "    best_params = optimizer.max\n",
    "    print(best_params)\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran the following cell many times, recording the result each time.\n",
    "\n",
    "This final iteration represents a honing-in on the most optimal parameters.\n",
    "\n",
    "A fuller discussion will be the forthcoming project report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boptimize(test_users=100, n_iter=15, init_points=8, show_result=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "While the bulk of the conclusions and analysis will be in the forthcoming presentation step, we can see by the 'target' score that we are able to games that the user will enjoy much more frequently than games the user will not enjoy, and that the optimal parameters for our evaluation function are as follows (I had to remove the outputs to make the notebook readable):  \n",
    "\n",
    "{'target': 13.0,  \n",
    " 'params': {'collab_filter_limit': 103.48734651630105,  \n",
    "  'content_filter_limit': 32.921446485352185,  \n",
    "  'double_bonus': 1.7930894746349533,  \n",
    "  'popular_bias': 1.8472839810604431,  \n",
    "  'ratio': 0.7140703845572055,  \n",
    "  'recs': 20.0,  \n",
    "  'similar_user_limit': 250.0}}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
