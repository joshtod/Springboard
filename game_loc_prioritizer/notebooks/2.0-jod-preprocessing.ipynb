{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Uses the following data:  \n",
    "1. games_df, a table of general information about (almost) all Steam games\n",
    "2. review_table, a table of 6+million reviews scraped from the Steam store, listing the user, game, etc\n",
    "3. recently_played_df, a table of users' recently played games with playtimes\n",
    "\n",
    "Accomplishes the following:\n",
    "1. Generate tables containing vectors for every game and every user. Our inputs will be limited to items in this table.\n",
    "2. Generate reduced tables containing vectors of only the games and users that have rich enough info to be useful for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bidict import bidict\n",
    "\n",
    "import pickle\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import coo_matrix, csr_matrix, lil_matrix, save_npz\n",
    "\n",
    "%store -r tags_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "\n",
    "with open('../data/interim/1 - Games DF - Wrangled.pkl', 'rb') as file :\n",
    "    games_df = pickle.load(file)\n",
    "\n",
    "review_table = pq.read_table('../data/interim/cleaned_reviews.parquet')\n",
    "\n",
    "with open('../data/interim/recently_played_cleaned.pkl', 'rb') as file :\n",
    "    recently_played_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make games vectors/matrices\n",
    "\n",
    "We'll produce one matrix with all known games. This will be used to vectorize input.  \n",
    "  \n",
    "Then we'll produce a matrix that contains only those games with sufficient information to be subjects of recommendation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>tag_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>730</td>\n",
       "      <td>[FPS, Shooter, Multiplayer, Competitive, Actio...</td>\n",
       "      <td>[FPS, Shooter, Multiplayer, Competitive, Actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>553850</td>\n",
       "      <td>[Action, Online Co-Op, Multiplayer, Third-Pers...</td>\n",
       "      <td>[Action, Online Co-Op, Third-Person Shooter, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1086940</td>\n",
       "      <td>[RPG, Choices Matter, Story Rich, Character Cu...</td>\n",
       "      <td>[RPG, Choices Matter, Story Rich, Character Cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1245620</td>\n",
       "      <td>[Souls-like, Dark Fantasy, Open World, RPG, Di...</td>\n",
       "      <td>[Souls-like, Dark Fantasy, Open World, RPG, Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1623730</td>\n",
       "      <td>[Multiplayer, Open World, Survival, Creature C...</td>\n",
       "      <td>[Multiplayer, Open World, Survival, Creature C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    app_id                                               tags  \\\n",
       "0      730  [FPS, Shooter, Multiplayer, Competitive, Actio...   \n",
       "1   553850  [Action, Online Co-Op, Multiplayer, Third-Pers...   \n",
       "2  1086940  [RPG, Choices Matter, Story Rich, Character Cu...   \n",
       "3  1245620  [Souls-like, Dark Fantasy, Open World, RPG, Di...   \n",
       "4  1623730  [Multiplayer, Open World, Survival, Creature C...   \n",
       "\n",
       "                                            tag_list  \n",
       "0  [FPS, Shooter, Multiplayer, Competitive, Actio...  \n",
       "1  [Action, Online Co-Op, Third-Person Shooter, M...  \n",
       "2  [RPG, Choices Matter, Story Rich, Character Cu...  \n",
       "3  [Souls-like, Dark Fantasy, Open World, RPG, Di...  \n",
       "4  [Multiplayer, Open World, Survival, Creature C...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isolate the info we'll use for the vectors\n",
    "games_df_tags_only = games_df[['app_id', 'tags', 'tag_list']]\n",
    "games_df_tags_only.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a handy dict for the app_ids and their new indexes\n",
    "game_to_full_index = bidict()\n",
    "for index, row in games_df_tags_only.iterrows() :\n",
    "    game_to_full_index[index] = row['app_id']\n",
    "game_to_full_index = game_to_full_index.inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our list of columns\n",
    "used_tags = set(tags_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 'FPS', 1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare our sparse matrix\n",
    "# NOTE: We will weight PRIMARY tags more strongly than non-primary tags.\n",
    "\n",
    "weight_ratio = 0.8\n",
    "\n",
    "matrix_values = []\n",
    "\n",
    "for index, row in games_df_tags_only.iterrows() :\n",
    "    skips = set()\n",
    "    for tag in row['tags'] :\n",
    "        skips.add(tag)\n",
    "        tup = (index, tag, 1)\n",
    "        matrix_values.append(tup)\n",
    "    for tag in row['tag_list'] :\n",
    "        if tag not in skips :\n",
    "                    tup = (index, tag, weight_ratio)\n",
    "                    matrix_values.append(tup)\n",
    "\n",
    "matrix_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make the matrix, we must index our tags.\n",
    "tag_to_col_index = bidict()\n",
    "i = 0\n",
    "for value in tags_dict.values() :\n",
    "    tag_to_col_index[value] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the matrix\n",
    "\n",
    "rows = [row[0] for row in matrix_values]\n",
    "columns = [tag_to_col_index[row[1]] for row in matrix_values]\n",
    "values = [row[2] for row in matrix_values]\n",
    "\n",
    "matrix_row_count = max(rows)+1\n",
    "matrix_col_count = max(columns)+1\n",
    "\n",
    "game_tags_matrix = coo_matrix((values, (rows, columns)), shape=(matrix_row_count, matrix_col_count))\n",
    "game_tags_matrix = csr_matrix(game_tags_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good job, everybody! Let's save it and move on.\n",
    "save_npz('../data/processed/full_game_tag_matrix.npz', game_tags_matrix)\n",
    "\n",
    "# And also the index dicts.\n",
    "with open('../data/processed/tag_to_col_index.pkl', \"wb\") as file :\n",
    "    pickle.dump(tag_to_col_index, file)\n",
    "\n",
    "with open('../data/processed/game_to_full_index.pkl', \"wb\") as file :\n",
    "    pickle.dump(game_to_full_index, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we subset this matrix to include only games with 10+ tags.\n",
    "\n",
    "This index will be smaller, but we must be careful to note the original index values. That's the only way we can relate the rows in this matrix to any other matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_counts = pd.Series(game_tags_matrix.getnnz(axis=1))\n",
    "can_keep = nonzero_counts >= 10\n",
    "game_tags_matrix_reduced = game_tags_matrix[can_keep]\n",
    "\n",
    "## This creates a dict with:\n",
    "##  KEYS == reduced matrix index\n",
    "##  VALUES == corresponding full matrix index\n",
    "game_reduced_index_to_full_index = bidict()\n",
    "i=0\n",
    "for index, value in can_keep.items() :\n",
    "    if value==True :\n",
    "        game_reduced_index_to_full_index[i]=index\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save! That! Matrix!\n",
    "save_npz('../data/processed/reduced_game_tag_matrix.npz', game_tags_matrix_reduced)\n",
    "\n",
    "# And the dict, of course.\n",
    "with open('../data/processed/game_reduced_index_to_full_index.pkl', 'wb') as file :\n",
    "    pickle.dump(game_reduced_index_to_full_index, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we make the users matrices..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4181501 entries, 0 to 4181500\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Dtype \n",
      "---  ------       ----- \n",
      " 0   user         object\n",
      " 1   app_id       int64 \n",
      " 2   playtime_2w  int64 \n",
      " 3   playtime_f   int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 127.6+ MB\n"
     ]
    }
   ],
   "source": [
    "recently_played_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6747619, 11)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100894"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because our games_df does not contain every single game on Steam, it's possible\n",
    "# that a game will be touched in a review or recently_played about which we cannot\n",
    "# make inference.\n",
    "# Let's make a set of all usable games to help limit our tables to legal values.\n",
    "usable_app_ids = set(games_df['app_id'].values)\n",
    "len(usable_app_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3593525 entries, 0 to 3593524\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Dtype \n",
      "---  ------       ----- \n",
      " 0   user         object\n",
      " 1   app_id       int64 \n",
      " 2   playtime_2w  int64 \n",
      " 3   playtime_f   int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 109.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Now let's reduce the above datasets to only those which touch usable games.\n",
    "recently_played_df = recently_played_df[recently_played_df['app_id'].isin(usable_app_ids)].reset_index(drop=True)\n",
    "recently_played_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5726093 entries, 0 to 5726092\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   user             object \n",
      " 1   app_id           int64  \n",
      " 2   positive         int64  \n",
      " 3   total_playtime   float64\n",
      " 4   review_playtime  float64\n",
      " 5   text             object \n",
      " 6   helpful_count    int64  \n",
      " 7   review_date      object \n",
      " 8   edit_date        object \n",
      " 9   date_scraped     object \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 436.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# To subset the review_talbe, we'll have to pandacize it first.\n",
    "\n",
    "review_df = review_table.to_pandas()\n",
    "review_df = review_df[review_df['app_id'].isin(usable_app_ids)].reset_index(drop=True)\n",
    "review_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should save processed versions of these for use in the modeling notebook.\n",
    "usable_review_table = pa.Table.from_pandas(review_df)\n",
    "pq.write_table(usable_review_table, '../data/processed/usable_review_table.parquet')\n",
    "\n",
    "with open('../data/processed/usable_recently_played.pkl', 'wb') as file :\n",
    "    pickle.dump(recently_played_df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The two tables above contain different but overlapping sets of users.\n",
    "# In order to combine them into a single users matrix, we must first create\n",
    "# a unified index for all touched users.\n",
    "\n",
    "recently_users = set(recently_played_df['user'].values)\n",
    "review_users = set(review_table['user'].to_pylist())\n",
    "touched_users = recently_users | review_users\n",
    "\n",
    "user_to_full_index = bidict()\n",
    "i=0\n",
    "for user in touched_users :\n",
    "    user_to_full_index[user] = i\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need a unified index for games.\n",
    "\n",
    "recently_games =set(recently_played_df['app_id'].values)\n",
    "review_games = set(review_table['app_id'].to_pylist())\n",
    "touched_games = recently_games | review_games\n",
    "\n",
    "game_to_col_index = bidict()\n",
    "i=0\n",
    "for game in touched_games :\n",
    "    game_to_col_index[game] = i\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's prepare our points.\n",
    "recently_played_points = recently_played_df.apply( \\\n",
    "                                lambda row: (user_to_full_index[row['user']], game_to_col_index[row['app_id']], 0.5), axis=1) \\\n",
    "                                .tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we'll have to update this matrix in a sec, let's make it a lil_matrix first.\n",
    "\n",
    "user_info_matrix = lil_matrix((len(touched_users), len(touched_games)), dtype=float)\n",
    "\n",
    "for point in recently_played_points :\n",
    "    user_info_matrix[point[0], point[1]] = point[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's prepare the review data to update that matrix.\n",
    "\n",
    "positive_reviews = review_df[review_df['positive']==1][['user', 'app_id']]\n",
    "negative_reviews = review_df[review_df['positive']==0][['user', 'app_id']]\n",
    "\n",
    "positive_points = positive_reviews.apply( \\\n",
    "                lambda row: (user_to_full_index[row['user']], game_to_col_index[row['app_id']], 1), axis=1) \\\n",
    "                .tolist()\n",
    "                                \n",
    "negative_points = negative_reviews.apply( \\\n",
    "                lambda row: (user_to_full_index[row['user']], game_to_col_index[row['app_id']], -1), axis=1) \\\n",
    "                .tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now, we update the matrix.\n",
    "\n",
    "for point in positive_points :\n",
    "    user_info_matrix[point[0], point[1]] = point[2]\n",
    "\n",
    "for point in negative_points :\n",
    "    user_info_matrix[point[0], point[1]] = point[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just for funsies, make it the same format as our games matrix.\n",
    "user_info_matrix = user_info_matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save! That! Matrix!\n",
    "save_npz('../data/processed/user_info_matrix.npz', user_info_matrix)\n",
    "\n",
    "# And the dicts, of course.\n",
    "with open('../data/processed/user_to_full_index.pkl', 'wb') as file :\n",
    "    pickle.dump(user_to_full_index, file)\n",
    "\n",
    "with open('../data/processed/game_to_col_index.pkl', 'wb') as file :\n",
    "    pickle.dump(game_to_col_index, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.887354e+06\n",
       "mean     4.779766e+00\n",
       "std      7.041132e+00\n",
       "min      0.000000e+00\n",
       "25%      1.000000e+00\n",
       "50%      3.000000e+00\n",
       "75%      6.000000e+00\n",
       "max      5.517000e+03\n",
       "dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we create a subset of the matrix that contains only users with enough info for prediction.\n",
    "# Where should we put the threshold?\n",
    "\n",
    "nonzero_counts = pd.Series(user_info_matrix.getnnz(axis=1))\n",
    "nonzero_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll arbitrarily choose 5. Sue me! I dare you.\n",
    "\n",
    "can_keep = nonzero_counts >= 5\n",
    "user_info_matrix_reduced = user_info_matrix[can_keep]\n",
    "\n",
    "## This creates a dict with:\n",
    "##  KEYS == reduced matrix index\n",
    "##  VALUES == corresponding full matrix index\n",
    "user_reduced_index_to_full_index = bidict()\n",
    "i=0\n",
    "for index, value in can_keep.items() :\n",
    "    if value==True :\n",
    "        user_reduced_index_to_full_index[i]=index\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save! That! Matrix!\n",
    "save_npz('../data/processed/user_info_matrix_reduced.npz', user_info_matrix_reduced)\n",
    "\n",
    "# etc etc\n",
    "with open('../data/processed/user_reduced_index_to_full_index.pkl', 'wb') as file :\n",
    "    pickle.dump(user_reduced_index_to_full_index, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At time of inference, the top X consine similarity users' rows will be called up, and the most common games not already played by the user will be recommended."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
