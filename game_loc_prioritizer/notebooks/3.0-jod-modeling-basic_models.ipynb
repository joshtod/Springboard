{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We're Ready for the Runway\n",
    "\n",
    "As a control, I'm just gonna linearly regress right quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/processed/2 - Games DF - PreProcessed Features', 'rb') as file :\n",
    "    X = pickle.load(file)\n",
    "\n",
    "with open('../data/processed/2 - Games DF - PreProcessed Targets', 'rb') as file :\n",
    "    y_universe = pickle.load(file)\n",
    "\n",
    "%store -r relevant_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're All Agnostics Now!\n",
    "---\n",
    "\n",
    "I'll choose the \"agnostic\" case for our initial analysis, and calculate basic vanilla lasso scores for all languages under that condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let me get a persistent set of indexes for my train/test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_universe, test_size=0.2)\n",
    "\n",
    "training_indexes = y_train.index\n",
    "testing_indexes = y_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 572 entries, 553850 to 1962660\n",
      "Data columns (total 54 columns):\n",
      " #   Column                   Non-Null Count  Dtype\n",
      "---  ------                   --------------  -----\n",
      " 0   2D                       572 non-null    int64\n",
      " 1   3D                       572 non-null    int64\n",
      " 2   Action                   572 non-null    int64\n",
      " 3   Action-Adventure         572 non-null    int64\n",
      " 4   Adventure                572 non-null    int64\n",
      " 5   Anime                    572 non-null    int64\n",
      " 6   Atmospheric              572 non-null    int64\n",
      " 7   Building                 572 non-null    int64\n",
      " 8   Casual                   572 non-null    int64\n",
      " 9   Character Customization  572 non-null    int64\n",
      " 10  Choices Matter           572 non-null    int64\n",
      " 11  Co-op                    572 non-null    int64\n",
      " 12  Colorful                 572 non-null    int64\n",
      " 13  Comedy                   572 non-null    int64\n",
      " 14  Controller               572 non-null    int64\n",
      " 15  Cute                     572 non-null    int64\n",
      " 16  Dark                     572 non-null    int64\n",
      " 17  Difficult                572 non-null    int64\n",
      " 18  Exploration              572 non-null    int64\n",
      " 19  FPS                      572 non-null    int64\n",
      " 20  Family Friendly          572 non-null    int64\n",
      " 21  Fantasy                  572 non-null    int64\n",
      " 22  Female Protagonist       572 non-null    int64\n",
      " 23  First-Person             572 non-null    int64\n",
      " 24  Free to Play             572 non-null    int64\n",
      " 25  Funny                    572 non-null    int64\n",
      " 26  Gore                     572 non-null    int64\n",
      " 27  Great Soundtrack         572 non-null    int64\n",
      " 28  Horror                   572 non-null    int64\n",
      " 29  Indie                    572 non-null    int64\n",
      " 30  Management               572 non-null    int64\n",
      " 31  Multiplayer              572 non-null    int64\n",
      " 32  Online Co-Op             572 non-null    int64\n",
      " 33  Open World               572 non-null    int64\n",
      " 34  Pixel Graphics           572 non-null    int64\n",
      " 35  Platformer               572 non-null    int64\n",
      " 36  Psychological Horror     572 non-null    int64\n",
      " 37  Puzzle                   572 non-null    int64\n",
      " 38  PvP                      572 non-null    int64\n",
      " 39  RPG                      572 non-null    int64\n",
      " 40  Realistic                572 non-null    int64\n",
      " 41  Relaxing                 572 non-null    int64\n",
      " 42  Retro                    572 non-null    int64\n",
      " 43  Sandbox                  572 non-null    int64\n",
      " 44  Sci-fi                   572 non-null    int64\n",
      " 45  Shooter                  572 non-null    int64\n",
      " 46  Simulation               572 non-null    int64\n",
      " 47  Singleplayer             572 non-null    int64\n",
      " 48  Story Rich               572 non-null    int64\n",
      " 49  Strategy                 572 non-null    int64\n",
      " 50  Survival                 572 non-null    int64\n",
      " 51  Tactical                 572 non-null    int64\n",
      " 52  Third Person             572 non-null    int64\n",
      " 53  Violent                  572 non-null    int64\n",
      "dtypes: int64(54)\n",
      "memory usage: 245.8 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso\n",
    "\n",
    "Yee-haw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german: -0.01494\n",
      "french: -0.00037\n",
      "spanish: -0.05411\n",
      "brazilian: -0.02398\n",
      "russian: -0.00679\n",
      "italian: -0.00807\n",
      "schinese: -0.00217\n",
      "japanese: -0.00047\n",
      "koreana: -0.02825\n",
      "polish: -0.00027\n",
      "english: -0.00945\n"
     ]
    }
   ],
   "source": [
    "naive_scores = {}\n",
    "\n",
    "for lang in relevant_langs :\n",
    "\n",
    "    # Create the target variable for this lang\n",
    "    y = {}\n",
    "    for index, row in y_universe.iterrows() :\n",
    "        y[index] = row['comment_diff_agnostic'][lang]\n",
    "    y = pd.Series(y)\n",
    "\n",
    "    # Generate our target splits based on the persistent train/test index split\n",
    "    y_train = y[training_indexes]\n",
    "    y_test = y[testing_indexes]\n",
    "\n",
    "    # Run the model\n",
    "    model = Lasso()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Score it and log it\n",
    "    score = r2_score(y_test, y_pred)\n",
    "    naive_scores[lang] = score\n",
    "    print(f\"{lang}: {round(score, 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are weak, but the vast majority did better than chance. That might mean our idea is not complete bunk.\n",
    "\n",
    "Let's see if hyperparameter tuning helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, define the function we'll use to tune our alpha\n",
    "def Lasso_eval(alpha) :\n",
    "    params = {\"alpha\":alpha}\n",
    "    model = Lasso(max_iter=100000, **params)\n",
    "    score = cross_val_score(model, X, y, cv=5).mean()\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german: -0.0023 (improvement: 0.0, alpha: 86.45)\n",
      "french: -0.00027 (improvement: 0.0, alpha: 17.04)\n",
      "spanish: -0.00481 (improvement: 0.0, alpha: 84.49)\n",
      "brazilian: -0.00135 (improvement: 0.0, alpha: 67.34)\n",
      "russian: -0.00141 (improvement: 0.001047, alpha: 0.01)\n",
      "italian: -0.00065 (improvement: 0.0, alpha: 41.68)\n",
      "schinese: 0.05513 (improvement: 0.055235, alpha: 0.01)\n",
      "japanese: -0.0 (improvement: 0.0, alpha: 37.53)\n",
      "koreana: -0.01662 (improvement: 0.0, alpha: 82.02)\n",
      "polish: -0.00023 (improvement: 0.0, alpha: 29.98)\n",
      "english: -0.00132 (improvement: 0.0, alpha: 4.28)\n"
     ]
    }
   ],
   "source": [
    "# Now, do run the model again, optimizing on each lang\n",
    "\n",
    "for lang in relevant_langs :\n",
    "\n",
    "    # Create the target variable for this lang\n",
    "    y = {}\n",
    "    for index, row in y_universe.iterrows() :\n",
    "        y[index] = row['comment_diff_agnostic'][lang]\n",
    "    y = pd.Series(y)\n",
    "\n",
    "    # Run some optimization\n",
    "    param_bounds = {\"alpha\":(0.01, 100)}\n",
    "    optimal = BayesianOptimization(Lasso_eval, param_bounds, verbose=False, allow_duplicate_points=True)\n",
    "    optimal.maximize(20, 20)\n",
    "    bayes_alpha = optimal.max['params']['alpha']\n",
    "\n",
    "    # Generate our target splits based on the persistent train/test index split\n",
    "    y_train = y[training_indexes]\n",
    "    y_test = y[testing_indexes]\n",
    "\n",
    "    # Run the model\n",
    "    model = Lasso(max_iter=100000, alpha=bayes_alpha)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Score it and log it\n",
    "    score = r2_score(y_test, y_pred)\n",
    "    rounded_score = round(score, 5)\n",
    "    improvement = round(score - naive_scores[lang], 6)\n",
    "    rounded_alpha = round(optimal.max['params']['alpha'], 2)\n",
    "    print(f\"{lang}: {rounded_score} (improvement: {improvement}, alpha: {rounded_alpha})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope.\n",
    "\n",
    "I can only assume this is because the variability in the data makes the cv split scores so random that the tuned parameters end up essentially random as well.\n",
    "\n",
    "So that's one strike AGAINST our idea, though I'd argue that the uniformly weak positive of the naive parameter model indicates that we are onto *something*, no matter how slight.\n",
    "\n",
    "Perhaps the relationships between the tags can be better captured by other models. Let's try gradient boosting next, and then neural nets.\n",
    "\n",
    "Huzzah! Onward!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Get Boosted\n",
    "\n",
    "Honestly I feel like we might be too sparse for this to be super useful, but let's try try"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
