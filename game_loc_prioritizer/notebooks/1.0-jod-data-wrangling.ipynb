{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangling & Cleaning\n",
    "---\n",
    "\n",
    "This notebook includes the following steps:\n",
    "\n",
    "1. Load the data from the 0 json\n",
    "2. Fixes data types\n",
    "3. Checks the data for reasonableness and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load up our scraped dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17503 entries, 0 to 17502\n",
      "Data columns (total 42 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   app_id                   17503 non-null  int64  \n",
      " 1   title                    17503 non-null  object \n",
      " 2   release_date             17503 non-null  object \n",
      " 3   positive_review_percent  17484 non-null  float64\n",
      " 4   number_of_reviews        17484 non-null  float64\n",
      " 5   price                    17473 non-null  float64\n",
      " 6   game_page_link           17503 non-null  object \n",
      " 7   tags                     17503 non-null  object \n",
      " 8   date_scraped             17503 non-null  object \n",
      " 9   developer                17501 non-null  object \n",
      " 10  publisher                17427 non-null  object \n",
      " 11  description              17503 non-null  object \n",
      " 12  interface_languages      17503 non-null  object \n",
      " 13  full_audio_languages     17503 non-null  object \n",
      " 14  subtitles_languages      17503 non-null  object \n",
      " 15  english                  17503 non-null  int64  \n",
      " 16  schinese                 17488 non-null  float64\n",
      " 17  tchinese                 2148 non-null   float64\n",
      " 18  japanese                 17488 non-null  float64\n",
      " 19  koreana                  17488 non-null  float64\n",
      " 20  thai                     2148 non-null   float64\n",
      " 21  bulgarian                2148 non-null   float64\n",
      " 22  czech                    2148 non-null   float64\n",
      " 23  danish                   2148 non-null   float64\n",
      " 24  german                   17488 non-null  float64\n",
      " 25  spanish                  17488 non-null  float64\n",
      " 26  latam                    2148 non-null   float64\n",
      " 27  greek                    2148 non-null   float64\n",
      " 28  french                   17488 non-null  float64\n",
      " 29  italian                  17488 non-null  float64\n",
      " 30  indonesian               2148 non-null   float64\n",
      " 31  hungarian                2148 non-null   float64\n",
      " 32  dutch                    2148 non-null   float64\n",
      " 33  norwegian                2148 non-null   float64\n",
      " 34  polish                   17488 non-null  float64\n",
      " 35  brazilian                17488 non-null  float64\n",
      " 36  romanian                 2148 non-null   float64\n",
      " 37  russian                  17488 non-null  float64\n",
      " 38  finnish                  2148 non-null   float64\n",
      " 39  swedish                  2148 non-null   float64\n",
      " 40  turkish                  2148 non-null   float64\n",
      " 41  vietnamese               2148 non-null   float64\n",
      "dtypes: float64(29), int64(2), object(11)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "with open('../data/raw/0 - Scraped Games DF.pkl', 'rb') as file :\n",
    "    games_df = pickle.load(file)\n",
    "\n",
    "games_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>positive_review_percent</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>price</th>\n",
       "      <th>game_page_link</th>\n",
       "      <th>tags</th>\n",
       "      <th>date_scraped</th>\n",
       "      <th>developer</th>\n",
       "      <th>...</th>\n",
       "      <th>dutch</th>\n",
       "      <th>norwegian</th>\n",
       "      <th>polish</th>\n",
       "      <th>brazilian</th>\n",
       "      <th>romanian</th>\n",
       "      <th>russian</th>\n",
       "      <th>finnish</th>\n",
       "      <th>swedish</th>\n",
       "      <th>turkish</th>\n",
       "      <th>vietnamese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>730</td>\n",
       "      <td>Counter-Strike 2</td>\n",
       "      <td>Aug 21, 2012</td>\n",
       "      <td>0.87</td>\n",
       "      <td>7908923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://store.steampowered.com/app/730/Counter...</td>\n",
       "      <td>[1663, 1774, 3859, 3878, 19, 5711, 5055]</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>[Valve]</td>\n",
       "      <td>...</td>\n",
       "      <td>2207191.0</td>\n",
       "      <td>2203326.0</td>\n",
       "      <td>436547.0</td>\n",
       "      <td>452516.0</td>\n",
       "      <td>52405.0</td>\n",
       "      <td>2074889.0</td>\n",
       "      <td>2234701.0</td>\n",
       "      <td>2245677.0</td>\n",
       "      <td>403681.0</td>\n",
       "      <td>10514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>553850</td>\n",
       "      <td>HELLDIVERSâ„¢ 2</td>\n",
       "      <td>Feb 8, 2024</td>\n",
       "      <td>0.72</td>\n",
       "      <td>124161.0</td>\n",
       "      <td>3999.0</td>\n",
       "      <td>https://store.steampowered.com/app/553850/HELL...</td>\n",
       "      <td>[19, 3843, 3859, 3814, 1685, 1774, 6730]</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>[Arrowhead Game Studios]</td>\n",
       "      <td>...</td>\n",
       "      <td>119001.0</td>\n",
       "      <td>118995.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1349.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2268.0</td>\n",
       "      <td>118689.0</td>\n",
       "      <td>119026.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1086940</td>\n",
       "      <td>Baldur's Gate 3</td>\n",
       "      <td>Aug 3, 2023</td>\n",
       "      <td>0.96</td>\n",
       "      <td>508705.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>https://store.steampowered.com/app/1086940/Bal...</td>\n",
       "      <td>[122, 6426, 1742, 4747, 4325, 14153, 21]</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>[Larian Studios]</td>\n",
       "      <td>...</td>\n",
       "      <td>355432.0</td>\n",
       "      <td>354726.0</td>\n",
       "      <td>6901.0</td>\n",
       "      <td>17285.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40942.0</td>\n",
       "      <td>354812.0</td>\n",
       "      <td>355703.0</td>\n",
       "      <td>6528.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1245620</td>\n",
       "      <td>ELDEN RING</td>\n",
       "      <td>Feb 24, 2022</td>\n",
       "      <td>0.92</td>\n",
       "      <td>579380.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>https://store.steampowered.com/app/1245620/ELD...</td>\n",
       "      <td>[29482, 4604, 1695, 122, 4026, 4231, 1697]</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>[FromSoftware Inc.]</td>\n",
       "      <td>...</td>\n",
       "      <td>402341.0</td>\n",
       "      <td>401950.0</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>23732.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>26978.0</td>\n",
       "      <td>402097.0</td>\n",
       "      <td>402984.0</td>\n",
       "      <td>6953.0</td>\n",
       "      <td>503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1623730</td>\n",
       "      <td>Palworld</td>\n",
       "      <td>Jan 18, 2024</td>\n",
       "      <td>0.94</td>\n",
       "      <td>228380.0</td>\n",
       "      <td>2999.0</td>\n",
       "      <td>https://store.steampowered.com/app/1623730/Pal...</td>\n",
       "      <td>[3859, 1695, 1662, 916648, 1100689, 1702, 1685]</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>[Pocketpair]</td>\n",
       "      <td>...</td>\n",
       "      <td>113556.0</td>\n",
       "      <td>113002.0</td>\n",
       "      <td>1221.0</td>\n",
       "      <td>9384.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6311.0</td>\n",
       "      <td>112952.0</td>\n",
       "      <td>113242.0</td>\n",
       "      <td>1447.0</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    app_id             title  release_date  positive_review_percent  \\\n",
       "0      730  Counter-Strike 2  Aug 21, 2012                     0.87   \n",
       "1   553850     HELLDIVERSâ„¢ 2   Feb 8, 2024                     0.72   \n",
       "2  1086940   Baldur's Gate 3   Aug 3, 2023                     0.96   \n",
       "3  1245620        ELDEN RING  Feb 24, 2022                     0.92   \n",
       "4  1623730          Palworld  Jan 18, 2024                     0.94   \n",
       "\n",
       "   number_of_reviews   price  \\\n",
       "0          7908923.0     0.0   \n",
       "1           124161.0  3999.0   \n",
       "2           508705.0  5999.0   \n",
       "3           579380.0  5999.0   \n",
       "4           228380.0  2999.0   \n",
       "\n",
       "                                      game_page_link  \\\n",
       "0  https://store.steampowered.com/app/730/Counter...   \n",
       "1  https://store.steampowered.com/app/553850/HELL...   \n",
       "2  https://store.steampowered.com/app/1086940/Bal...   \n",
       "3  https://store.steampowered.com/app/1245620/ELD...   \n",
       "4  https://store.steampowered.com/app/1623730/Pal...   \n",
       "\n",
       "                                              tags date_scraped  \\\n",
       "0         [1663, 1774, 3859, 3878, 19, 5711, 5055]   2024-02-23   \n",
       "1         [19, 3843, 3859, 3814, 1685, 1774, 6730]   2024-02-23   \n",
       "2         [122, 6426, 1742, 4747, 4325, 14153, 21]   2024-02-23   \n",
       "3       [29482, 4604, 1695, 122, 4026, 4231, 1697]   2024-02-23   \n",
       "4  [3859, 1695, 1662, 916648, 1100689, 1702, 1685]   2024-02-23   \n",
       "\n",
       "                  developer  ...      dutch  norwegian    polish brazilian  \\\n",
       "0                   [Valve]  ...  2207191.0  2203326.0  436547.0  452516.0   \n",
       "1  [Arrowhead Game Studios]  ...   119001.0   118995.0    1020.0    1349.0   \n",
       "2          [Larian Studios]  ...   355432.0   354726.0    6901.0   17285.0   \n",
       "3       [FromSoftware Inc.]  ...   402341.0   401950.0    6590.0   23732.0   \n",
       "4              [Pocketpair]  ...   113556.0   113002.0    1221.0    9384.0   \n",
       "\n",
       "  romanian    russian    finnish    swedish   turkish  vietnamese  \n",
       "0  52405.0  2074889.0  2234701.0  2245677.0  403681.0     10514.0  \n",
       "1     27.0     2268.0   118689.0   119026.0     317.0        12.0  \n",
       "2     32.0    40942.0   354812.0   355703.0    6528.0        71.0  \n",
       "3    113.0    26978.0   402097.0   402984.0    6953.0       503.0  \n",
       "4     39.0     6311.0   112952.0   113242.0    1447.0       319.0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Standardize our data types\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'relevant_langs' (list)\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "# The numbers in the comment count columns are strings\n",
    "# with extra characters. Let's standardize them as ints.\n",
    "\n",
    "# First, let's get a list of the columns that we need to process.\n",
    "# That's all columns from the comments df and one column from the\n",
    "# original game page scraped df.\n",
    "%store -r top_10_languages\n",
    "%store -r all_languages\n",
    "relevant_langs = top_10_languages.copy()\n",
    "relevant_langs.append('english')\n",
    "%store relevant_langs\n",
    "\n",
    "\n",
    "# We need all our comment counts to be ints.\n",
    "# Some of them failed to scrape - we can almost certainly remove\n",
    "# them without impacting our study, but I would like to check to\n",
    "# make sure something didn't go wrong in our previous step that\n",
    "# caused too many of them to fail.\n",
    "# So, we'll two-birds this.\n",
    "# As we ensure that all the values are ints, we'll remove the\n",
    "# ones that are \"Failed\", and then display the removed indexes.\n",
    "# We also have some games that weren't released at time of\n",
    "# scraping, so we'll just remove those as well at this stage.\n",
    "indexes_to_remove = set()\n",
    "\n",
    "for index, row in games_df.iterrows() :\n",
    "    for language in relevant_langs :\n",
    "        # If the count is \"Failed\", mark it for deletion.\n",
    "        if (row[language] == 'Failed') or (pd.isna(row[language])) :\n",
    "            indexes_to_remove.add(index)\n",
    "        \n",
    "\n",
    "print(len(indexes_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not too bad. Let's just drop them, then integerize.\n",
    "\n",
    "games_df = games_df.drop(indexes_to_remove)\n",
    "games_df = games_df.reset_index(drop=True)\n",
    "\n",
    "for language in relevant_langs :\n",
    "    games_df[language] = games_df[language].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For games that have multiple publishers, developers, etc, they're all stored as one string.\n",
    "# If we want to use this data eventually, we should split it into lists.\n",
    "# Some games don't have publishers or developers, and that's fine.\n",
    "# Oddly, some of them have trailing spaces.\n",
    "for index, row in games_df.iterrows() :\n",
    "    if not row['developer'] :\n",
    "        games_df.at[index, 'developer'] = []\n",
    "    else :\n",
    "        if type(row['developer']) != list :\n",
    "            row['developer'] = row['developer'].split(', ')\n",
    "            # Since the above line changes the str into a list, we can .strip() each item in the list\n",
    "            # with a comprehension.\n",
    "            list_of_developers = [name.strip() for name in row['developer']]\n",
    "            games_df.at[index, 'developer'] = list_of_developers\n",
    "\n",
    "    # And again.\n",
    "    if not row['publisher'] :\n",
    "        games_df.at[index, 'publisher'] = []\n",
    "    else :\n",
    "        if type(row['publisher']) != list :\n",
    "            row['publisher'] = row['publisher'].split(', ')\n",
    "            list_of_publishers = [name.strip() for name in row['publisher']]\n",
    "            games_df.at[index, 'publisher'] = list_of_publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# The tags are also just a string. We need them listed.\n",
    "tags_list = []\n",
    "\n",
    "for index, row in games_df.iterrows() :\n",
    "    if (type(row['tags']) != list) & (row['tags'] != '') :\n",
    "        tags_list = row['tags'].strip('[]').split(',')\n",
    "        games_df.at[index, 'tags'] = tags_list\n",
    "\n",
    "print(type(games_df.loc[0, 'tags']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Same problem for our languages types columns (interface, audio, subitles).\n",
    "\n",
    "for index, row in games_df.iterrows() :\n",
    "    if (type(row['interface_languages']) != list) & (row['interface_languages'] != '') :\n",
    "        languages_list = row['interface_languages'].strip('[]').split(', ')\n",
    "        games_df.at[index, 'interface_languages'] = languages_list\n",
    "    if (type(row['full_audio_languages']) != list) & (row['full_audio_languages'] != '') :\n",
    "        languages_list = row['full_audio_languages'].strip('[]').split(', ')\n",
    "        games_df.at[index, 'full_audio_languages'] = languages_list\n",
    "    if (type(row['subtitles_languages']) != list) & (row['subtitles_languages'] != '') :\n",
    "        languages_list = row['subtitles_languages'].strip('[]').split(', ')\n",
    "        games_df.at[index, 'subtitles_languages'] = languages_list\n",
    "\n",
    "# Check.\n",
    "print(type(games_df.loc[0, 'interface_languages']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'tags_dict' (dict)\n"
     ]
    }
   ],
   "source": [
    "# For future reference, let's create a dictionary of tags codes & their meanings.\n",
    "# We can get that from the search page.\n",
    "# Keys will be the codes. Values will be the names.\n",
    "url = 'https://store.steampowered.com/search'\n",
    "html = urlopen(url)\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "# The relevant data is in this one code block.\n",
    "code_block = soup.find('div', id=\"TagFilter_Container\")\n",
    "\n",
    "# Create the empty dict.\n",
    "tags_dict = {}\n",
    "\n",
    "# Iterate over all 400+ tags described in the code block.\n",
    "for listing in code_block.find_all('div', class_='tab_filter_control_row') :\n",
    "    tag_code = listing.get('data-value')\n",
    "    tag_name = listing.get('data-loc')\n",
    "    tags_dict[tag_code] = tag_name\n",
    "\n",
    "# We'll probably need it later, so let's save it a couple ways.\n",
    "# Weirdly, it's quicker and easier to do this via a DF.\n",
    "tags_dict_df = pd.DataFrame.from_dict(tags_dict, orient='index')\n",
    "tags_dict_df.to_csv('../data/raw/tag_dictionary.csv')\n",
    "%store tags_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement indicator variables\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For language_types, implement pipes (???)\n",
    "# NOTE:dx WHAT DID I MEAN BY THIS??????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Sanity checks\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{7: 15495, 5: 421, 6: 413, 4: 304, 3: 273, 2: 87, 1: 16}\n"
     ]
    }
   ],
   "source": [
    "# Since our tags column is very important to us, let's make sure\n",
    "# that the entries are reasonably comparable.\n",
    "\n",
    "# In order to count the number of tags in each game's tags list,\n",
    "# let's turn that column into a list of lists (by way of a series)\n",
    "# so that we can use a list comprehension to get a list of len()s.\n",
    "series_of_tags_column_values = games_df['tags']\n",
    "list_of_tags_column_values = series_of_tags_column_values.tolist()\n",
    "tags_values_lengths = [len(x) for x in list_of_tags_column_values]\n",
    "\n",
    "# Now we organize the counts into a dictionary, where the keys are\n",
    "# the lengths and the values are the frequencies of those lengths.\n",
    "dict_of_lenghts = {}\n",
    "\n",
    "for length in tags_values_lengths :\n",
    "    if length in dict_of_lenghts :\n",
    "        dict_of_lenghts[length] += 1\n",
    "    else :\n",
    "        dict_of_lenghts[length] = 1\n",
    "\n",
    "print(dict_of_lenghts)\n",
    "\n",
    "# Looks not too bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I discovered that summing the number of comments in the top 10 loc languages + En\n",
    "# as recorded in our DF resulted in a HIGHER comment count than Steam displays (which\n",
    "# is the one we grabbed from Steam as \"number_of_reviews\").\n",
    "\n",
    "# I don't know why that is, but it doesn't really matter. What we want is the RELATIVE\n",
    "# difference in comments per game WITHIN each language, so as long as Steam calculates\n",
    "# the number of comments in each language in a consistent way WITHIN each language, our\n",
    "# method still works.\n",
    "\n",
    "# Thus the \"number_of_reviews\" column may be useless to us, BUT I'm loathe to let go\n",
    "# of any data. Let's keep it for now, and just add a new column that we'll use for our\n",
    "# calculations: \"relevant_langs_review_sum\"\n",
    "\n",
    "games_df['relevant_langs_comments_sum'] = None\n",
    "\n",
    "for index, row in games_df.iterrows() :\n",
    "    games_df.loc[index, 'relevant_langs_comments_sum'] = row[relevant_langs].sum()\n",
    "\n",
    "games_df['relevant_langs_comments_sum'] = games_df['relevant_langs_comments_sum'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This NLP step is pretty complex and not entirely relevant for the ML task at hand, so we'll leave it out for now.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Check for string similarity in all verbal cols.\n",
    "# # In developer and publisher, this could likely find typos.\n",
    "\n",
    "# # First, let's create sets of all the extant developer and publisher names\n",
    "# # as currently typed.\n",
    "\n",
    "# set_of_developer_names = set()\n",
    "\n",
    "# for developers_list in games_df['developer'] :\n",
    "#     for developer in developers_list :\n",
    "#         set_of_developer_names.add(developer)\n",
    "\n",
    "# set_of_publisher_names = set()\n",
    "\n",
    "# for publishers_list in games_df['publisher'] :\n",
    "#     for publisher in publishers_list :\n",
    "#         set_of_publisher_names.add(publisher)\n",
    "\n",
    "# # Now, let's see if any items in that list are super similar to each other.\n",
    "# # This could possibly the the result of a typo.\n",
    "# # Let's first find the MOST similar pair in each set.\n",
    "# # If these pairs are clearly not typos, then it's very likely that there are\n",
    "# # no typos at all.\n",
    "\n",
    "# list_of_developer_similarities = []\n",
    "# listing = []\n",
    "\n",
    "# for developer in set_of_developer_names :\n",
    "#     # Create a set of names to test this name against.\n",
    "#     # We want to avoid testing the name against itself,\n",
    "#     # since that will return a maximum similarity score\n",
    "#     # and make our lives harder.\n",
    "#     # So, we'll create a new set, then drop this name\n",
    "#     # from the set before doing the comparisons.\n",
    "#     testing_set = set_of_developer_names.copy()\n",
    "#     testing_set.remove(developer)\n",
    "#     highest = process.extract(developer, testing_set, limit=1)\n",
    "#     # We need to retain both of the tested strings, while .extract only\n",
    "#     # returns the second one. We'll have to group them manually.\n",
    "#     # Let's also arbitrarily set 90 as the cutoff for similarity.\n",
    "#     if highest[0][1] >= 90 :\n",
    "#         listing = [developer, highest[0][0], highest[0][1]]\n",
    "#         list_of_developer_similarities.append(listing)\n",
    "\n",
    "\n",
    "# # Then we do it all again for publishers.\n",
    "# list_of_publisher_similarities = []\n",
    "\n",
    "# for publisher in set_of_publisher_names :\n",
    "#     testing_set = set_of_publisher_names.copy()\n",
    "#     testing_set.remove(publisher)\n",
    "#     highest = process.extract(publisher, testing_set, limit=1)\n",
    "#     if highest[0][1] >= 90 :\n",
    "#         listing = [publisher, highest[0][0], highest[0][1]]\n",
    "#         list_of_publisher_similarities.append(listing)\n",
    "\n",
    "\n",
    "# # Now we sort the lists by the similarity score.\n",
    "# list_of_developer_similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "# list_of_publisher_similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "\n",
    "# # Let's take a look at some of them... and also get a feel for\n",
    "# # how long these lists are (and therefore how many of these names\n",
    "# # are truly similar).\n",
    "# print('Similar developer names:')\n",
    "# print(list_of_developer_similarities[0:10])\n",
    "# print('Total similarity scores over 90: '+str(len(list_of_developer_similarities)))\n",
    "# print('')\n",
    "# print('Similar publisher names:')\n",
    "# print(list_of_publisher_similarities[0:10])\n",
    "# print('Total similarity scores over 90: '+str(len(list_of_publisher_similarities)))\n",
    "\n",
    "# # Well, what I've learned from this is that the names of developers and publishers\n",
    "# # would be a LOT of work to fix. Since we don't need them for now (they aren't part\n",
    "# # of our key analysis), we can just leave them as-is and clean them later if we need\n",
    "# # them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Determine completeness\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# While I want to keep all the data around just in case, this is a great\n",
    "# point for us to determine whether some rows may not be useful for us.\n",
    "\n",
    "# Our main label is the comment counts per language, so we can safely drop\n",
    "# all rows that have no language-specific comment counts at all.\n",
    "\n",
    "indexes_to_drop = []\n",
    "\n",
    "for index, row in games_df[relevant_langs].iterrows() :\n",
    "    if row.sum() == 0 :\n",
    "        indexes_to_drop.append(index)\n",
    "\n",
    "print(len(indexes_to_drop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not bad. Not worth fussing over. Let's just throw them out\n",
    "# directly.\n",
    "games_df = games_df.drop(indexes_to_drop)\n",
    "games_df = games_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Our main feature is the tags, so we should make sure that all rows have them.\n",
    "indexes_to_drop = []\n",
    "\n",
    "for index, row in games_df.iterrows() :\n",
    "    if len(row['tags']) == 0 :\n",
    "        indexes_to_drop.append(index)\n",
    "\n",
    "print(len(indexes_to_drop))\n",
    "# Excellent! Looks like we're in the clear there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: A bit more standardization\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I've noticed that the way languages are written in the langauge types columns is different\n",
    "# from the way they're written in the languages columns. We'll need them to match up if we\n",
    "# want to do a comparative analysis.\n",
    "\n",
    "# The problems are threefold.\n",
    "# First, the capitalization is different.\n",
    "# Second, the language types columns split up some languages (for example, Spanish is split\n",
    "#   into \"Spanish - Spain\" and \"Spanish - Latin America\").\n",
    "# Third, some are just spelled differently, like \"schinese\" and \"Simplified Chinese\".\n",
    "\n",
    "# Since I don't want to lose data, I'll make new columns to hold the 'reduced' versions\n",
    "# (for example, where 'Spanish- Spain' is 'reduced' to 'spanish')\n",
    "\n",
    "# First, make cols and fill 'em with lists\n",
    "games_df['mod_interface_languages'] = [[] for _ in range(len(games_df))]\n",
    "games_df['mod_full_audio_languages'] = [[] for _ in range(len(games_df))]\n",
    "games_df['mod_subtitles_languages'] = [[] for _ in range(len(games_df))]\n",
    "\n",
    "\n",
    "# Next, let's just lowcap everything. Turn down the volume a bit.\n",
    "for index, row in games_df.iterrows() :\n",
    "\n",
    "    for item in row['interface_languages'] :\n",
    "        # Make a easy-to-mess-with version\n",
    "        lang = item.lower()\n",
    "\n",
    "        # Check to see if it's a variant, replace if so\n",
    "        for language in relevant_langs :\n",
    "            if language in lang :\n",
    "                lang = language\n",
    "\n",
    "        # And it looks like there are three special cases we need to handle specifically.\n",
    "        if lang == 'simplified chinese' :\n",
    "            lang = 'schinese'\n",
    "        \n",
    "        if lang == 'portuguese - brazil' :\n",
    "            lang = 'brazilian'\n",
    "        \n",
    "        if lang == 'korean' :\n",
    "            lang = 'koreana'\n",
    "\n",
    "        # Add the lowercaseified, standardizified version to the col in the main df\n",
    "        games_df.loc[index, 'mod_interface_languages'].append(lang)\n",
    "\n",
    "\n",
    "    # Now we do the same for the other two langauge type columns...\n",
    "    for item in row['full_audio_languages'] :\n",
    "        # Make a easy-to-mess-with version\n",
    "        lang = item.lower()\n",
    "\n",
    "        # Check to see if it's a variant, replace if so\n",
    "        for language in relevant_langs :\n",
    "            if language in lang :\n",
    "                lang = language\n",
    "\n",
    "        # And it looks like there are two special cases we need to handle specifically.\n",
    "        if lang == 'simplified chinese' :\n",
    "            lang = 'schinese'\n",
    "        \n",
    "        if lang == 'portuguese - brazil' :\n",
    "            lang = 'brazilian'\n",
    "\n",
    "        if lang == 'korean' :\n",
    "            lang = 'koreana'\n",
    "\n",
    "        # Add the lowercaseified, standardizified version to the col in the main df\n",
    "        games_df.loc[index, 'mod_full_audio_languages'].append(lang)\n",
    "\n",
    "\n",
    "    for item in row['subtitles_languages'] :\n",
    "        # Make a easy-to-mess-with version\n",
    "        lang = item.lower()\n",
    "\n",
    "        # Check to see if it's a variant, replace if so\n",
    "        for language in relevant_langs :\n",
    "            if language in lang :\n",
    "                lang = language\n",
    "\n",
    "        # And it looks like there are two special cases we need to handle specifically.\n",
    "        if lang == 'simplified chinese' :\n",
    "            lang = 'schinese'\n",
    "        \n",
    "        if lang == 'portuguese - brazil' :\n",
    "            lang = 'brazilian'\n",
    "\n",
    "        if lang == 'korean' :\n",
    "            lang = 'koreana'\n",
    "\n",
    "        # Add the lowercaseified, standardizified version to the col in the main df\n",
    "        games_df.loc[index, 'mod_subtitles_languages'].append(lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Wrangle a couple more key columns\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999.0     2261\n",
      "1999.0    1971\n",
      "1499.0    1668\n",
      "499.0     1569\n",
      "0.0       1065\n",
      "2999.0     769\n",
      "299.0      696\n",
      "2499.0     619\n",
      "699.0      610\n",
      "99.0       601\n",
      "199.0      574\n",
      "599.0      518\n",
      "399.0      518\n",
      "799.0      506\n",
      "3999.0     395\n",
      "1299.0     369\n",
      "1199.0     316\n",
      "899.0      250\n",
      "5999.0     198\n",
      "1799.0     168\n",
      "4999.0     149\n",
      "1099.0     125\n",
      "1599.0     120\n",
      "1699.0     117\n",
      "3499.0     117\n",
      "1399.0     107\n",
      "1899.0      71\n",
      "Name: price, dtype: int64\n",
      "16447\n"
     ]
    }
   ],
   "source": [
    "# Let's look at how our prices are distributed...\n",
    "list_of_prices = games_df['price']\n",
    "counts = list_of_prices.value_counts()\n",
    "print(counts[counts > 50])\n",
    "print(counts[counts > 50].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that almost 5/6 of our games fall into just a\n",
    "# few price points! That's significant to know. Let's use\n",
    "# these as bins, then \"below that\" and \"above that\" as\n",
    "# separate bins, for a total of 13 bins.\n",
    "\n",
    "# I'm not 100% confident in the efficacy of this method,\n",
    "# so let's preserve the original price data in the DF.\n",
    "# Later, when modeling, we can see if there's a reason\n",
    "# to use one or the other.\n",
    "\n",
    "ranges = [-5, 0, 700, 1200, 1700, 2200, 2700, 3200, 3700, 4200, 4700, 5200, 5700, 6500, 7500, np.inf]\n",
    "range_names = ['none', 'under 10', '999', '1499', '1999', '2499', '2999', '3499', '3999', '4499', '4999', '5499', '5999', '6999', 'over 80']\n",
    "games_df['price_category'] = pd.cut(games_df['price'], bins=ranges, labels=range_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'german': 0.3518753398782969, 'french': 0.016539223773356204, 'spanish': 0.031766593774197535, 'brazilian': 0.030889743446507623, 'russian': 0.0881180857999952, 'italian': 0.004785608745900224, 'schinese': 0.11112167415367331, 'japanese': 0.0037240807332686093, 'koreana': 0.014969650337693426, 'polish': 0.018410866700020782, 'english': 0.3277991326570902}\n"
     ]
    }
   ],
   "source": [
    "# We have all the info we need now, but it's not quite in a form\n",
    "# that we can use. The total number of comments per language is\n",
    "# meaningless - we need to know the average proportion of comments in\n",
    "# that language, so we can tell if any individual game (and therefore\n",
    "# any specific combination of tags) generates more engagement in that\n",
    "# market than others do.\n",
    "\n",
    "# Unfortunately, there's one other thing that probably impacts the\n",
    "# proportion of comments much more than the game itself - whether or\n",
    "# not the game has been localized into that language at all. So we can\n",
    "# control for that, making multiple constants...\n",
    "\n",
    "# To find the average, we'll need the total amount of comments in all langs\n",
    "# for all games.\n",
    "total_comments = games_df['relevant_langs_comments_sum'].sum()\n",
    "\n",
    "# Now we can programmatically calculate the percentage of ALL comments\n",
    "# that each language occupies.\n",
    "language_averages_agnostic = {}\n",
    "\n",
    "# Iterate over the languages, summing all comments in that language to find\n",
    "# the overall average.\n",
    "for language in relevant_langs :\n",
    "    total_comments_l = games_df[language].sum()\n",
    "    language_average = total_comments_l / total_comments\n",
    "    language_averages_agnostic[language] = language_average\n",
    "\n",
    "print(language_averages_agnostic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above is the calculation if we ignore whether or not the game is even in that\n",
    "# language. Let's see if it's much different when we take into account text, voice,\n",
    "# and subtitle translation, or any of the three.\n",
    "\n",
    "# Let's subset for these 4 situations, then run the same calculations again.\n",
    "\n",
    "language_averages_any = {}\n",
    "language_averages_interface = {}\n",
    "language_averages_audio = {}\n",
    "language_averages_subtitles = {}\n",
    "\n",
    "\n",
    "# Do it for all languages, all situations.\n",
    "for language in relevant_langs :\n",
    "\n",
    "    # First, the condition of the target language being localized in any way.\n",
    "    running_language_comments = 0\n",
    "    running_total_comments = 0\n",
    "\n",
    "    for index, row in games_df.iterrows() :\n",
    "        if language in row['mod_interface_languages'] or language in row['mod_full_audio_languages'] or language in row['mod_subtitles_languages'] :\n",
    "            if not pd.isna(row[language]) :\n",
    "                running_language_comments += int(row[language])\n",
    "            if not pd.isna(row['relevant_langs_comments_sum']) :\n",
    "                running_total_comments += row['relevant_langs_comments_sum']\n",
    "    if running_total_comments != 0 :\n",
    "        language_averages_any[language] = running_language_comments / running_total_comments\n",
    "\n",
    "\n",
    "    # Now, the condition of the target language being an interface language.\n",
    "    running_total_comments = 0\n",
    "    running_language_comments = 0\n",
    "\n",
    "    for index, row in games_df.iterrows() :\n",
    "        if language in row['mod_interface_languages'] :\n",
    "            if not pd.isna(row[language]) :\n",
    "                running_language_comments += row[language]\n",
    "            if not pd.isna(row['relevant_langs_comments_sum']) :\n",
    "                running_total_comments += row['relevant_langs_comments_sum']\n",
    "        if running_total_comments != 0 :\n",
    "            language_averages_interface[language] = running_language_comments / running_total_comments\n",
    "\n",
    "\n",
    "    # Now, the condition of the target language being an audio langauge.\n",
    "    running_total_comments = 0\n",
    "    running_language_comments = 0\n",
    "\n",
    "    for index, row in games_df.iterrows() :\n",
    "        if language in row['mod_full_audio_languages'] :\n",
    "            if not pd.isna(row[language]) :\n",
    "                running_language_comments += row[language]\n",
    "            if not pd.isna(row['relevant_langs_comments_sum']) :\n",
    "                running_total_comments += row['relevant_langs_comments_sum']\n",
    "    if running_total_comments != 0 :\n",
    "        language_averages_audio[language] = running_language_comments / running_total_comments\n",
    "\n",
    "\n",
    "    # Now, the condition of the target language being a subtitle langauge.\n",
    "    running_total_comments = 0\n",
    "    running_language_comments = 0\n",
    "\n",
    "    for index, row in games_df.iterrows() :\n",
    "        if language in row['mod_subtitles_languages'] :\n",
    "            if not pd.isna(row[language]) :\n",
    "                running_language_comments += row[language]\n",
    "            if not pd.isna(row['relevant_langs_comments_sum']) :\n",
    "                running_total_comments += row['relevant_langs_comments_sum']\n",
    "    if running_total_comments != 0 :\n",
    "        language_averages_subtitles[language] = running_language_comments / running_total_comments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'german': 0.3518753398782969, 'french': 0.016539223773356204, 'spanish': 0.031766593774197535, 'brazilian': 0.030889743446507623, 'russian': 0.0881180857999952, 'italian': 0.004785608745900224, 'schinese': 0.11112167415367331, 'japanese': 0.0037240807332686093, 'koreana': 0.014969650337693426, 'polish': 0.018410866700020782, 'english': 0.3277991326570902}\n",
      "{'german': 0.34900522403288403, 'french': 0.017543118764265255, 'spanish': 0.03311731507594367, 'brazilian': 0.03378615554990004, 'russian': 0.09910695706570627, 'italian': 0.005158734597328153, 'schinese': 0.13418207987403555, 'japanese': 0.0038583302792842564, 'koreana': 0.017874514097121805, 'polish': 0.021620239507972674, 'english': 0.3277991326570902}\n",
      "{'german': 0.348963744241476, 'french': 0.017548029478360067, 'spanish': 0.0331179597854611, 'brazilian': 0.03377270583585592, 'russian': 0.09912495984862231, 'italian': 0.005159162333795608, 'schinese': 0.1342625393198584, 'japanese': 0.003861035939398966, 'koreana': 0.017878601153285583, 'polish': 0.021595776671969158, 'english': 0.3277991326570902}\n",
      "{'german': 0.3540244333572581, 'french': 0.018227131178332894, 'spanish': 0.0364817118658295, 'brazilian': 0.03406458557914754, 'russian': 0.09275445382427816, 'italian': 0.006033254133052727, 'schinese': 0.1598215232866237, 'japanese': 0.005005360995938495, 'koreana': 0.015073548227345319, 'polish': 0.02227286205281403, 'english': 0.32526602152870787}\n",
      "{'german': 0.35597838599414033, 'french': 0.01833435612256012, 'spanish': 0.03073198030169981, 'brazilian': 0.03218945876119056, 'russian': 0.0778090064554942, 'italian': 0.00580963872868943, 'schinese': 0.15383918562964102, 'japanese': 0.004563185028758467, 'koreana': 0.020937545237045174, 'polish': 0.017879881621076395, 'english': 0.32862537629380284}\n"
     ]
    }
   ],
   "source": [
    "print(language_averages_agnostic)\n",
    "print(language_averages_any)\n",
    "print(language_averages_interface)\n",
    "print(language_averages_audio)\n",
    "print(language_averages_subtitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm not sure if this is \"wrangling\"  or \"feature engineering,\" but I might as well\n",
    "# end this section with a full dataset...\n",
    "\n",
    "# Let's create a column with the DIFFERENCES between the %s of comments in a language\n",
    "# on a certain game and the average number of comments in that language on all games.\n",
    "# A positive number here will indicate above-average interest within this language\n",
    "# group for this game, and a negative number will indicate below-average interest.\n",
    "\n",
    "# We'll make 5 such columns, one for each of the \"language_averages\" metrics. Later,\n",
    "# during EDA, we can see which (if any) of them yield a clearer result.\n",
    "\n",
    "# Since we have what we need already, let's just dig right in to creating columns.\n",
    "# Let's make one column for each metric, and store all language values in a dict\n",
    "# for each game in that column.\n",
    "\n",
    "holding_dict = {}\n",
    "\n",
    "games_df['comment_ratios'] = ''\n",
    "games_df['comment_diff_agnostic'] = ''\n",
    "games_df['comment_diff_any'] = ''\n",
    "games_df['comment_diff_interface'] = ''\n",
    "games_df['comment_diff_audio'] = ''\n",
    "games_df['comment_diff_subtitles'] = ''\n",
    "\n",
    "\n",
    "# First we need to create the dict of the ratio of comments for that specific\n",
    "# language/game pair.\n",
    "for index, row in games_df.iterrows() :\n",
    "\n",
    "    for language in relevant_langs :\n",
    "        score = np.nan\n",
    "        score = row[language] / row['relevant_langs_comments_sum']\n",
    "        holding_dict[language] = score\n",
    "    games_df.at[index, 'comment_ratios'] = holding_dict \n",
    "    holding_dict={}\n",
    "\n",
    "# Now that that column is filled in, we can populate the rest of them with calculations.\n",
    "for index, row in games_df.iterrows() :\n",
    "\n",
    "    # Start with the agnostic metric.\n",
    "    for language in relevant_langs :\n",
    "        score = np.nan\n",
    "        score = row['comment_ratios'][language] - language_averages_agnostic[language]\n",
    "        holding_dict[language] = score\n",
    "    games_df.at[index, 'comment_diff_agnostic'] = holding_dict.copy()\n",
    "    holding_dict={}\n",
    "\n",
    "    # Now we do the 'any' metric\n",
    "    for language in relevant_langs :\n",
    "        score = np.nan\n",
    "        if language in row['mod_interface_languages'] or \\\n",
    "                language in row['mod_full_audio_languages'] or \\\n",
    "                language in row['mod_subtitles_languages'] :\n",
    "            score = row['comment_ratios'][language] - language_averages_any[language]\n",
    "        holding_dict[language] = score\n",
    "    games_df.at[index, 'comment_diff_any'] = holding_dict.copy()\n",
    "    holding_dict={}\n",
    "\n",
    "    # \"interface_languages\" metric.\n",
    "    for language in relevant_langs :\n",
    "        score = np.nan\n",
    "        if language in row['mod_interface_languages'] :\n",
    "            score = row['comment_ratios'][language] - language_averages_interface[language]\n",
    "        holding_dict[language] = score\n",
    "    games_df.at[index, 'comment_diff_interface'] = holding_dict.copy()\n",
    "    holding_dict={}\n",
    "\n",
    "    # \"full_audio\" metric.\n",
    "    for language in relevant_langs :\n",
    "        score = np.nan\n",
    "        if language in row['mod_full_audio_languages'] :\n",
    "            score = row['comment_ratios'][language] - language_averages_audio[language]\n",
    "        holding_dict[language] = score\n",
    "    games_df.at[index, 'comment_diff_audio'] = holding_dict.copy()\n",
    "    holding_dict={}\n",
    "\n",
    "    # Last but not least, 'subtitles.'\n",
    "    for language in relevant_langs :\n",
    "        score = np.nan\n",
    "        if language in row['mod_subtitles_languages'] :\n",
    "            score = row['comment_ratios'][language] - language_averages_subtitles[language]\n",
    "        holding_dict[language] = score\n",
    "    games_df.at[index, 'comment_diff_subtitles'] = holding_dict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that all our ratios are in dictionary form, it feels kind of silly for the\n",
    "# comment counts to have their own columns. Let's dictify that one as well.\n",
    "\n",
    "games_df['language_comment_counts'] = ''\n",
    "\n",
    "for index, row in games_df.iterrows() :\n",
    "    holding_dict = {}\n",
    "    for language in relevant_langs :\n",
    "        holding_dict[language] = row[language]\n",
    "    games_df.at[index, 'language_comment_counts'] = holding_dict.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Save and Quit\n",
    "---\n",
    "We now have the maximum amount of data that we will produce before modeling.\n",
    "\n",
    "In the next notebook, we will pare down the columns and perform other steps to prepare for modeling.\n",
    "\n",
    "We'll also save some of the variables we need along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['app_id', 'title', 'developer', 'publisher', 'description',\n",
       "       'release_date', 'price', 'price_category', 'number_of_reviews',\n",
       "       'positive_review_percent', 'relevant_langs_comments_sum', 'tags',\n",
       "       'interface_languages', 'mod_interface_languages',\n",
       "       'full_audio_languages', 'mod_full_audio_languages',\n",
       "       'subtitles_languages', 'mod_subtitles_languages',\n",
       "       'language_comment_counts', 'comment_ratios', 'comment_diff_agnostic',\n",
       "       'comment_diff_any', 'comment_diff_interface', 'comment_diff_audio',\n",
       "       'comment_diff_subtitles', 'game_page_link', 'date_scraped', 'schinese',\n",
       "       'tchinese', 'japanese', 'koreana', 'thai', 'bulgarian', 'czech',\n",
       "       'danish', 'german', 'english', 'spanish', 'latam', 'greek', 'french',\n",
       "       'italian', 'indonesian', 'hungarian', 'dutch', 'norwegian', 'polish',\n",
       "       'portugese', 'brazilian', 'romanian', 'russian', 'finnish', 'swedish',\n",
       "       'turkish', 'vietnamese', 'ukranian'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's reorder or coulmns to a more sane order.\n",
    "new_column_order = ['app_id', 'title', 'developer', 'publisher', 'description', 'release_date', 'price', \\\n",
    "                    'price_category', 'number_of_reviews', 'positive_review_percent', 'relevant_langs_comments_sum', \\\n",
    "                    'tags', 'interface_languages', 'mod_interface_languages', 'full_audio_languages', \\\n",
    "                    'mod_full_audio_languages', 'subtitles_languages', 'mod_subtitles_languages', \\\n",
    "                    'language_comment_counts', 'comment_ratios', 'comment_diff_agnostic', 'comment_diff_any', \\\n",
    "                    'comment_diff_interface', 'comment_diff_audio', 'comment_diff_subtitles', 'game_page_link', 'date_scraped']\n",
    "\n",
    "# This will be the most complete version of data that we save, so let's make sure it's all in\n",
    "new_column_order = new_column_order + all_languages\n",
    "\n",
    "# Do it\n",
    "games_df = games_df.reindex(columns=new_column_order)\n",
    "\n",
    "# Check it\n",
    "games_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'all_languages' (list)\n"
     ]
    }
   ],
   "source": [
    "with open('../data/interim/1 - Games DF - Wrangled', 'wb') as file :\n",
    "    pickle.dump(games_df, file)\n",
    "\n",
    "%store all_languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
