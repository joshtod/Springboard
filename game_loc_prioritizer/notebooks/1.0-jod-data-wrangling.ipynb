{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangling & Cleaning\n",
    "---\n",
    "\n",
    "This notebook includes the following steps:\n",
    "\n",
    "1. Load the data from the 0 json\n",
    "2. Fixes data types\n",
    "3. Checks the data for reasonableness and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load up our scraped dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10008 entries, 0 to 10007\n",
      "Data columns (total 42 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   app_id                   10008 non-null  int64  \n",
      " 1   title                    10008 non-null  object \n",
      " 2   release_date             10008 non-null  object \n",
      " 3   positive_review_percent  9968 non-null   float64\n",
      " 4   number_of_reviews        9968 non-null   float64\n",
      " 5   price                    9390 non-null   float64\n",
      " 6   game_page_link           10008 non-null  object \n",
      " 7   tags                     10008 non-null  object \n",
      " 8   date_scraped             10008 non-null  object \n",
      " 9   developer                10008 non-null  object \n",
      " 10  publisher                10006 non-null  object \n",
      " 11  description              10008 non-null  object \n",
      " 12  interface_languages      10008 non-null  object \n",
      " 13  full_audio_languages     10008 non-null  object \n",
      " 14  subtitles_languages      10008 non-null  object \n",
      " 15  english                  10008 non-null  int64  \n",
      " 16  schinese                 9977 non-null   object \n",
      " 17  tchinese                 9976 non-null   object \n",
      " 18  japanese                 9976 non-null   object \n",
      " 19  koreana                  9975 non-null   object \n",
      " 20  thai                     9976 non-null   object \n",
      " 21  bulgarian                9976 non-null   object \n",
      " 22  czech                    9975 non-null   object \n",
      " 23  danish                   9976 non-null   object \n",
      " 24  german                   9977 non-null   object \n",
      " 25  spanish                  9977 non-null   object \n",
      " 26  latam                    9975 non-null   object \n",
      " 27  greek                    9975 non-null   object \n",
      " 28  french                   9976 non-null   object \n",
      " 29  italian                  9976 non-null   object \n",
      " 30  indonesian               9975 non-null   object \n",
      " 31  hungarian                9975 non-null   object \n",
      " 32  dutch                    9976 non-null   object \n",
      " 33  norwegian                9976 non-null   object \n",
      " 34  polish                   9976 non-null   object \n",
      " 35  brazilian                9976 non-null   object \n",
      " 36  romanian                 9975 non-null   object \n",
      " 37  russian                  9976 non-null   object \n",
      " 38  finnish                  9975 non-null   object \n",
      " 39  swedish                  9976 non-null   object \n",
      " 40  turkish                  9976 non-null   object \n",
      " 41  vietnamese               9976 non-null   object \n",
      "dtypes: float64(3), int64(2), object(37)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "games_df = pd.read_json('../data/raw/0 - Scraped Games DF.json', orient='records')\n",
    "\n",
    "games_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>positive_review_percent</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>price</th>\n",
       "      <th>game_page_link</th>\n",
       "      <th>tags</th>\n",
       "      <th>date_scraped</th>\n",
       "      <th>developer</th>\n",
       "      <th>...</th>\n",
       "      <th>dutch</th>\n",
       "      <th>norwegian</th>\n",
       "      <th>polish</th>\n",
       "      <th>brazilian</th>\n",
       "      <th>romanian</th>\n",
       "      <th>russian</th>\n",
       "      <th>finnish</th>\n",
       "      <th>swedish</th>\n",
       "      <th>turkish</th>\n",
       "      <th>vietnamese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>730</td>\n",
       "      <td>Counter-Strike 2</td>\n",
       "      <td>Aug 21, 2012</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7624537.0</td>\n",
       "      <td>1499.0</td>\n",
       "      <td>https://store.steampowered.com/app/730/Counter...</td>\n",
       "      <td>[1663, 1774, 3859, 3878, 19, 5711, 5055]</td>\n",
       "      <td>2023-10-03</td>\n",
       "      <td>Valve</td>\n",
       "      <td>...</td>\n",
       "      <td>18072</td>\n",
       "      <td>14293</td>\n",
       "      <td>428161</td>\n",
       "      <td>440207</td>\n",
       "      <td>51544</td>\n",
       "      <td>2008642</td>\n",
       "      <td>44889</td>\n",
       "      <td>55478</td>\n",
       "      <td>392048</td>\n",
       "      <td>9795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1086940</td>\n",
       "      <td>Baldur's Gate 3</td>\n",
       "      <td>Aug 3, 2023</td>\n",
       "      <td>0.95</td>\n",
       "      <td>318163.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>https://store.steampowered.com/app/1086940/Bal...</td>\n",
       "      <td>[122, 6426, 1742, 4747, 21, 4325, 4474]</td>\n",
       "      <td>2023-10-03</td>\n",
       "      <td>Larian Studios</td>\n",
       "      <td>...</td>\n",
       "      <td>998</td>\n",
       "      <td>501</td>\n",
       "      <td>4040</td>\n",
       "      <td>9412</td>\n",
       "      <td>19</td>\n",
       "      <td>20921</td>\n",
       "      <td>493</td>\n",
       "      <td>1153</td>\n",
       "      <td>3546</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1091500</td>\n",
       "      <td>Cyberpunk 2077</td>\n",
       "      <td>Dec 9, 2020</td>\n",
       "      <td>0.80</td>\n",
       "      <td>575978.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>https://store.steampowered.com/app/1091500/Cyb...</td>\n",
       "      <td>[4115, 1695, 6650, 122, 4182, 3942, 4295]</td>\n",
       "      <td>2023-10-03</td>\n",
       "      <td>CD PROJEKT RED</td>\n",
       "      <td>...</td>\n",
       "      <td>1003</td>\n",
       "      <td>682</td>\n",
       "      <td>17850</td>\n",
       "      <td>18341</td>\n",
       "      <td>143</td>\n",
       "      <td>61375</td>\n",
       "      <td>867</td>\n",
       "      <td>1396</td>\n",
       "      <td>15197</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1172470</td>\n",
       "      <td>Apex Legendsâ„¢</td>\n",
       "      <td>Nov 4, 2020</td>\n",
       "      <td>0.79</td>\n",
       "      <td>725075.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://store.steampowered.com/app/1172470/Ape...</td>\n",
       "      <td>[113, 3859, 176981, 1774, 1663, 3839, 1775]</td>\n",
       "      <td>2023-10-03</td>\n",
       "      <td>Respawn Entertainment</td>\n",
       "      <td>...</td>\n",
       "      <td>1729</td>\n",
       "      <td>1486</td>\n",
       "      <td>11889</td>\n",
       "      <td>14045</td>\n",
       "      <td>666</td>\n",
       "      <td>86575</td>\n",
       "      <td>2653</td>\n",
       "      <td>3697</td>\n",
       "      <td>14975</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1063730</td>\n",
       "      <td>New World</td>\n",
       "      <td>Sep 28, 2021</td>\n",
       "      <td>0.70</td>\n",
       "      <td>223724.0</td>\n",
       "      <td>3999.0</td>\n",
       "      <td>https://store.steampowered.com/app/1063730/New...</td>\n",
       "      <td>[128, 1695, 1754, 122, 21, 19, 1775]</td>\n",
       "      <td>2023-10-03</td>\n",
       "      <td>Amazon Games</td>\n",
       "      <td>...</td>\n",
       "      <td>1151</td>\n",
       "      <td>605</td>\n",
       "      <td>7642</td>\n",
       "      <td>18133</td>\n",
       "      <td>151</td>\n",
       "      <td>14059</td>\n",
       "      <td>566</td>\n",
       "      <td>1378</td>\n",
       "      <td>6383</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    app_id             title  release_date  positive_review_percent  \\\n",
       "0      730  Counter-Strike 2  Aug 21, 2012                     0.88   \n",
       "1  1086940   Baldur's Gate 3   Aug 3, 2023                     0.95   \n",
       "2  1091500    Cyberpunk 2077   Dec 9, 2020                     0.80   \n",
       "3  1172470     Apex Legendsâ„¢   Nov 4, 2020                     0.79   \n",
       "4  1063730         New World  Sep 28, 2021                     0.70   \n",
       "\n",
       "   number_of_reviews   price  \\\n",
       "0          7624537.0  1499.0   \n",
       "1           318163.0  5999.0   \n",
       "2           575978.0  5999.0   \n",
       "3           725075.0     NaN   \n",
       "4           223724.0  3999.0   \n",
       "\n",
       "                                      game_page_link  \\\n",
       "0  https://store.steampowered.com/app/730/Counter...   \n",
       "1  https://store.steampowered.com/app/1086940/Bal...   \n",
       "2  https://store.steampowered.com/app/1091500/Cyb...   \n",
       "3  https://store.steampowered.com/app/1172470/Ape...   \n",
       "4  https://store.steampowered.com/app/1063730/New...   \n",
       "\n",
       "                                          tags date_scraped  \\\n",
       "0     [1663, 1774, 3859, 3878, 19, 5711, 5055]   2023-10-03   \n",
       "1      [122, 6426, 1742, 4747, 21, 4325, 4474]   2023-10-03   \n",
       "2    [4115, 1695, 6650, 122, 4182, 3942, 4295]   2023-10-03   \n",
       "3  [113, 3859, 176981, 1774, 1663, 3839, 1775]   2023-10-03   \n",
       "4         [128, 1695, 1754, 122, 21, 19, 1775]   2023-10-03   \n",
       "\n",
       "               developer  ...  dutch norwegian  polish brazilian romanian  \\\n",
       "0                  Valve  ...  18072     14293  428161    440207    51544   \n",
       "1         Larian Studios  ...    998       501    4040      9412       19   \n",
       "2         CD PROJEKT RED  ...   1003       682   17850     18341      143   \n",
       "3  Respawn Entertainment  ...   1729      1486   11889     14045      666   \n",
       "4           Amazon Games  ...   1151       605    7642     18133      151   \n",
       "\n",
       "   russian finnish swedish turkish vietnamese  \n",
       "0  2008642   44889   55478  392048       9795  \n",
       "1    20921     493    1153    3546         31  \n",
       "2    61375     867    1396   15197        159  \n",
       "3    86575    2653    3697   14975        379  \n",
       "4    14059     566    1378    6383         87  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Standardize our data types\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "# The numbers in the comment count columns are strings\n",
    "# with extra characters. Let's standardize them as ints.\n",
    "\n",
    "# First, let's get a list of the columns that we need to process.\n",
    "# That's all columns from the comments df and one column from the\n",
    "# original game page scraped df.\n",
    "%store -r top_10_languages\n",
    "%store -r all_languages\n",
    "list_of_languages = top_10_languages.copy()\n",
    "list_of_languages.append('english')\n",
    "\n",
    "# We need all our comment counts to be ints.\n",
    "# Some of them failed to scrape - we can almost certainly remove\n",
    "# them without impacting our study, but I would like to check to\n",
    "# make sure something didn't go wrong in our previous step that\n",
    "# caused too many of them to fail.\n",
    "# So, we'll two-birds this.\n",
    "# As we ensure that all the values are ints, we'll remove the\n",
    "# ones that are \"Failed\", and then display the removed indexes.\n",
    "# We also have some games that weren't released at time of\n",
    "# scraping, so we'll just remove those as well at this stage.\n",
    "\n",
    "indexes_to_remove = set()\n",
    "\n",
    "for index, row in games_df.iterrows() :\n",
    "    for language in list_of_languages :\n",
    "        # If the count is \"Failed\", mark it for deletion.\n",
    "        if (row[language] == 'Failed') or (pd.isna(row[language])) :\n",
    "            indexes_to_remove.add(index)\n",
    "        \n",
    "\n",
    "print(len(indexes_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not too bad. Let's just drop them, then integerize.\n",
    "\n",
    "games_df = games_df.drop(indexes_to_remove)\n",
    "games_df = games_df.reset_index(drop=True)\n",
    "\n",
    "for language in list_of_languages :\n",
    "    games_df[language] = games_df[language].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's make release_date a datetime object.\n",
    "\n",
    "games_df['release_date'] = pd.to_datetime(games_df['release_date'], infer_datetime_format=True, format=\"%Y-%m-%d\", errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For games that have multiple publishers, developers, etc, they're all stored as one string.\n",
    "# If we want to use this data eventually, we should split it into lists.\n",
    "# Some games don't have publishers or developers, and that's fine.\n",
    "# Oddly, some of them have trailing spaces.\n",
    "for index, row in games_df.iterrows() :\n",
    "    if not row['developer'] :\n",
    "        games_df.at[index, 'developer'] = []\n",
    "    else :\n",
    "        if type(row['developer']) != list :\n",
    "            row['developer'] = row['developer'].split(', ')\n",
    "            # Since the above line changes the str into a list, we can .strip() each item in the list\n",
    "            # with a comprehension.\n",
    "            list_of_developers = [name.strip() for name in row['developer']]\n",
    "            games_df.at[index, 'developer'] = list_of_developers\n",
    "\n",
    "    # And again.\n",
    "    if not row['publisher'] :\n",
    "        games_df.at[index, 'publisher'] = []\n",
    "    else :\n",
    "        if type(row['publisher']) != list :\n",
    "            row['publisher'] = row['publisher'].split(', ')\n",
    "            list_of_publishers = [name.strip() for name in row['publisher']]\n",
    "            games_df.at[index, 'publisher'] = list_of_publishers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [1663, 1774, 3859, 3878, 19, 5711, 5055]\n",
       "1           [122, 6426, 1742, 4747, 21, 4325, 4474]\n",
       "2         [4115, 1695, 6650, 122, 4182, 3942, 4295]\n",
       "3       [113, 3859, 176981, 1774, 1663, 3839, 1775]\n",
       "4              [128, 1695, 1754, 122, 21, 19, 1775]\n",
       "                           ...                     \n",
       "9966     [3843, 1667, 3839, 1685, 1721, 3978, 3834]\n",
       "9967      [3859, 1774, 113, 1663, 5363, 1775, 3839]\n",
       "9968     [3843, 1671, 19, 3814, 353880, 3859, 6730]\n",
       "9969      [4231, 1646, 122, 5851, 3843, 1685, 4182]\n",
       "9970          [493, 1662, 1695, 5160, 21, 3859, 19]\n",
       "Name: tags, Length: 9971, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The tags are also just a string. We need them listed.\n",
    "tags_list = []\n",
    "\n",
    "for index, row in games_df.iterrows() :\n",
    "    if (type(row['tags']) != list) & (row['tags'] != '') :\n",
    "        tags_list = row['tags'].strip('[]').split(',')\n",
    "        games_df.at[index, 'tags'] = tags_list\n",
    "\n",
    "games_df['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['app_id', 'title', 'release_date', 'positive_review_percent',\n",
       "       'number_of_reviews', 'price', 'game_page_link', 'tags', 'date_scraped',\n",
       "       'developer', 'publisher', 'description', 'interface_languages',\n",
       "       'full_audio_languages', 'subtitles_languages', 'english', 'schinese',\n",
       "       'tchinese', 'japanese', 'koreana', 'thai', 'bulgarian', 'czech',\n",
       "       'danish', 'german', 'spanish', 'latam', 'greek', 'french', 'italian',\n",
       "       'indonesian', 'hungarian', 'dutch', 'norwegian', 'polish', 'brazilian',\n",
       "       'romanian', 'russian', 'finnish', 'swedish', 'turkish', 'vietnamese'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Same problem for our languages types columns (interface, audio, subitles).\n",
    "\n",
    "for index, row in games_df.iterrows() :\n",
    "    if (type(row['interface_languages']) != list) & (row['interface_languages'] != '') :\n",
    "        languages_list = row['interface_languages'].strip('[]').split(', ')\n",
    "        games_df.at[index, 'interface_languages'] = languages_list\n",
    "    if (type(row['full_audio_languages']) != list) & (row['full_audio_languages'] != '') :\n",
    "        languages_list = row['full_audio_languages'].strip('[]').split(', ')\n",
    "        games_df.at[index, 'full_audio_languages'] = languages_list\n",
    "    if (type(row['subtitles_languages']) != list) & (row['subtitles_languages'] != '') :\n",
    "        languages_list = row['subtitles_languages'].strip('[]').split(', ')\n",
    "        games_df.at[index, 'subtitles_languages'] = languages_list\n",
    "\n",
    "# Check.\n",
    "print(type(games_df.loc[0, 'interface_languages']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'tags_dict' (dict)\n"
     ]
    }
   ],
   "source": [
    "# For future reference, let's create a dictionary of tags codes & their meanings.\n",
    "# We can get that from the search page.\n",
    "# Keys will be the codes. Values will be the names.\n",
    "url = 'https://store.steampowered.com/search'\n",
    "html = urlopen(url)\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "# The relevant data is in this one code block.\n",
    "code_block = soup.find('div', id=\"TagFilter_Container\")\n",
    "\n",
    "# Create the empty dict.\n",
    "tags_dict = {}\n",
    "\n",
    "# Iterate over all 400+ tags described in the code block.\n",
    "for listing in code_block.find_all('div', class_='tab_filter_control_row') :\n",
    "    tag_code = listing.get('data-value')\n",
    "    tag_name = listing.get('data-loc')\n",
    "    tags_dict[tag_code] = tag_name\n",
    "\n",
    "# We'll probably need it later, so let's save it a couple ways.\n",
    "# Weirdly, it's quicker and easier to do this via a DF.\n",
    "tags_dict_df = pd.DataFrame.from_dict(tags_dict, orient='index')\n",
    "tags_dict_df.to_csv('../data/interim/Tags Dictionary DF.csv')\n",
    "%store tags_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement indicator variables\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For language_types, implement pipes (???)\n",
    "# NOTE:dx WHAT DID I MEAN BY THIS??????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Sanity checks\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{7: 9566, 4: 72, 5: 121, 6: 131, 2: 26, 3: 50, 1: 5}\n"
     ]
    }
   ],
   "source": [
    "# Since our tags column is very important to us, let's make sure\n",
    "# that the entries are reasonably comparable.\n",
    "\n",
    "# In order to count the number of tags in each game's tags list,\n",
    "# let's turn that column into a list of lists (by way of a series)\n",
    "# so that we can use a list comprehension to get a list of len()s.\n",
    "series_of_tags_column_values = games_df['tags']\n",
    "list_of_tags_column_values = series_of_tags_column_values.tolist()\n",
    "tags_values_lengths = [len(x) for x in list_of_tags_column_values]\n",
    "\n",
    "# Now we organize the counts into a dictionary, where the keys are\n",
    "# the lengths and the values are the frequencies of those lengths.\n",
    "dict_of_lenghts = {}\n",
    "\n",
    "for length in tags_values_lengths :\n",
    "    if length in dict_of_lenghts :\n",
    "        dict_of_lenghts[length] += 1\n",
    "    else :\n",
    "        dict_of_lenghts[length] = 1\n",
    "\n",
    "print(dict_of_lenghts)\n",
    "\n",
    "# Looks not too bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I discovered that summing the number of comments in the top 10 loc languages + En\n",
    "# as recorded in our DF resulted in a HIGHER comment count than Steam displays (which\n",
    "# is the one we grabbed from Steam as \"number_of_reviews\").\n",
    "\n",
    "# I don't know why that is, but it doesn't really matter. What we want is the RELATIVE\n",
    "# difference in comments per game WITHIN each language, so as long as Steam calculates\n",
    "# the number of comments in each language in a consistent way WITHIN each language, our\n",
    "# method still works.\n",
    "\n",
    "# Thus the \"number_of_reviews\" column may be useless to us, BUT I'm loathe to let go\n",
    "# of any data. Let's keep it for now, and just add a new column that we'll use for our\n",
    "# calculations: \"relevant_langs_review_sum\"\n",
    "\n",
    "games_df['relevant_langs_reviews_sum'] = None\n",
    "\n",
    "for index, row in games_df.iterrows() :\n",
    "    games_df.loc[index, 'relevant_langs_reviews_sum'] = row[list_of_languages].sum()\n",
    "\n",
    "games_df['relevant_langs_reviews_sum'] = games_df['relevant_langs_reviews_sum'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This NLP step is pretty complex and not entirely relevant for the ML task at hand, so we'll leave it out for now.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Check for string similarity in all verbal cols.\n",
    "# # In developer and publisher, this could likely find typos.\n",
    "\n",
    "# # First, let's create sets of all the extant developer and publisher names\n",
    "# # as currently typed.\n",
    "\n",
    "# set_of_developer_names = set()\n",
    "\n",
    "# for developers_list in games_df['developer'] :\n",
    "#     for developer in developers_list :\n",
    "#         set_of_developer_names.add(developer)\n",
    "\n",
    "# set_of_publisher_names = set()\n",
    "\n",
    "# for publishers_list in games_df['publisher'] :\n",
    "#     for publisher in publishers_list :\n",
    "#         set_of_publisher_names.add(publisher)\n",
    "\n",
    "# # Now, let's see if any items in that list are super similar to each other.\n",
    "# # This could possibly the the result of a typo.\n",
    "# # Let's first find the MOST similar pair in each set.\n",
    "# # If these pairs are clearly not typos, then it's very likely that there are\n",
    "# # no typos at all.\n",
    "\n",
    "# list_of_developer_similarities = []\n",
    "# listing = []\n",
    "\n",
    "# for developer in set_of_developer_names :\n",
    "#     # Create a set of names to test this name against.\n",
    "#     # We want to avoid testing the name against itself,\n",
    "#     # since that will return a maximum similarity score\n",
    "#     # and make our lives harder.\n",
    "#     # So, we'll create a new set, then drop this name\n",
    "#     # from the set before doing the comparisons.\n",
    "#     testing_set = set_of_developer_names.copy()\n",
    "#     testing_set.remove(developer)\n",
    "#     highest = process.extract(developer, testing_set, limit=1)\n",
    "#     # We need to retain both of the tested strings, while .extract only\n",
    "#     # returns the second one. We'll have to group them manually.\n",
    "#     # Let's also arbitrarily set 90 as the cutoff for similarity.\n",
    "#     if highest[0][1] >= 90 :\n",
    "#         listing = [developer, highest[0][0], highest[0][1]]\n",
    "#         list_of_developer_similarities.append(listing)\n",
    "\n",
    "\n",
    "# # Then we do it all again for publishers.\n",
    "# list_of_publisher_similarities = []\n",
    "\n",
    "# for publisher in set_of_publisher_names :\n",
    "#     testing_set = set_of_publisher_names.copy()\n",
    "#     testing_set.remove(publisher)\n",
    "#     highest = process.extract(publisher, testing_set, limit=1)\n",
    "#     if highest[0][1] >= 90 :\n",
    "#         listing = [publisher, highest[0][0], highest[0][1]]\n",
    "#         list_of_publisher_similarities.append(listing)\n",
    "\n",
    "\n",
    "# # Now we sort the lists by the similarity score.\n",
    "# list_of_developer_similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "# list_of_publisher_similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "\n",
    "# # Let's take a look at some of them... and also get a feel for\n",
    "# # how long these lists are (and therefore how many of these names\n",
    "# # are truly similar).\n",
    "# print('Similar developer names:')\n",
    "# print(list_of_developer_similarities[0:10])\n",
    "# print('Total similarity scores over 90: '+str(len(list_of_developer_similarities)))\n",
    "# print('')\n",
    "# print('Similar publisher names:')\n",
    "# print(list_of_publisher_similarities[0:10])\n",
    "# print('Total similarity scores over 90: '+str(len(list_of_publisher_similarities)))\n",
    "\n",
    "# # Well, what I've learned from this is that the names of developers and publishers\n",
    "# # would be a LOT of work to fix. Since we don't need them for now (they aren't part\n",
    "# # of our key analysis), we can just leave them as-is and clean them later if we need\n",
    "# # them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Determine completeness\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# While I want to keep all the data around just in case, this is a great\n",
    "# point for us to determine whether some rows may not be useful for us.\n",
    "\n",
    "# Our main label is the comment counts per language, so we can safely drop\n",
    "# all rows that have no language-specific comment counts at all.\n",
    "\n",
    "indexes_to_drop = []\n",
    "\n",
    "for index, row in games_df[list_of_languages].iterrows() :\n",
    "    if row.sum() == 0 :\n",
    "        indexes_to_drop.append(index)\n",
    "\n",
    "print(len(indexes_to_drop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not bad. Not worth fussing over. Let's just throw them out\n",
    "# directly.\n",
    "games_df = games_df.drop(indexes_to_drop)\n",
    "games_df = games_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Our main feature is the tags, so we should make sure that all rows have them.\n",
    "indexes_to_drop = []\n",
    "\n",
    "for index, row in games_df.iterrows() :\n",
    "    if len(row['tags']) == 0 :\n",
    "        indexes_to_drop.append(index)\n",
    "\n",
    "print(len(indexes_to_drop))\n",
    "# Excellent! Looks like we're in the clear there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: A bit more standardization\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I've noticed that the way languages are written in the langauge types columns is different\n",
    "# from the way they're written in the languages columns. We'll need them to match up if we\n",
    "# want to do a comparative analysis.\n",
    "\n",
    "# The problems are threefold.\n",
    "# First, the capitalization is different.\n",
    "# Second, the language types columns split up some languages (for example, Spanish is split\n",
    "#   into \"Spanish - Spain\" and \"Spanish - Latin America\").\n",
    "# Third, some are just spelled differently, like \"schinese\" and \"Simplified Chinese\".\n",
    "\n",
    "# Since I don't want to lose data, I'll make new columns to hold the 'reduced' versions\n",
    "# (for example, where 'Spanish- Spain' is 'reduced' to 'spanish')\n",
    "\n",
    "games_df['mod_interface_languages'] = [[] for _ in range(len(games_df))]\n",
    "games_df['mod_full_audio_languages'] = [[] for _ in range(len(games_df))]\n",
    "games_df['mod_subtitles_languages'] = [[] for _ in range(len(games_df))]\n",
    "\n",
    "\n",
    "# First, let's just lowcap everything. Turn down the volume a bit.\n",
    "for index, row in games_df.iterrows() :\n",
    "\n",
    "    for item in row['interface_languages'] :\n",
    "        # Make a easy-to-mess-with version\n",
    "        lang = item.lower()\n",
    "\n",
    "        # Check to see if it's a variant, replace if so\n",
    "        for language in list_of_languages :\n",
    "            if language in lang :\n",
    "                lang = language\n",
    "\n",
    "        # And it looks like there are three special cases we need to handle specifically.\n",
    "        if lang == 'simplified chinese' :\n",
    "            lang = 'schinese'\n",
    "        \n",
    "        if lang == 'portuguese - brazil' :\n",
    "            lang = 'brazilian'\n",
    "        \n",
    "        if lang == 'korean' :\n",
    "            lang = 'koreana'\n",
    "\n",
    "        # Add the lowercaseified, standardizified version to the col in the main df\n",
    "        games_df.loc[index, 'mod_interface_languages'].append(lang)\n",
    "\n",
    "\n",
    "    # Now we do the same for the other two langauge type columns...\n",
    "    for item in row['full_audio_languages'] :\n",
    "        # Make a easy-to-mess-with version\n",
    "        lang = item.lower()\n",
    "\n",
    "        # Check to see if it's a variant, replace if so\n",
    "        for language in list_of_languages :\n",
    "            if language in lang :\n",
    "                lang = language\n",
    "\n",
    "        # And it looks like there are two special cases we need to handle specifically.\n",
    "        if lang == 'simplified chinese' :\n",
    "            lang = 'schinese'\n",
    "        \n",
    "        if lang == 'portuguese - brazil' :\n",
    "            lang = 'brazilian'\n",
    "\n",
    "        if lang == 'korean' :\n",
    "            lang = 'koreana'\n",
    "\n",
    "        # Add the lowercaseified, standardizified version to the col in the main df\n",
    "        games_df.loc[index, 'mod_full_audio_languages'].append(lang)\n",
    "\n",
    "\n",
    "    for item in row['subtitles_languages'] :\n",
    "        # Make a easy-to-mess-with version\n",
    "        lang = item.lower()\n",
    "\n",
    "        # Check to see if it's a variant, replace if so\n",
    "        for language in list_of_languages :\n",
    "            if language in lang :\n",
    "                lang = language\n",
    "\n",
    "        # And it looks like there are two special cases we need to handle specifically.\n",
    "        if lang == 'simplified chinese' :\n",
    "            lang = 'schinese'\n",
    "        \n",
    "        if lang == 'portuguese - brazil' :\n",
    "            lang = 'brazilian'\n",
    "\n",
    "        if lang == 'korean' :\n",
    "            lang = 'koreana'\n",
    "\n",
    "        # Add the lowercaseified, standardizified version to the col in the main df\n",
    "        games_df.loc[index, 'mod_subtitles_languages'].append(lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Wrangle a couple more key columns\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999.0    1736\n",
      "999.0     1265\n",
      "1499.0    1202\n",
      "2999.0     684\n",
      "2499.0     566\n",
      "499.0      542\n",
      "3999.0     386\n",
      "699.0      264\n",
      "799.0      252\n",
      "1299.0     217\n",
      "599.0      211\n",
      "299.0      204\n",
      "5999.0     195\n",
      "1199.0     174\n",
      "4999.0     142\n",
      "399.0      139\n",
      "199.0      126\n",
      "1799.0     124\n",
      "899.0      111\n",
      "1699.0      99\n",
      "3499.0      94\n",
      "99.0        83\n",
      "1599.0      73\n",
      "1399.0      55\n",
      "Name: price, dtype: int64\n",
      "8944\n"
     ]
    }
   ],
   "source": [
    "# Let's look at how our prices are distributed...\n",
    "list_of_prices = games_df['price']\n",
    "counts = list_of_prices.value_counts()\n",
    "print(counts[counts > 50])\n",
    "print(counts[counts > 50].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that almost 5/6 of our games fall into just a\n",
    "# few price points! That's significant to know. Let's use\n",
    "# these as bins, then \"below that\" and \"above that\" as\n",
    "# separate bins, for a total of 13 bins.\n",
    "\n",
    "# I'm not 100% confident in the efficacy of this method,\n",
    "# so let's preserve the original price data in the DF.\n",
    "# Later, when modeling, we can see if there's a reason\n",
    "# to use one or the other.\n",
    "\n",
    "ranges = [-5, 0, 700, 1200, 1700, 2200, 2700, 3200, 3700, 4200, 4700, 5200, 5700, 6500, 7500, np.inf]\n",
    "range_names = ['none', 'under 10', '999', '1499', '1999', '2499', '2999', '3499', '3999', '4499', '4999', '5499', '5999', '6999', 'over 80']\n",
    "games_df['price_category'] = pd.cut(games_df['price'], bins=ranges, labels=range_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'german': 0.036144778355734, 'french': 0.024984206743360108, 'spanish': 0.047231059143115164, 'brazilian': 0.04553095708577151, 'russian': 0.13040473822233248, 'italian': 0.007174079027273987, 'schinese': 0.16373661242532556, 'japanese': 0.005471265311775909, 'koreana': 0.022479065030598478, 'polish': 0.027782788606404412, 'english': 0.4890604500483084}\n"
     ]
    }
   ],
   "source": [
    "# We have all the info we need now, but it's not quite in a form\n",
    "# that we can use. The total number of comments per language is\n",
    "# meaningless - we need to know the average proportion of comments in\n",
    "# that language, so we can tell if any individual game (and therefore\n",
    "# any specific combination of tags) generates more engagement in that\n",
    "# market than others do.\n",
    "\n",
    "# Unfortunately, there's one other thing that probably impacts the\n",
    "# proportion of comments much more than the game itself - whether or\n",
    "# not the game has been localized into that language at all. So we can\n",
    "# control for that, making multiple constants...\n",
    "\n",
    "# To find the average, we'll need the total amount of comments in all langs\n",
    "# for all games.\n",
    "total_comments = games_df['relevant_langs_reviews_sum'].sum()\n",
    "\n",
    "# Now we can programmatically calculate the percentage of ALL comments\n",
    "# that each language occupies.\n",
    "language_averages_agnostic = {}\n",
    "\n",
    "# Iterate over the languages, summing all comments in that language to find\n",
    "# the overall average.\n",
    "for language in list_of_languages :\n",
    "    total_comments_l = games_df[language].sum()\n",
    "    language_average = total_comments_l / total_comments\n",
    "    language_averages_agnostic[language] = language_average\n",
    "\n",
    "print(language_averages_agnostic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above is the calculation if we ignore whether or not the game is even in that\n",
    "# language. Let's see if it's much different when we take into account text, voice,\n",
    "# and subtitle translation, or any of the three.\n",
    "\n",
    "# Let's subset for these 4 situations, then run the same calculations again.\n",
    "\n",
    "language_averages_any = {}\n",
    "language_averages_interface = {}\n",
    "language_averages_audio = {}\n",
    "language_averages_subtitles = {}\n",
    "\n",
    "\n",
    "# Do it for all languages, all situations.\n",
    "for language in list_of_languages :\n",
    "\n",
    "    # First, the condition of the target language being localized in any way.\n",
    "    running_language_comments = 0\n",
    "    running_total_comments = 0\n",
    "\n",
    "    for index, row in games_df.iterrows() :\n",
    "        if language in row['mod_interface_languages'] or language in row['mod_full_audio_languages'] or language in row['mod_subtitles_languages'] :\n",
    "            if not pd.isna(row[language]) :\n",
    "                running_language_comments += int(row[language])\n",
    "            if not pd.isna(row['relevant_langs_reviews_sum']) :\n",
    "                running_total_comments += row['relevant_langs_reviews_sum']\n",
    "    if running_total_comments != 0 :\n",
    "        language_averages_any[language] = running_language_comments / running_total_comments\n",
    "\n",
    "\n",
    "    # Now, the condition of the target language being an interface language.\n",
    "    running_total_comments = 0\n",
    "    running_language_comments = 0\n",
    "\n",
    "    for index, row in games_df.iterrows() :\n",
    "        if language in row['mod_interface_languages'] :\n",
    "            if not pd.isna(row[language]) :\n",
    "                running_language_comments += row[language]\n",
    "            if not pd.isna(row['relevant_langs_reviews_sum']) :\n",
    "                running_total_comments += row['relevant_langs_reviews_sum']\n",
    "        if running_total_comments != 0 :\n",
    "            language_averages_interface[language] = running_language_comments / running_total_comments\n",
    "\n",
    "\n",
    "    # Now, the condition of the target language being an audio langauge.\n",
    "    running_total_comments = 0\n",
    "    running_language_comments = 0\n",
    "\n",
    "    for index, row in games_df.iterrows() :\n",
    "        if language in row['mod_full_audio_languages'] :\n",
    "            if not pd.isna(row[language]) :\n",
    "                running_language_comments += row[language]\n",
    "            if not pd.isna(row['relevant_langs_reviews_sum']) :\n",
    "                running_total_comments += row['relevant_langs_reviews_sum']\n",
    "    if running_total_comments != 0 :\n",
    "        language_averages_audio[language] = running_language_comments / running_total_comments\n",
    "\n",
    "\n",
    "    # Now, the condition of the target language being a subtitle langauge.\n",
    "    running_total_comments = 0\n",
    "    running_language_comments = 0\n",
    "\n",
    "    for index, row in games_df.iterrows() :\n",
    "        if language in row['mod_subtitles_languages'] :\n",
    "            if not pd.isna(row[language]) :\n",
    "                running_language_comments += row[language]\n",
    "            if not pd.isna(row['relevant_langs_reviews_sum']) :\n",
    "                running_total_comments += row['relevant_langs_reviews_sum']\n",
    "    if running_total_comments != 0 :\n",
    "        language_averages_subtitles[language] = running_language_comments / running_total_comments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'german': 0.036144778355734, 'french': 0.024984206743360108, 'spanish': 0.047231059143115164, 'brazilian': 0.04553095708577151, 'russian': 0.13040473822233248, 'italian': 0.007174079027273987, 'schinese': 0.16373661242532556, 'japanese': 0.005471265311775909, 'koreana': 0.022479065030598478, 'polish': 0.027782788606404412, 'english': 0.4890604500483084}\n",
      "{'german': 0.03820873372873624, 'french': 0.026287156605066822, 'spanish': 0.048909878901039636, 'brazilian': 0.04903540680844366, 'russian': 0.14465392518202805, 'italian': 0.007641480840734052, 'schinese': 0.19441194304805706, 'japanese': 0.0056357526935938655, 'koreana': 0.02632102031860673, 'polish': 0.03217858504546673, 'english': 0.4890604500483084}\n",
      "{'german': 0.03821671790426049, 'french': 0.026292358709004256, 'spanish': 0.048907999769560465, 'brazilian': 0.049015116804730835, 'russian': 0.1446776568327955, 'italian': 0.0076417149023017515, 'schinese': 0.19452605992606867, 'japanese': 0.0056408407643961265, 'koreana': 0.02632672993685473, 'polish': 0.03214198402547969, 'english': 0.4890604500483084}\n",
      "{'german': 0.04207609631700441, 'french': 0.027354554185195376, 'spanish': 0.054202471490695396, 'brazilian': 0.04915350792794835, 'russian': 0.13358993838306327, 'italian': 0.009104020337148513, 'schinese': 0.22038545199188317, 'japanese': 0.007445024096378019, 'koreana': 0.022069539683156628, 'polish': 0.03364025010015045, 'english': 0.48241713878650727}\n",
      "{'german': 0.039592630746067344, 'french': 0.027800610073768633, 'spanish': 0.04575977395250984, 'brazilian': 0.04689105344061799, 'russian': 0.11438169639046838, 'italian': 0.008706848636097856, 'schinese': 0.22556698601613356, 'japanese': 0.006814790178499301, 'koreana': 0.03135781813190943, 'polish': 0.027191887302639862, 'english': 0.4896275123968649}\n"
     ]
    }
   ],
   "source": [
    "print(language_averages_agnostic)\n",
    "print(language_averages_any)\n",
    "print(language_averages_interface)\n",
    "print(language_averages_audio)\n",
    "print(language_averages_subtitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm not sure if this is \"wrangling\"  or \"feature engineering,\" but I might as well\n",
    "# end this section with a full dataset...\n",
    "\n",
    "# Let's create a column with the DIFFERENCES between the %s of comments in a language\n",
    "# on a certain game and the average number of comments in that language on all games.\n",
    "# A positive number here will indicate above-average interest within this language\n",
    "# group for this game, and a negative number will indicate below-average interest.\n",
    "\n",
    "# We'll make 5 such columns, one for each of the \"language_averages\" metrics. Later,\n",
    "# during EDA, we can see which (if any) of them yield a clearer result.\n",
    "\n",
    "# Since we have what we need already, let's just dig right in to creating columns.\n",
    "# Let's make one column for each metric, and store all language values in a dict\n",
    "# for each game in that column.\n",
    "\n",
    "holding_dict = {}\n",
    "\n",
    "games_df['comment_ratios'] = ''\n",
    "games_df['comment_diff_agnostic'] = ''\n",
    "games_df['comment_diff_any'] = ''\n",
    "games_df['comment_diff_interface'] = ''\n",
    "games_df['comment_diff_audio'] = ''\n",
    "games_df['comment_diff_subtitles'] = ''\n",
    "\n",
    "\n",
    "# First we need to create the dict of the ratio of comments for that specific\n",
    "# language/game pair.\n",
    "for index, row in games_df.iterrows() :\n",
    "\n",
    "    for language in list_of_languages :\n",
    "        score = np.nan\n",
    "        score = row[language] / row['relevant_langs_reviews_sum']\n",
    "        holding_dict[language] = score\n",
    "    games_df.at[index, 'comment_ratios'] = holding_dict \n",
    "    holding_dict={}\n",
    "\n",
    "# Now that that column is filled in, we can populate the rest of them with calculations.\n",
    "for index, row in games_df.iterrows() :\n",
    "\n",
    "    # Start with the agnostic metric.\n",
    "    for language in list_of_languages :\n",
    "        score = np.nan\n",
    "        score = row['comment_ratios'][language] - language_averages_agnostic[language]\n",
    "        holding_dict[language] = score\n",
    "    games_df.at[index, 'comment_diff_agnostic'] = holding_dict \n",
    "    holding_dict={}\n",
    "\n",
    "    # Now we do the 'any' metric\n",
    "    for language in list_of_languages :\n",
    "        score = np.nan\n",
    "        if language in row['mod_interface_languages'] or \\\n",
    "                language in row['mod_full_audio_languages'] or \\\n",
    "                language in row['mod_subtitles_languages'] :\n",
    "            score = row['comment_ratios'][language] - language_averages_any[language]\n",
    "        holding_dict[language] = score\n",
    "    games_df.at[index, 'comment_diff_any'] = holding_dict\n",
    "    holding_dict={}\n",
    "\n",
    "    # \"interface_languages\" metric.\n",
    "    for language in list_of_languages :\n",
    "        score = np.nan\n",
    "        if language in row['mod_interface_languages'] :\n",
    "            score = row['comment_ratios'][language] - language_averages_interface[language]\n",
    "        holding_dict[language] = score\n",
    "    games_df.at[index, 'comment_diff_interface'] = holding_dict\n",
    "    holding_dict={}\n",
    "\n",
    "    # \"full_audio\" metric.\n",
    "    for language in list_of_languages :\n",
    "        score = np.nan\n",
    "        if language in row['mod_full_audio_languages'] :\n",
    "            score = row['comment_ratios'][language] - language_averages_audio[language]\n",
    "        holding_dict[language] = score\n",
    "    games_df.at[index, 'comment_diff_audio'] = holding_dict\n",
    "    holding_dict={}\n",
    "\n",
    "    # Last but not least, 'subtitles.'\n",
    "    for language in list_of_languages :\n",
    "        score = np.nan\n",
    "        if language in row['mod_subtitles_languages'] :\n",
    "            score = row['comment_ratios'][language] - language_averages_subtitles[language]\n",
    "        holding_dict[language] = score\n",
    "    games_df.at[index, 'comment_diff_subtitles'] = holding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that all our ratios are in dictionary form, it feels kind of silly for the\n",
    "# comment counts to have their own columns. Let's dictify that one as well.\n",
    "\n",
    "games_df['language_comment_counts'] = ''\n",
    "\n",
    "for index, row in games_df.iterrows() :\n",
    "    holding_dict = {}\n",
    "    for language in list_of_languages :\n",
    "        holding_dict[language] = row[language]\n",
    "    games_df.at[index, 'language_comment_counts'] = holding_dict.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Save and Quit\n",
    "---\n",
    "We now have the maximum amount of data that we will produce before modeling.\n",
    "\n",
    "In the next notebook, we will pare down the columns and perform other steps to prepare for modeling.\n",
    "\n",
    "We'll also save some of the variables we need along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['app_id', 'title', 'developer', 'publisher', 'description',\n",
       "       'release_date', 'price', 'price_category', 'number_of_reviews',\n",
       "       'positive_review_percent', 'relevant_langs_reviews_sum', 'tags',\n",
       "       'interface_languages', 'mod_interface_languages',\n",
       "       'full_audio_languages', 'mod_full_audio_languages',\n",
       "       'subtitles_languages', 'mod_subtitles_languages',\n",
       "       'language_comment_counts', 'comment_ratios', 'comment_diff_agnostic',\n",
       "       'comment_diff_any', 'comment_diff_interface', 'comment_diff_audio',\n",
       "       'comment_diff_subtitles', 'game_page_link'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's reorder or coulmns to a more sane order.\n",
    "\n",
    "new_column_order = ['app_id', 'title', 'developer', 'publisher', 'description', 'release_date', 'price', \\\n",
    "                    'price_category', 'number_of_reviews', 'positive_review_percent', 'relevant_langs_reviews_sum', \\\n",
    "                    'tags', 'interface_languages', 'mod_interface_languages', 'full_audio_languages', \\\n",
    "                    'mod_full_audio_languages', 'subtitles_languages', 'mod_subtitles_languages', \\\n",
    "                    'language_comment_counts', 'comment_ratios', 'comment_diff_agnostic', 'comment_diff_any', \\\n",
    "                    'comment_diff_interface', 'comment_diff_audio', 'comment_diff_subtitles', 'game_page_link']\n",
    "\n",
    "games_df = games_df.reindex(columns=new_column_order)\n",
    "\n",
    "games_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'all_languages' (list)\n"
     ]
    }
   ],
   "source": [
    "with open('../data/interim/1 - Games DF - Wrangled', 'wb') as file :\n",
    "    pickle.dump(games_df, file)\n",
    "\n",
    "%store all_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(load_test.loc[0, 'release_date'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
