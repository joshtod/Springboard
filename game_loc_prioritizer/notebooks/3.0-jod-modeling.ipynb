{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Describes a system for taking a single user_id as an input and generating game recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "\n",
    "- Develop a way to verify (remove a game from a user with 10+ games, try to infer it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "# import datatable as dt\n",
    "\n",
    "import pickle\n",
    "# import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# from collections import Counter\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# import scipy.sparse as sp\n",
    "from scipy.sparse import coo_matrix, csr_matrix, lil_matrix\n",
    "from scipy.sparse import load_npz\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%store -r tags_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dfs to display the rec results in a human-readable way\n",
    "with open('../data/interim/1 - Games DF - Wrangled.pkl', 'rb') as file :\n",
    "    games_df = pickle.load(file)\n",
    "with open('../data/processed/usable_recently_played.pkl', 'rb') as file :\n",
    "    recently_played_df = pickle.load(file)\n",
    "review_table = pq.read_table('../data/processed/usable_review_table.parquet')\n",
    "with open('../data/raw/all_users', 'rb') as file :\n",
    "    all_users = pickle.load(file)\n",
    "\n",
    "# Load the tables used to define input\n",
    "game_tags_matrix = load_npz('../data/processed/full_game_tag_matrix.npz')\n",
    "user_info_matrix = load_npz('../data/processed/user_info_matrix.npz')\n",
    "\n",
    "# Load the tables used for inference\n",
    "game_tags_matrix_reduced = load_npz('../data/processed/reduced_game_tag_matrix.npz')\n",
    "user_info_matrix_reduced = load_npz('../data/processed/user_info_matrix_reduced.npz')\n",
    "\n",
    "# Load the index converters for the games/tags matrix\n",
    "with open('../data/processed/tag_to_col_index.pkl', \"rb\") as file :\n",
    "    tag_to_col_index = pickle.load(file)\n",
    "with open('../data/processed/game_reduced_index_to_full_index.pkl', 'rb') as file :\n",
    "    game_reduced_index_to_full_index = pickle.load(file)\n",
    "with open('../data/processed/game_to_full_index.pkl', 'rb') as file :\n",
    "    game_to_full_index = pickle.load(file)\n",
    "\n",
    "# Load the index converters for the users/games matrix\n",
    "with open('../data/processed/user_to_full_index.pkl', 'rb') as file :\n",
    "    user_to_full_index = pickle.load(file)\n",
    "with open('../data/processed/game_to_col_index.pkl', 'rb') as file :\n",
    "    game_to_col_index = pickle.load(file)\n",
    "with open('../data/processed/user_reduced_index_to_full_index.pkl', 'rb') as file :\n",
    "    user_reduced_index_to_full_index = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative recommendations, step 1: find similar users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an arbitrary number of similar users\n",
    "def get_similar_users(target_user_row, similar_user_limit=50, test_user_indices=[], testing=False, verbose=False) :\n",
    "    \"\"\"\n",
    "    Takes a user id and returns a sorted descending series of the X most similar users:\n",
    "        keys = user index (in the reduced matrix)\n",
    "        values = cosine similarity\n",
    "    Rows that have played no games that the target user hasn't also played are removed,*\n",
    "    as they have no novel info for prediction.\n",
    "    \"\"\"\n",
    "\n",
    "    # Establish the indices of users that can be considered\n",
    "    # (they must have played at least one game that the target user has not)\n",
    "    # All users in the reduced table have played at least 5 games, so \n",
    "    # if len(target_user_touched_games) < 5 :\n",
    "    #     usable_indices = [index for index in range(user_info_matrix_reduced.shape[0]) if len(set(user_info_matrix_reduced[index].indices) - target_user_touched_games) > 0]\n",
    "    # else :\n",
    "    #     usable_indices = range(0, user_info_matrix_reduced.shape[0])\n",
    "    # NOTE: PROBABLY NEED TO TIGHTEN THIS UP A BIT!\n",
    "    # I NEED TO FILTER THE MATRIX OR ASCERTAIN THE INDICES FOR USERS THAT HAVE PLAYED\n",
    "    # AT LEAST ONE GAME THAT THE TARGET HAS NOT.\n",
    "    # THIS MAY BE A NONISSUE, SINCE ALL USERS IN THE PREDICITON SET HAVE PLAYED AT\n",
    "    # LEAST 5 GAMES, AND WE ARE REMOVING COSINE SIM SCORES OF 1\n",
    "    # SO SOMEONE WHO HAS PLAYED 1 FEWER GAME MIGHT SCORE HIGHER THAN SOMEONE PLAYING 2 MORE\n",
    "    # BUT ALL THE OPERATIONS I CAN THINK OF TO DO THIS ON A CSR ARE WAAAAY TOO SLOW\n",
    "\n",
    "    # Go ahead and run cosine similarity now, so that the scores can be associated with the correct index.\n",
    "    row_cosine_similarities = pd.Series(cosine_similarity(target_user_row, user_info_matrix_reduced)[0], name=\"similarity_score\")\n",
    "\n",
    "    # If we're testing, remove all test users from this step\n",
    "    if testing==True :\n",
    "        for index in row_cosine_similarities.index :\n",
    "            if index in test_user_indices :\n",
    "                row_cosine_similarities = row_cosine_similarities.drop(index)\n",
    "\n",
    "    # Remove the 1s\n",
    "    row_cosine_similarities = row_cosine_similarities[row_cosine_similarities < 1]\n",
    "\n",
    "    row_cosine_similarities.sort_values(ascending=False, inplace=True)\n",
    "    most_similar_users = row_cosine_similarities[:similar_user_limit]\n",
    "\n",
    "    if verbose==True :\n",
    "        print(f\"Top {similar_user_limit} most similar users:\")\n",
    "        for index, value in most_similar_users.items() :\n",
    "            print(f\"{round(value, 9)} -- {index}\")\n",
    "            \n",
    "    return(most_similar_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative recommendations, step 2: generate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate suggestions based on that.\n",
    "# First, find out all the games these \"similar users\" have played.\n",
    "# Then, weight those playes by the similarity score, then sum them across users.\n",
    "\n",
    "# NOTE：I could speed all this up by just using arrays instead of rows/columns\n",
    "\n",
    "\n",
    "def get_collab_scores(similar_users, collab_filter_limit=50, target_user_touched_games=[], verbose=False) :\n",
    "    \n",
    "    # Convert to df for easier row/column-wise computation\n",
    "    similar_users_df = pd.DataFrame(similar_users)\n",
    "\n",
    "    # We need to make a column in the df for each game, so we grab all games\n",
    "    # here (indexed by game col index).\n",
    "    # We remove any games already touched by the target user along the way.\n",
    "    relevant_games = set()\n",
    "    for user in similar_users.keys() :\n",
    "        for game in user_info_matrix[user].indices :\n",
    "            if game not in target_user_touched_games :\n",
    "                relevant_games.add(game)\n",
    "    \n",
    "    # Create a column for each game\n",
    "    for game in relevant_games :\n",
    "        similar_users_df[game] = 0\n",
    "\n",
    "    # Now fill those columns with the scores\n",
    "    for user in similar_users.keys() :\n",
    "        for game in user_info_matrix[user].indices :\n",
    "            similar_users_df.loc[user, game] = user_info_matrix[user, game]\n",
    "\n",
    "    # Now multiply the scores by the normalized similarity score\n",
    "    for user, row in similar_users_df.iterrows() :\n",
    "        for game in relevant_games :\n",
    "            if row[game] != 0 :\n",
    "                similar_users_df.loc[user, game] = row['similarity_score'] * row[game]\n",
    "\n",
    "    # Now collect those scores\n",
    "    # NOTE: CONVERTS GAME COL INDEX BACK TO APP_ID AT THIS STEP\n",
    "    collab_filt_rec_scores = {}\n",
    "    for game in relevant_games:\n",
    "        collab_filt_rec_scores[game_to_col_index.inverse[game]] = similar_users_df[game].sum()\n",
    "\n",
    "    collab_filt_scores = pd.Series(collab_filt_rec_scores, name=\"collab_rec_score\").sort_values(ascending=False)\n",
    "\n",
    "    # Limit the output\n",
    "    collab_filt_scores = collab_filt_scores[:collab_filter_limit]\n",
    "\n",
    "    # To make them interactible with later scores, let's standardize them\n",
    "    # scaler = MinMaxScaler()\n",
    "    # collab_filt_scores = pd.Series(scaler.fit_transform(collab_filt_rec_scores.values.reshape(-1,1)).flatten(), index=collab_filt_rec_scores.index)\n",
    "    # if verbose==True :\n",
    "    #     for app_id, score in collab_filt_scores.items() :\n",
    "    #         print(f\"{round(score, 3)} -- {games_df[games_df['app_id']==app_id]['title'].values[0]}\")\n",
    "    \n",
    "    return collab_filt_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-based recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: STRETCH GOAL: Determine multimodality, generate different lists of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine most similar games for each, multiply by user preference, MinMaxScale.\n",
    "\n",
    "def get_content_scores(target_user_row, content_filter_limit, verbose=False) :\n",
    "\n",
    "    \"\"\"\n",
    "    Takes a row from the users/games table, then does the following:\n",
    "        1. Finds recs for each from the reduced game/tags matrix\n",
    "        2. Creates a descending-sorted 10-row Series:\n",
    "            keys = game's index (relative to main games_df)\n",
    "            values = queried game's cosine similarity score to the queried game\n",
    "        3. Weights all values in the series by the user's preference for the game\n",
    "        4. Combines all resulting series into a single series with sim scores summed\n",
    "        5. Returns the series\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the most recent games.\n",
    "    # I already have the games in terms of col indices in the users matrix.\n",
    "    # I need the indices for the games matrix, to do cos similarity.\n",
    "\n",
    "    # Go from game col index to app_id\n",
    "    # played_game_app_ids = [game_to_col_index.inverse[game] for game in target_user_row.indices]\n",
    "    # # Go from app_id to full game row index\n",
    "    # played_game_full_matrix_row_indices = [game_to_full_index[game] for game in played_game_app_ids]\n",
    "\n",
    "    # Find the sim scores for each game, adding them to the main list\n",
    "    similarity_series_list = []\n",
    "    full_row_indexes = []\n",
    "\n",
    "    for query_index in target_user_row.indices :\n",
    "\n",
    "        # Get the reduced game/tags matrix index\n",
    "        current_app_id = game_to_col_index.inverse[query_index] \n",
    "        current_full_row_index = game_to_full_index[current_app_id]\n",
    "        try :\n",
    "            reduced_row_index = game_reduced_index_to_full_index.inverse[current_full_row_index]\n",
    "        except :\n",
    "            ####\n",
    "            continue \n",
    "\n",
    "        # Let's grab the full row index. We will later use this to remove\n",
    "        # already-touched games from the recommendations.\n",
    "        full_row_indexes.append(current_full_row_index)\n",
    "\n",
    "        # Find the similarity score between games\n",
    "        # The resulting series is indexed by the reduced games matrix\n",
    "        row_cosine_similarities = pd.Series(cosine_similarity(game_tags_matrix[current_full_row_index], game_tags_matrix_reduced)[0])\n",
    "        # Reindex the predictions back to the full game matrix index\n",
    "        row_cosine_similarities.index = [game_reduced_index_to_full_index[index] for index in row_cosine_similarities.index]\n",
    "        row_cosine_similarities.sort_values(ascending=False, inplace=True)\n",
    "        # Since we cannot know ahead of time how many games the user has touched,\n",
    "        # and the user may have only touched one game,\n",
    "        # we can safely limit the results here to the overall content filter limit.\n",
    "        # This will ensure that the full number of scores are returned no matter \n",
    "        # how many games were touched. \n",
    "        # This is still indexed by the full game matrix.\n",
    "        top_similar = row_cosine_similarities[:content_filter_limit]\n",
    "\n",
    "        # Now, get a coefficient to represent the user's preference for the game in question.\n",
    "        # All games similar to this game will be modified by this coefficient.\n",
    "        # First we find the game's column in the full user matrix\n",
    "        preference_coefficient = target_user_row[0, query_index]\n",
    "        # Then we just multiply.\n",
    "        top_similar = top_similar * preference_coefficient\n",
    "\n",
    "        # That's all we need for the score! Let's append.\n",
    "        similarity_series_list.append(top_similar)\n",
    "\n",
    "        # if verbose == True :\n",
    "        #     print(f\"Recs for {games_df.loc[current_full_row_index]['title']}:\")\n",
    "        #     for rec in top_similar.items() :\n",
    "        #         print(f\"{round(rec[1], 3)} -- {games_df.loc[rec[0]]['title']}\")\n",
    "\n",
    "    # Combine the serieses into the main series.\n",
    "    # Here it's still indexed by full game matrix index.\n",
    "    final_scores = pd.Series()\n",
    "    for similarity_series in similarity_series_list :\n",
    "        final_scores = final_scores.add(similarity_series, fill_value=0)\n",
    "    final_scores = final_scores.sort_values(ascending=False)\n",
    "\n",
    "    # Remove already-played games from the main series\n",
    "    for game in full_row_indexes :\n",
    "        try :\n",
    "            final_scores = final_scores.drop(labels=game)\n",
    "        except :\n",
    "            continue\n",
    "\n",
    "    # Normalize the series to make it similar to the collaborative score series\n",
    "    # I suppose the original values were some wonky kind of float that didn't work\n",
    "    # with scipy, so we coerce them here.\n",
    "    content_filt_scores = stats.zscore(final_scores.astype(float))\n",
    "\n",
    "    # Return the desired number of values\n",
    "    if len(content_filt_scores) < content_filter_limit :\n",
    "        content_filter_limit = len(content_filt_scores)\n",
    "    content_filt_scores = content_filt_scores[:content_filter_limit]\n",
    "\n",
    "    # Set index to app_id\n",
    "    content_filt_scores.index = [game_to_full_index.inverse[game] for game in content_filt_scores.index]\n",
    "\n",
    "    # if verbose == True :\n",
    "    #     print('------------------')\n",
    "    #     for game, score in content_filt_scores.items() :\n",
    "    #         print(f\"{round(score, 3)} -- {games_df[games_df['app_id']==game]['title'].values[0]}\")     \n",
    "    \n",
    "    return(content_filt_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the recs for final set of recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Is it worth checking the scale discrepancy between the two and tweaking the ratio\n",
    "# programmatically for each distribution?\n",
    "\n",
    "# It may be that tweaking the relative weights of the collaborative and content-based filter results\n",
    "# can improve accuracy. Let's define this as a function so we can play with that programmatically\n",
    "# later, if need be.\n",
    "\n",
    "def combine_scores(collaborative, content_based, double_bonus=0, popular_bias=0, ratio=0.5, recs=10) :\n",
    "    \"\"\"\n",
    "    Takes a series of collaborative filtering scores (key=app_id, value=score)\n",
    "    And a series of content based filtering scores with the same schema\n",
    "    And a 0-1 ratio of importance between the two (higher ratio favors collaborative scores)\n",
    "    And the \"double_bonus\", which is multiplied/summed to the score of each game that appears in both lists\n",
    "    And a \"popular_bias\" which is multiplied to the pos_review_percent and added to the score\n",
    "    And the number of recommendations to be returned\n",
    "\n",
    "    Returns a series of game app_ids and recommendation scores\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the ratio-modified scores\n",
    "    collaborative = collaborative * ratio\n",
    "    content_based = content_based * (1-ratio)\n",
    "\n",
    "    # Add them into the base final scores series\n",
    "    final_recs = collaborative.add(content_based, fill_value=0)\n",
    "\n",
    "    # Apply doubles bonus, if any\n",
    "    doubles = []\n",
    "    for game in collaborative.index :\n",
    "        if game in content_based.index :\n",
    "            doubles.append(game)\n",
    "    for game in doubles :\n",
    "        final_recs[game] += (final_recs[game] * double_bonus)\n",
    "\n",
    "    # Apply popularity bonus, if any\n",
    "    for index in final_recs.index :\n",
    "        positive_review_percent = games_df[games_df['app_id']==index]['positive_review_percent'].values[0]\n",
    "        final_recs[index] += (positive_review_percent * popular_bias)\n",
    "\n",
    "    # Sort descending\n",
    "    final_recs = final_recs.sort_values(ascending=False)\n",
    "\n",
    "    # Determine length\n",
    "    if len(final_recs) < recs :\n",
    "        recs = len(final_recs)\n",
    "    \n",
    "    # Determine final recs\n",
    "    final_recs = final_recs[:recs]\n",
    "\n",
    "    return final_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create unified function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recs(user, similar_user_limit=50, collab_filter_limit=50, content_filter_limit=50, double_bonus=0, popular_bias=0, ratio=0.5, recs=10, test_user_indices=[], test_user_rows=[], testing=False, verbose=False, show_result=False) :\n",
    "\n",
    "    \"\"\"\n",
    "    Takes a user via full user matrix index\n",
    "    Generates a series of recommendations\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Let's-a-go!\n",
    "    begin = time.time()\n",
    "\n",
    "    # Grab some useful info about the target user\n",
    "    if testing==True :\n",
    "        # target_user_id = user_reduced_index_to_full_index.inverse[game_reduced_index_to_full_index[user]]\n",
    "        target_user_row = test_user_rows[test_user_indices.index(user)]\n",
    "        # print(target_user_row)\n",
    "    else :\n",
    "        # target_user_id = user_to_full_index.inverse[user]\n",
    "        target_user_row = user_info_matrix[user]\n",
    "\n",
    "    target_user_touched_games = set(target_user_row.indices)\n",
    "\n",
    "    # Display some stuff\n",
    "    if show_result==True or verbose==True :\n",
    "        print(\"------ User profile:\")\n",
    "        for game in target_user_touched_games :\n",
    "            app_id = game_to_col_index.inverse[game]\n",
    "            score = target_user_row[0, game]\n",
    "            print(f\"{score} - {games_df[games_df['app_id']==app_id]['title'].values[0]}\")\n",
    "        print(\"--------------------\")\n",
    "\n",
    "    # Get similar users\n",
    "    most_similar_users = get_similar_users(target_user_row, similar_user_limit=similar_user_limit, test_user_indices=test_user_indices, testing=testing, verbose=False)\n",
    "    if verbose==True :\n",
    "        print(\"\\nTop 5 most similar users\\n\")\n",
    "        print(most_similar_users.head())\n",
    "        print(\"--------------------------\")\n",
    "\n",
    "    # Print the params here to make it easier to intuit what's happening in the results\n",
    "    if verbose==True :\n",
    "        print(f\"similar_user_limit: {similar_user_limit}\")\n",
    "        print(f\"collab_filter_limit: {collab_filter_limit}\")\n",
    "        print(f\"content_filter_limit: {content_filter_limit}\")\n",
    "        print(f\"double_bonus: {round(double_bonus, 3)}\")\n",
    "        print(f\"popular_bias: {round(popular_bias, 3)}\")\n",
    "        print(f\"ratio col/con: {round(ratio, 3)}\")\n",
    "        print(f\"num of recs: {recs}\\n\")\n",
    "\n",
    "    # Get scores from them\n",
    "    collab_filt_scores = get_collab_scores(most_similar_users, collab_filter_limit=collab_filter_limit, target_user_touched_games=target_user_touched_games, verbose=False)\n",
    "    if verbose==True :\n",
    "        print(\"Top 8 collab filt scores\")\n",
    "        for index, item in collab_filt_scores.head(8).items() :\n",
    "            print(f\"{round(item, 3)} -- {games_df[games_df['app_id']==index]['title'].values[0]}\")\n",
    "        print(\"--------------------------\")\n",
    "\n",
    "    # Get content filtering scores\n",
    "    content_filt_scores = get_content_scores(target_user_row, content_filter_limit=content_filter_limit,  verbose=False)\n",
    "    if verbose==True :\n",
    "        print(\"Top 8 content filt scores\")\n",
    "        for index, item in content_filt_scores.head(8).items() :\n",
    "            print(f\"{round(item, 3)} -- {games_df[games_df['app_id']==index]['title'].values[0]}\")\n",
    "        print(\"--------------------------\")\n",
    "    \n",
    "    # Calculate final scores\n",
    "    final_recs = combine_scores(collab_filt_scores, content_filt_scores, double_bonus=double_bonus, popular_bias=popular_bias, ratio=ratio, recs=recs)\n",
    "\n",
    "    if show_result==True or verbose==True:\n",
    "        print('')\n",
    "        print('------ Recommendations')\n",
    "        for index, score in final_recs.items() :\n",
    "            print(f\"{round(score, 3)} -- {games_df[games_df['app_id']==index]['title'].values[0]}\")\n",
    "        print(\"--------------------\")\n",
    "        print(f\"\\nRuntime: {round(time.time()-begin, 2)}s\\n\")\n",
    "\n",
    "    return final_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Commented out so that running the notebook skips directly to testing/evaluation\n",
    "\n",
    "# params = {\n",
    "#     \"similar_user_limit\":50,\n",
    "#     \"collab_filter_limit\":50,\n",
    "#     \"content_filter_limit\":50,\n",
    "#     \"double_bonus\":2,\n",
    "#     \"popular_bias\":3,\n",
    "#     \"ratio\":0.2,\n",
    "#     \"recs\":20,\n",
    "#     \"verbose\":False,\n",
    "#     \"show_result\": True\n",
    "# }\n",
    "\n",
    "# recs = get_recs(50, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "The basic idea is to remove a game or games from a user's profile (preferably a user with a significant number of touched games) and see if the engine recommends that game for the modified user profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programmatically assemble a set of usable user profiles (10+ touched games)\n",
    "\n",
    "def get_test_users(user_count=50, minimum_games=10) :\n",
    "    \"\"\"\n",
    "    Returns user_count number of test users (reduced user matrix index) as a list\n",
    "    Each user must have at least minimum_games number of touched games and disliked at least one game\n",
    "    \"\"\"\n",
    "    \n",
    "    # VARS\n",
    "    test_user_indices = []\n",
    "    checked_indices = set()\n",
    "    total_users = user_info_matrix_reduced.shape[0]\n",
    "\n",
    "    while len(test_user_indices) < user_count :\n",
    "        # Find a user at random\n",
    "        index = random.randint(1, total_users)\n",
    "        # Make sure you haven't done this one before\n",
    "        if index not in checked_indices :\n",
    "            # Make sure the user has enough games\n",
    "            if len(user_info_matrix_reduced[index].indices) >= minimum_games :\n",
    "                # Make sure they dislike at least one game\n",
    "                if -1 in user_info_matrix_reduced[index].data :\n",
    "                    # Log 'em!\n",
    "                    test_user_indices.append(index)\n",
    "        # Log 'em!\n",
    "        checked_indices.add(index)\n",
    "    \n",
    "    return test_user_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly remove one or more game(s) from each, and save as a list of rows.\n",
    "\n",
    "def create_test_rows(test_user_indices) :\n",
    "    \"\"\"\n",
    "    Takes a list of reduced user matrix indices (test users)\n",
    "    Returns 3 items:\n",
    "    1. A list of those users' rows with the most- and least- liked games removed\n",
    "    2. A list of those users' most-liked games (in matching index order)\n",
    "    3. A list of those users' least-liked games (in matching index order)\n",
    "    \"\"\"\n",
    "\n",
    "    test_rows = []\n",
    "    liked_games = []\n",
    "    disliked_games = []\n",
    "\n",
    "    for test_user in test_user_indices :\n",
    "        current_row = user_info_matrix_reduced[test_user]\n",
    "\n",
    "        # Pick a game they LIKED VERY MUCH to remove\n",
    "        liked_game = np.argmax(current_row.data)\n",
    "\n",
    "        # Pick a game they HATED to remove.\n",
    "        # It's possible that all values are positive, in which case this variable will\n",
    "        # have no meaning. We will check that at the evaluation phase.\n",
    "        # For now, we'll pull the value no matter what to perserve index relationships.\n",
    "        disliked_game = np.argmin(current_row.data)\n",
    "\n",
    "        # Save the values for evaluation\n",
    "        liked = (test_user, current_row.indices[liked_game], current_row.data[liked_game])\n",
    "        liked_games.append(liked)\n",
    "        disliked = (test_user, current_row.indices[disliked_game], current_row.data[disliked_game])\n",
    "        disliked_games.append(disliked)\n",
    "\n",
    "        # Remove the values\n",
    "\n",
    "        lil_row = current_row.tolil()\n",
    "        lil_row[0, liked[1]] = 0\n",
    "        lil_row[0, disliked[1]] = 0\n",
    "        current_row = lil_row.tocsr()\n",
    "        current_row.eliminate_zeros()\n",
    "\n",
    "        # Add it to the list\n",
    "        test_rows.append(current_row)\n",
    "        \n",
    "    return test_rows, liked_games, disliked_games\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "\n",
    "# Checks to see if POSITIVE game is in top X recs: +\n",
    "# Checks to see if NEGATIVE game is in recs at all: -\n",
    "\n",
    "def binary_evaluator(results, verbose=False) :\n",
    "    \"\"\"\"\n",
    "    Takes a list of tuples with the schema:\n",
    "        1. Series of recommendations (key=app_id, value=utility score)\n",
    "        2. app_id of favorite game\n",
    "        3. app_id of least favorite game\n",
    "\n",
    "    Evaluates the recommendations in each tuple by:\n",
    "        Adding 1 to the overall score if the favorite game is recommended\n",
    "        Subtracting 1 from the overall score if the least favorite game is recommended\n",
    "    \n",
    "    Returns the score as an int\n",
    "    \"\"\"\n",
    "\n",
    "    good = []\n",
    "    bad = []\n",
    "\n",
    "    for result in results :\n",
    "        if result[1] in result[0].index :\n",
    "            good.append(1)\n",
    "        if (result[2] != result[1]) and (result[2] in result[0].index) :\n",
    "            bad.append(1)\n",
    "    \n",
    "    validated = sum(good)\n",
    "    disproved = sum(bad)\n",
    "    score = validated - disproved\n",
    "\n",
    "    print(f\"Validated recommendations: {validated}\")\n",
    "    print(f\"Disproved recommendations: {disproved}\")\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on each modified profile\n",
    "\n",
    "\n",
    "def run_a_test(test_users=50, evaluator=binary_evaluator, similar_user_limit=50, collab_filter_limit=50, \\\n",
    "               content_filter_limit=50, double_bonus=0, popular_bias=0, ratio=0.5, recs=10, \\\n",
    "               testing=True, verbose=False, show_result=False) :\n",
    "    \n",
    "    # Generate X test user indices\n",
    "    test_user_indices = get_test_users(test_users)\n",
    "\n",
    "    test_rows, liked_games, disliked_games = create_test_rows(test_user_indices)\n",
    "\n",
    "    # test_user_full_indices = [user_reduced_index_to_full_index[user] for user in test_user_indices]\n",
    "    results = []\n",
    "\n",
    "    params = {\n",
    "        \"test_user_indices\":test_user_indices,\n",
    "        \"test_user_rows\":test_rows,\n",
    "        \"similar_user_limit\":similar_user_limit,\n",
    "        \"collab_filter_limit\":collab_filter_limit,\n",
    "        \"content_filter_limit\":content_filter_limit,\n",
    "        \"double_bonus\":double_bonus,\n",
    "        \"popular_bias\":popular_bias,\n",
    "        \"ratio\":ratio,\n",
    "        \"recs\":recs,\n",
    "        \"verbose\":verbose,\n",
    "        \"show_result\":show_result,\n",
    "        \"testing\":testing\n",
    "        }\n",
    "\n",
    "    for i in range(len(test_user_indices)) :\n",
    "        result = get_recs(test_user_indices[i], **params)\n",
    "        results.append((result, \\\n",
    "                        game_to_col_index.inverse[liked_games[i][1]], \\\n",
    "                        game_to_col_index.inverse[disliked_games[i][1]]))\n",
    "        \n",
    "    score = evaluator(results)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Commented out so that running the notebook skips directly to testing/evaluation\n",
    "\n",
    "# test_params = {\n",
    "#     \"test_users\":50,\n",
    "#     \"evaluator\":binary_evaluator,\n",
    "#     \"similar_user_limit\":50,\n",
    "#     \"collab_filter_limit\":50,\n",
    "#     \"content_filter_limit\":50,\n",
    "#     \"double_bonus\":2,\n",
    "#     \"popular_bias\":3,\n",
    "#     \"ratio\":0.2,\n",
    "#     \"recs\":20,\n",
    "#     \"testing\":True,\n",
    "#     \"verbose\":False,\n",
    "#     \"show_result\":True\n",
    "# }\n",
    "\n",
    "# run_a_test(**test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O   P   T   I   M   I   Z   E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boptimize(test_users=50, evaluator=binary_evaluator, n_iter=4, init_points=10, verbose=False, show_result=False) :\n",
    "    \n",
    "    # We'll define our test set here, so the Bayesian bit below will\n",
    "    # execute on the same subset each time.\n",
    "\n",
    "    # Generate X test user indices\n",
    "    test_user_indices = get_test_users(test_users)\n",
    "\n",
    "    # Generate test rows\n",
    "    test_rows, liked_games, disliked_games = create_test_rows(test_user_indices)\n",
    "\n",
    "\n",
    "    # Define the scoring function within the main function so that it has native access to variables\n",
    "    def bayes_test(test_user_indices=test_user_indices, liked_games=liked_games, \\\n",
    "               disliked_games=disliked_games, test_rows=test_rows, evaluator=evaluator, \\\n",
    "               similar_user_limit=50, collab_filter_limit=50, \\\n",
    "               content_filter_limit=50, double_bonus=0, popular_bias=0, ratio=0.5, \\\n",
    "               recs=10, testing=True, verbose=verbose, show_result=show_result) :\n",
    "    \n",
    "        params = {\n",
    "        \"test_user_indices\":test_user_indices,\n",
    "        \"test_user_rows\":test_rows,\n",
    "        \"similar_user_limit\":int(similar_user_limit),\n",
    "        \"collab_filter_limit\":int(collab_filter_limit),\n",
    "        \"content_filter_limit\":int(content_filter_limit),\n",
    "        \"double_bonus\":double_bonus,\n",
    "        \"popular_bias\":popular_bias,\n",
    "        \"ratio\":ratio,\n",
    "        \"recs\":int(recs),\n",
    "        \"verbose\":verbose,\n",
    "        \"show_result\":show_result,\n",
    "        \"testing\":testing\n",
    "        }\n",
    "        \n",
    "        results = []\n",
    "\n",
    "        for i in range(len(test_user_indices)) :\n",
    "            result = get_recs(test_user_indices[i], **params)\n",
    "            results.append((result, \\\n",
    "                            game_to_col_index.inverse[liked_games[i][1]], \\\n",
    "                            game_to_col_index.inverse[disliked_games[i][1]]))\n",
    "            \n",
    "        score = evaluator(results)\n",
    "        print(score)\n",
    "\n",
    "        return score\n",
    "\n",
    "\n",
    "    # Prepare params for Bayes\n",
    "    param_bounds = {\n",
    "        \"similar_user_limit\":(250, 250),\n",
    "        \"collab_filter_limit\":(100, 125),\n",
    "        \"content_filter_limit\":(25, 45),\n",
    "        \"double_bonus\":(1.5, 2.3),\n",
    "        \"popular_bias\":(1.5, 2.8),\n",
    "        \"ratio\":(0.1, 0.7),\n",
    "        \"recs\":(20, 20),\n",
    "        }\n",
    "    \n",
    "    # Execute\n",
    "    optimizer = BayesianOptimization(f=bayes_test, pbounds=param_bounds, random_state=42)\n",
    "    optimizer.maximize(init_points=init_points, n_iter=n_iter)\n",
    "    best_params = optimizer.max\n",
    "    print(best_params)\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | collab... | conten... | double... | popula... |   ratio   |   recs    | simila... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "------ User profile:\n",
      "0.2 - Sven Co-op\n",
      "0.2 - Psychopomp\n",
      "0.2 - Dream Tactics Demo\n",
      "0.2 - Bendy and the Ink Machine\n",
      "1.0 - Valheim\n",
      "1.0 - Crab Game\n",
      "0.2 - Team Fortress 2\n",
      "1.0 - Gloomwood\n",
      "0.2 - Gravity Bone\n",
      "1.0 - ULTRAKILL\n",
      "1.0 - Among Us\n",
      "0.2 - Garry's Mod\n",
      "--------------------\n",
      "\n",
      "------ Recommendations\n",
      "7.423 -- Raft\n",
      "6.553 -- ARK: Survival Evolved\n",
      "4.78 -- Counter-Strike 2\n",
      "3.827 -- Scrap Mechanic\n",
      "3.787 -- Necesse\n",
      "3.507 -- REAVER\n",
      "3.503 -- Grounded\n",
      "3.46 -- Smalland: Survive the Wilds\n",
      "3.438 -- Scuffy Game\n",
      "3.416 -- TerraTech\n",
      "3.41 -- Enshrouded\n",
      "3.362 -- Dig or Die\n",
      "3.361 -- Solace Crafting\n",
      "3.315 -- Craftopia\n",
      "3.307 -- Volcanoids\n",
      "3.252 -- Imposters: Countdown\n",
      "3.2 -- Force of Nature\n",
      "3.179 -- Voidtrain\n",
      "3.127 -- Road to Eden\n",
      "3.057 -- Subsistence\n",
      "--------------------\n",
      "\n",
      "Runtime: 12.97s\n",
      "\n",
      "------ User profile:\n",
      "-1.0 - Five Nights at Freddy's: Security Breach\n",
      "0.2 - HELLDIVERS™ 2\n",
      "0.2 - Tom Clancy's Rainbow Six® Siege\n",
      "0.2 - Project Zomboid\n",
      "1.0 - Apex Legends™\n",
      "1.0 - Gorilla Tag\n",
      "1.0 - BONEWORKS\n",
      "1.0 - Sekiro™: Shadows Die Twice - GOTY Edition\n",
      "1.0 - Dishonored 2\n",
      "1.0 - POSTAL 2\n",
      "1.0 - Forza Horizon 4\n",
      "0.2 - Terraria\n",
      "0.2 - Squad\n",
      "-1.0 - Onward\n",
      "0.2 - Sea of Thieves 2023 Edition\n",
      "1.0 - Beat Saber\n",
      "1.0 - Tom Clancy's Ghost Recon: Future Soldier™\n",
      "0.2 - Diablo® IV\n",
      "1.0 - The Walking Dead: Saints & Sinners\n",
      "1.0 - VRChat\n",
      "0.2 - ELDEN RING\n",
      "1.0 - DARK SOULS™ III\n",
      "0.2 - Sid Meier’s Civilization® VI\n",
      "1.0 - Rust\n",
      "0.2 - War Thunder\n",
      "0.2 - Mortal Kombat 11\n",
      "0.2 - The Last of Us™ Part I\n",
      "0.2 - Assassin's Creed® Syndicate\n",
      "--------------------\n",
      "\n",
      "------ Recommendations\n",
      "9.112 -- DARK SOULS™ II: Scholar of the First Sin\n",
      "5.859 -- Forza Horizon 5\n",
      "4.118 -- Dragon's Dogma: Dark Arisen\n",
      "4.026 -- Counter-Strike 2\n",
      "3.953 -- Middle-earth™: Shadow of Mordor™\n",
      "3.868 -- Immortal Legacy: The Jade Cipher[VR]\n",
      "3.842 -- The Lab\n",
      "3.822 -- Necro Mutex\n",
      "3.808 -- Lies of P\n",
      "3.807 -- Nioh: Complete Edition\n",
      "3.801 -- Assassin's Creed Freedom Cry\n",
      "3.784 -- Shadow of the Tomb Raider: Definitive Edition\n",
      "3.717 -- Sniper Elite 4\n",
      "3.644 -- Steelrising\n",
      "3.637 -- Bound By Flame\n",
      "3.596 -- Pascal's Wager: Definitive Edition\n",
      "3.558 -- Lords Of The Fallen™ 2014\n",
      "3.552 -- Dark Cave\n",
      "3.42 -- Garbage Day\n",
      "3.391 -- Rogue Company\n",
      "--------------------\n",
      "\n",
      "Runtime: 12.93s\n",
      "\n",
      "------ User profile:\n",
      "1.0 - Resident Evil 3\n",
      "1.0 - Yu-Gi-Oh! Duel Links\n",
      "1.0 - Monster Hunter: World\n",
      "1.0 - Resident Evil 4 (2005)\n",
      "1.0 - Baldur's Gate 3\n",
      "1.0 - Cyberpunk 2077\n",
      "1.0 - Resident Evil 2\n",
      "1.0 - Resident Evil Village\n",
      "0.2 - Blasphemous\n",
      "1.0 - Gunfire Reborn\n",
      "1.0 - Warhammer: End Times - Vermintide\n",
      "0.2 - Street Fighter™ 6\n",
      "1.0 - TEKKEN 7\n",
      "1.0 - Street Fighter V\n",
      "1.0 - Guild Wars 2\n",
      "1.0 - Warhammer 40,000: Darktide\n",
      "1.0 - Borderlands 2\n",
      "--------------------\n",
      "\n",
      "------ Recommendations\n",
      "9.28 -- Resident Evil 4\n",
      "5.963 -- Resident Evil 7 Biohazard\n",
      "5.808 -- The Evil Within 2\n",
      "5.298 -- Resident Evil\n",
      "5.266 -- Resident Evil 0\n",
      "4.847 -- EBOLA\n",
      "4.733 -- Resident Evil 3: Raccoon City Demo\n",
      "4.691 -- Cold Fear™\n",
      "4.631 -- Counter-Strike 2\n",
      "4.63 -- Obscure\n",
      "4.495 -- The Evil Within\n",
      "4.427 -- Resident Evil Revelations\n",
      "4.299 -- Obscure II (Obscure: The Aftermath)\n",
      "4.066 -- Daymare: 1998\n",
      "4.031 -- RED EVIL\n",
      "3.951 -- Arizona Sunshine®\n",
      "3.903 -- E.Y.E: Divine Cybermancy\n",
      "3.861 -- Them and Us\n",
      "3.823 -- THE KING OF FIGHTERS XIII STEAM EDITION\n",
      "3.699 -- GUILTY GEAR Xrd REV 2\n",
      "--------------------\n",
      "\n",
      "Runtime: 11.71s\n",
      "\n",
      "------ User profile:\n",
      "0.2 - VRChat\n",
      "1.0 - PAYDAY 2\n",
      "0.2 - Need for Speed™ Heat\n",
      "0.2 - The Witcher® 3: Wild Hunt\n",
      "0.2 - Atomic Heart\n",
      "1.0 - Tom Clancy's Rainbow Six® Siege\n",
      "-1.0 - Cities: Skylines II\n",
      "-1.0 - SCP: Secret Laboratory\n",
      "0.2 - Lethal Company\n",
      "0.2 - Crab Champions\n",
      "1.0 - Fallout 4\n",
      "-1.0 - STAR WARS™: Squadrons\n",
      "1.0 - STAR WARS Jedi: Fallen Order™\n",
      "0.2 - Fallout 76\n",
      "0.2 - Watch Dogs®: Legion\n",
      "--------------------\n",
      "\n",
      "------ Recommendations\n",
      "13.765 -- Counter-Strike 2\n",
      "8.0 -- PUBG: BATTLEGROUNDS\n",
      "6.705 -- Metro Exodus\n",
      "6.105 -- Fallout 3: Game of the Year Edition\n",
      "5.794 -- Hogwarts Legacy\n",
      "5.748 -- Counter-Strike: Source\n",
      "4.275 -- Lightphobe\n",
      "4.164 -- Tom Clancy's Ghost Recon®\n",
      "4.083 -- GROUND BRANCH\n",
      "4.005 -- Arma 3\n",
      "3.825 -- Zero Hour\n",
      "3.592 -- ARMA: Gold Edition\n",
      "3.51 -- Fallout: New Vegas\n",
      "3.42 -- The Elder Scrolls IV: Oblivion® Game of the Year Edition\n",
      "3.388 -- Starfield\n",
      "3.383 -- The Elder Scrolls III: Morrowind® Game of the Year Edition\n",
      "3.314 -- S.T.A.L.K.E.R.: Call of Pripyat\n",
      "3.292 -- Rise of the Tomb Raider™\n",
      "3.281 -- Mad Max\n",
      "3.271 -- Fallout 3\n",
      "--------------------\n",
      "\n",
      "Runtime: 12.01s\n",
      "\n",
      "------ User profile:\n",
      "1.0 - No Man's Sky\n",
      "1.0 - MONOPOLY® PLUS\n",
      "1.0 - Mafia II (Classic)\n",
      "1.0 - Music Racer\n",
      "-1.0 - CROWZ\n",
      "1.0 - Euro Truck Simulator 2\n",
      "1.0 - Mafia II: Definitive Edition\n",
      "1.0 - STALCRAFT\n",
      "1.0 - V Rising\n",
      "1.0 - PUBG: BATTLEGROUNDS\n",
      "1.0 - The Elder Scrolls V: Skyrim Special Edition\n",
      "1.0 - American Truck Simulator\n",
      "1.0 - Borderlands 3\n",
      "1.0 - Dota Underlords\n",
      "--------------------\n",
      "\n",
      "------ Recommendations\n",
      "4.059 -- Motor Town: Behind The Wheel\n",
      "4.047 -- Mafia: Definitive Edition\n",
      "3.762 -- Sleeping Dogs: Definitive Edition\n",
      "3.73 -- Sleeping Dogs\n",
      "3.672 -- Mafia\n",
      "3.533 -- Farming Simulator 19\n",
      "3.512 -- Euro Truck Simulator\n",
      "3.512 -- Max Payne 2: The Fall of Max Payne\n",
      "3.506 -- OMSI 2: Steam Edition\n",
      "3.474 -- The Bus\n",
      "3.432 -- Counter-Strike 2\n",
      "3.342 -- Mafia III: Definitive Edition\n",
      "3.293 -- Truck & Logistics Simulator\n",
      "3.286 -- Grand Theft Auto: Vice City – The Definitive Edition\n",
      "3.285 -- Max Payne 3\n",
      "3.238 -- Fernbus Simulator\n",
      "3.23 -- Grand Theft Auto: San Andreas – The Definitive Edition\n",
      "3.208 -- Voidtrain\n",
      "3.193 -- Train Sim World® 4\n",
      "3.177 -- Tourist Bus Simulator\n",
      "--------------------\n",
      "\n",
      "Runtime: 12.44s\n",
      "\n",
      "------ User profile:\n",
      "1.0 - Half-Life: Alyx\n",
      "1.0 - Beat Saber\n",
      "0.2 - STEINS;GATE\n",
      "1.0 - Cyberpunk 2077\n",
      "1.0 - NieR Replicant™ ver.1.22474487139...\n",
      "1.0 - The Witcher® 3: Wild Hunt\n",
      "0.2 - Counter-Strike 2\n",
      "0.2 - Dead Cells\n",
      "1.0 - GRIS\n",
      "1.0 - Marvel’s Spider-Man Remastered\n",
      "1.0 - Assassin's Creed® Odyssey\n",
      "1.0 - NieR:Automata™\n",
      "-1.0 - Starfield\n",
      "-1.0 - Halo: The Master Chief Collection\n",
      "1.0 - Dota Underlords\n",
      "1.0 - Outer Wilds\n",
      "1.0 - Baba Is You\n",
      "0.2 - Ghostrunner\n",
      "--------------------\n",
      "\n",
      "------ Recommendations\n",
      "5.781 -- FINAL FANTASY XV WINDOWS EDITION\n",
      "4.007 -- Marvel’s Spider-Man: Miles Morales\n",
      "3.906 -- The Witcher: Enhanced Edition Director's Cut\n",
      "3.776 -- Rise of the Tomb Raider™\n",
      "3.705 -- Assassin’s Creed® IV Black Flag™\n",
      "3.679 -- Assassin's Creed® Revelations\n",
      "3.676 -- Assassin's Creed 2\n",
      "3.672 -- Assassin’s Creed® Brotherhood\n",
      "3.639 -- Middle-earth™: Shadow of War™\n",
      "3.619 -- Ys SEVEN\n",
      "3.608 -- Assassin's Creed® Origins\n",
      "3.594 -- Middle-earth™: Shadow of Mordor™\n",
      "3.566 -- Terminator: Resistance\n",
      "3.558 -- .hack//G.U. Last Recode\n",
      "3.542 -- Tales of Berseria™\n",
      "3.499 -- Ys Origin\n",
      "3.497 -- Metro Exodus\n",
      "3.486 -- Crystar\n",
      "3.426 -- Trials of Mana\n",
      "3.424 -- Horizon Zero Dawn™ Complete Edition\n",
      "--------------------\n",
      "\n",
      "Runtime: 13.08s\n",
      "\n",
      "------ User profile:\n",
      "1.0 - RIFT\n",
      "1.0 - The Long Dark\n",
      "1.0 - Home Legacy\n",
      "1.0 - Paladins®\n",
      "1.0 - Brawlhalla\n",
      "1.0 - Unturned\n",
      "1.0 - Grand Theft Auto V\n",
      "1.0 - Infestation: The New Z\n",
      "1.0 - Neverwinter\n",
      "1.0 - Rust\n",
      "--------------------\n",
      "\n",
      "------ Recommendations\n",
      "5.339 -- DayZ\n",
      "5.243 -- CastleMiner Z\n",
      "5.034 -- Miscreated\n",
      "4.298 -- Counter-Strike 2\n",
      "4.284 -- Undawn\n",
      "4.261 -- Sunrise: survival\n",
      "3.773 -- No More Room in Hell\n",
      "3.653 -- Transmissions: Element 120\n",
      "3.55 -- The Lord of the Rings Online™\n",
      "3.507 -- Stranded Deep\n",
      "3.478 -- SURVIVAL: Postapocalypse Now\n",
      "3.45 -- Continent of the Ninth Seal\n",
      "3.375 -- Voidtrain\n",
      "3.351 -- Toram Online\n",
      "3.329 -- NosTale - Anime MMORPG\n",
      "3.289 -- Dungeons & Dragons Online®\n",
      "3.201 -- Vindictus\n",
      "3.196 -- Star Trek Online\n",
      "3.183 -- Fallen Earth Classic\n",
      "3.166 -- Panzar\n",
      "--------------------\n",
      "\n",
      "Runtime: 12.72s\n",
      "\n",
      "------ User profile:\n",
      "1.0 - POSTAL Redux\n",
      "1.0 - Apsulov: End of Gods\n",
      "-1.0 - Sword Art Online: Lost Song\n",
      "1.0 - POSTAL 2\n",
      "-1.0 - Book of Yog Idle RPG\n",
      "-1.0 - Agony\n",
      "1.0 - Layers of Fear (2016)\n",
      "1.0 - SCP022\n",
      "-1.0 - A New Beginning - Final Cut\n",
      "-1.0 - Angry Video Game Nerd Adventures\n",
      "1.0 - AER Memories of Old\n",
      "-1.0 - Tower of Fantasy\n",
      "--------------------\n",
      "\n",
      "------ Recommendations\n",
      "4.048 -- SOMA\n",
      "3.245 -- What Remains of Edith Finch\n",
      "3.153 -- Marie's Room\n",
      "3.138 -- Counter-Strike 2\n",
      "3.113 -- Please Duology\n",
      "3.097 -- Year Walk\n",
      "3.064 -- RiME\n",
      "3.06 -- Off-Peak\n",
      "3.058 -- INFRA\n",
      "3.039 -- No one lives under the lighthouse Director's cut\n",
      "2.995 -- The Vanishing of Ethan Carter\n",
      "2.986 -- Among the Sleep - Enhanced Edition\n",
      "2.961 -- Trapped\n",
      "2.937 -- Visage\n",
      "2.904 -- Gray Dawn\n",
      "2.89 -- Marginalia\n",
      "2.881 -- The Hotel\n",
      "2.849 -- My Grandparents' Christmas Mystery\n",
      "2.826 -- Rise of Insanity\n",
      "2.782 -- Conarium\n",
      "--------------------\n",
      "\n",
      "Runtime: 12.0s\n",
      "\n",
      "------ User profile:\n",
      "1.0 - Half-Life: Alyx\n",
      "1.0 - PAYDAY 2\n",
      "0.2 - CONFLICT OF NATIONS: WORLD WAR 3\n",
      "1.0 - Splitgate\n",
      "0.2 - Bloons TD 6\n",
      "1.0 - Bean Battles\n",
      "0.2 - HELLDIVERS™ 2\n",
      "1.0 - Titanfall® 2\n",
      "0.2 - BattleBit Remastered\n",
      "1.0 - Apex Legends™\n",
      "0.2 - Grand Theft Auto V\n",
      "0.2 - Assetto Corsa\n",
      "0.2 - Call of Duty®\n",
      "0.2 - CarX Drift Racing Online\n",
      "1.0 - The Forest\n",
      "1.0 - Destiny 2\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "boptimize(test_users=200, n_iter=3, init_points=8, show_result=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
